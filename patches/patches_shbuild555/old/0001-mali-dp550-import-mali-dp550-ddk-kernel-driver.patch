From 1f8c1297907f12f0c7001bef7fa02a3769c72da9 Mon Sep 17 00:00:00 2001
From: Lei Zhang <lei.zhang@intel.com>
Date: Thu, 31 Dec 2015 13:26:20 +0800
Subject: [PATCH] mali, dp550: import mali dp550 ddk kernel driver

revision: r1p0-05rel0

Change-Id: Iebdf0ee5e44a2d51c3d469fb33c6c62b650703ab
Tracked-On:
Signed-off-by: Lei Zhang <lei.zhang@intel.com>
---
 Documentation/arm/video/malidp_adf_api.txt         |  478 +++++
 .../devicetree/bindings/video/mali-dp.txt          |  107 +
 .../devicetree/bindings/video/senc_tx.txt          |   51 +
 .../devicetree/bindings/video/test_video_tx.txt    |   37 +
 drivers/video/adf/arm/Kbuild                       |   32 +
 drivers/video/adf/arm/Kconfig                      |   27 +
 drivers/video/adf/arm/Makefile                     |   35 +
 drivers/video/adf/arm/malidp_adf.c                 | 1556 ++++++++++++++
 drivers/video/adf/arm/malidp_adf.h                 |   56 +
 drivers/video/adf/arm/malidp_adf_format.c          |  308 +++
 drivers/video/adf/arm/malidp_adf_format.h          |   32 +
 drivers/video/adf/arm/malidp_adf_interface.c       | 1171 +++++++++++
 drivers/video/adf/arm/malidp_adf_interface.h       |   62 +
 drivers/video/adf/arm/malidp_adf_overlay.c         |  154 ++
 drivers/video/adf/arm/malidp_adf_overlay.h         |   28 +
 drivers/video/adf/arm/malidp_de_device.c           | 1213 +++++++++++
 drivers/video/adf/arm/malidp_de_device.h           |  378 ++++
 drivers/video/adf/arm/malidp_drv.c                 |  396 ++++
 drivers/video/adf/arm/malidp_drv.h                 |   45 +
 drivers/video/adf/arm/malidp_hw.c                  | 2161 ++++++++++++++++++++
 drivers/video/adf/arm/malidp_hw.h                  |  315 +++
 drivers/video/adf/arm/malidp_hw_types.h            |  171 ++
 drivers/video/adf/arm/malidp_iommu.c               |  451 ++++
 drivers/video/adf/arm/malidp_iommu.h               |   41 +
 drivers/video/adf/arm/malidp_of_graph.c            |  130 ++
 drivers/video/adf/arm/malidp_of_graph.h            |   48 +
 drivers/video/adf/arm/malidp_se_device.c           |  668 ++++++
 drivers/video/adf/arm/malidp_se_device.h           |  296 +++
 drivers/video/adf/arm/malidp_sysfs.c               |  220 ++
 drivers/video/adf/arm/malidp_sysfs.h               |   29 +
 drivers/video/adf/arm/product/malidp_product_api.h |  165 ++
 .../video/adf/arm/product/malidp_product_dp500.c   | 1364 ++++++++++++
 .../video/adf/arm/product/malidp_product_dp550.c   | 1154 +++++++++++
 drivers/video/video-tx/Kbuild                      |   23 +
 drivers/video/video-tx/Kconfig                     |   37 +
 drivers/video/video-tx/Makefile                    |   38 +
 drivers/video/video-tx/senc_tx.c                   |  586 ++++++
 drivers/video/video-tx/test_video_tx.c             |  701 +++++++
 drivers/video/video-tx/video_tx.c                  |  489 +++++
 include/uapi/video/malidp_adf.h                    |  290 +++
 include/video/video_tx.h                           |  112 +
 41 files changed, 15655 insertions(+)
 create mode 100644 Documentation/arm/video/malidp_adf_api.txt
 create mode 100644 Documentation/devicetree/bindings/video/mali-dp.txt
 create mode 100644 Documentation/devicetree/bindings/video/senc_tx.txt
 create mode 100644 Documentation/devicetree/bindings/video/test_video_tx.txt
 create mode 100644 drivers/video/adf/arm/Kbuild
 create mode 100644 drivers/video/adf/arm/Kconfig
 create mode 100644 drivers/video/adf/arm/Makefile
 create mode 100644 drivers/video/adf/arm/malidp_adf.c
 create mode 100644 drivers/video/adf/arm/malidp_adf.h
 create mode 100644 drivers/video/adf/arm/malidp_adf_format.c
 create mode 100644 drivers/video/adf/arm/malidp_adf_format.h
 create mode 100644 drivers/video/adf/arm/malidp_adf_interface.c
 create mode 100644 drivers/video/adf/arm/malidp_adf_interface.h
 create mode 100644 drivers/video/adf/arm/malidp_adf_overlay.c
 create mode 100644 drivers/video/adf/arm/malidp_adf_overlay.h
 create mode 100644 drivers/video/adf/arm/malidp_de_device.c
 create mode 100644 drivers/video/adf/arm/malidp_de_device.h
 create mode 100644 drivers/video/adf/arm/malidp_drv.c
 create mode 100644 drivers/video/adf/arm/malidp_drv.h
 create mode 100644 drivers/video/adf/arm/malidp_hw.c
 create mode 100644 drivers/video/adf/arm/malidp_hw.h
 create mode 100644 drivers/video/adf/arm/malidp_hw_types.h
 create mode 100644 drivers/video/adf/arm/malidp_iommu.c
 create mode 100644 drivers/video/adf/arm/malidp_iommu.h
 create mode 100644 drivers/video/adf/arm/malidp_of_graph.c
 create mode 100644 drivers/video/adf/arm/malidp_of_graph.h
 create mode 100644 drivers/video/adf/arm/malidp_se_device.c
 create mode 100644 drivers/video/adf/arm/malidp_se_device.h
 create mode 100644 drivers/video/adf/arm/malidp_sysfs.c
 create mode 100644 drivers/video/adf/arm/malidp_sysfs.h
 create mode 100644 drivers/video/adf/arm/product/malidp_product_api.h
 create mode 100644 drivers/video/adf/arm/product/malidp_product_dp500.c
 create mode 100644 drivers/video/adf/arm/product/malidp_product_dp550.c
 create mode 100644 drivers/video/video-tx/Kbuild
 create mode 100644 drivers/video/video-tx/Kconfig
 create mode 100644 drivers/video/video-tx/Makefile
 create mode 100644 drivers/video/video-tx/senc_tx.c
 create mode 100644 drivers/video/video-tx/test_video_tx.c
 create mode 100644 drivers/video/video-tx/video_tx.c
 create mode 100644 include/uapi/video/malidp_adf.h
 create mode 100644 include/video/video_tx.h

diff --git a/Documentation/arm/video/malidp_adf_api.txt b/Documentation/arm/video/malidp_adf_api.txt
new file mode 100644
index 0000000..dc79fa8
--- /dev/null
+++ b/Documentation/arm/video/malidp_adf_api.txt
@@ -0,0 +1,478 @@
+#
+# (C) COPYRIGHT 2014-2015 ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+
+Mali-DP ADF custom data API
+===========================
+
+The malidp_custom_data struct, passed to the mali_dp driver in an ADF_POST
+operation describes the layout of the "posted" buffers on the screen,
+including their positions, orientations and sizes. It complements the list
+of adf_buffer_configs with a list of malidp_buffer_configs, which provide the
+further information necessary to construct the scene.
+
+Broadly speaking, the two buffer lists can be interpreted thus:
+  * adf_buffer_config list -> physical description of the buffers
+  * malidp_buffer_config list -> describes the appearance of the buffers
+    on-screen
+
+A malidp_buffer_config must always be associated with an adf_buffer_config by
+using the adf_buffer_index field. It must also target a particular interface:
+  * The primary display interface
+  * The memory write-back interface
+If it is desired to "display" a buffer on both interfaces, then two
+malidp_buffer_configs are required - one "targeting" the primary interface
+and one targeting the memory interface, both with the same adf_buffer_index.
+The fields in each malidp_buffer_config apply only to the targeted interface.
+This means that a post consisting of "n" input layers has at most (n * 2) + 1
+and at least "n" malidp_buffer_configs - up to 2 for each input layer, and a
+further one for any output buffer.
+
+Consider a simple case where a single buffer is to be displayed on the primary
+interface. There should be a single adf_buffer_config describing the physical
+memory, and selecting an overlay engine to use for the buffer.
+There should also be a matching malidp_buffer_config, targeting
+adf_buffer_index 0 and the interface ID of the primary interface. The other
+fields of the malidp_buffer_config can then be used to set how that buffer
+will be composed on screen.
+
+Source Cropping
+---------------
+Source cropping is expressed entirely in the adf_buffer_config, through a
+combination of the offset, width, height and pitch fields.
+Top and left cropping is specified by setting the offset fields:
+offset = (left_crop * bytes_per_pixel) + (top_crop * pitch)
+Right and bottom cropping is achieved by setting the width and height
+appropriately.
+
+Memory write-back
+-----------------
+To make use of the memory write-back interface, an output buffer must be
+supplied. This means an adf_buffer_config describing the memory to be written
+to, and a malidp_buffer_config with the MALIDP_FLAG_BUFFER_OUTPUT flag set,
+targeting the memory interface. For output buffers, the overlay engine is
+unimportant, but must be a valid overlay engine ID.
+The contents of the written buffer depend on the other buffer descriptions in
+the post. In general, any malidp_buffer_configs flagged as INPUT with the
+interface set to the memory write-back interface will be written to memory.
+If no INPUT buffers targeting the memory interface are provided, then the post
+will fail.
+
+The possible write-back operations are:
+  * Composition write-back
+    The result of composition (i.e. the image displayed on-screen) will be
+    written to memory if:
+    * The output buffer dimensions match those of the display mode
+    * All input buffers target both the primary and memory interfaces, and
+      the corresponding malidp_buffer_configs describe the same layout for
+      both interfaces.
+  * Scaled composition write-back
+    The composition result will be scaled before being written to memory if:
+    * All input buffers target both the primary and memory interfaces
+    * The corresponding malidp_buffer_configs differ only in a linear scaling
+      of all dimensions
+    NB: When scaling the composition, dimensions which are non-integer after
+    scaling should be truncated by the application.
+  * Selected layer write-back
+    A particular layer can be selected to be written to the output buffer if:
+    * It has a malidp_buffer_config targeting the memory interface
+    * No other layers have malidp_buffer_configs targeting the memory
+      interface
+    * The output buffer dimensions match the display rectangle of that
+      malidp_buffer_config
+    NB: In this case, no composition is conducted, meaning no alpha blending
+    (there is nothing to blend with!)
+
+There is one special case where the above can be ambiguous:
+Only a single layer is being displayed, with dimensions which match the
+display mode, and is also targeting the memory write-back interface.
+In this situation, the behavior is determined by comparing the display
+rectangles of the layer being written and the output buffer:
+  * the sizes do not match -> write the result of the composition
+  * the sizes match the mode -> write the result of the composition
+  * the sizes match (but not the mode) -> write only the layer matching the
+    input buffer
+
+Scaling
+-------
+Scaling is determined by comparing the display width and height specified in a
+malidp_buffer_config to the width and height of its corresponding
+adf_buffer_config - if the dimensions differ then a scaling operation is
+attempted.
+When a layer targets both interfaces (by having 2 malidp_buffer_configs) the
+display rectangles can differ, meaning that scaling can be set independently for
+each interface. In the case of "scaled composition write-back" above, this is
+the method used to indicate that the scaled composition should be written.
+
+Not all layers can be scaled, and only a limited number of total scaling
+operations can be conducted in a particular scene. This information can be
+queried from the ADF objects, stored in their custom data:
+ * A malidp ADF device exposes n_scalers which is the total number of
+   scale operations the device can carry out in a scene.
+ * A malidp ADF overlay engine exposes supports_scaling, which states whether
+   that overlay can be scaled.
+
+AFBC
+----
+The Mali-DP supports displaying buffers which are compressed using the AFBC
+compression algorithm.
+For an AFBC buffer, the adf_buffer_config must:
+  * Set the offset field to point to the start of the AFBC "header buffer"
+  * Set the width and height to the source width and height of the area to be
+    displayed, taking account of any cropping
+  * Use a format which is compatible with the AFBC decoder
+The corresponding malidp_buffer_config(s) must:
+  * Set the MALIDP_FLAG_AFBC flag
+  * If the compressed data uses the lossless YUV transform set
+    MALIDP_FLAG_AFBC_YTR
+  * Set the display top/left/width/height to the desired composed size of the
+    display region, after any scaling
+  * Set the afbc_crop_t/l/b/r fields for any required cropping (including
+    padding)
+The effect of all this is that the overall dimensions of the AFBC buffer are
+expressed as:
+  Width:  adf_buffer_config.w + afbc_crop_l + afbc_crop_r
+  Height: adf_buffer_config.h + afbc_crop_t + afbc_crop_b
+These overall width/height values must be aligned to 16 pixels as stated by the
+AFBC specification, however the individual components are only required to
+align to any chroma subsampling.
+
+Smart Layer
+-----------
+This feature is introduced by Mali-DP 550 display processor. It can be detected
+by the overlay engine custome data. If the n_supported_layers@malidp_adf_overlay_custom_data
+is more than 1, it means the smart layer is supported by this overlay engine and
+the field indicates how many smart layers are supported by this overlay engine.
+For smart layer overlay engine, multiple buffers can be mapped to it. But these
+buffers must be same format and non-overlapped. Please check the smart layer hardware
+spec for more detail about the smart layer limitation.
+
+Examples
+--------
+Below are some pseudo-code examples of different configurations, in all cases a
+640x480 display mode is assumed:
+
+Example 1 - Single buffer for display
+-------------------------------------
+adf_buffers = {
+	{ /* Input buffer, layer 1 */
+		.overlay_engine = MALIDP_OVERLAY_GRAPHICS1,
+		.format = RGB565,
+		.w = 640,
+		.h = 480,
+	},
+};
+
+malidp_buffers = {
+	{ /* Layer 1, primary interface descriptor */
+		.adf_buffer_index = 0,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		.display_width = 640,
+		.display_height = 480,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+};
+
+Example 2 - Compose 2 layers, display and write-back composition
+----------------------------------------------------------------
+adf_buffers = {
+	{ /* Input buffer, layer 1 */
+		.overlay_engine = MALIDP_OVERLAY_VIDEO,
+		.format = RGB888,
+		.w = 640,
+		.h = 480,
+	},
+	{ /* Input buffer, layer 2 */
+		.overlay_engine = MALIDP_OVERLAY_GRAPHICS1,
+		.format = RGB565,
+		.w = 320,
+		.h = 240,
+	},
+	{ /* Output buffer for writing to */
+		.overlay_engine = X, /* Don't care */
+		.format = XRGB8888,
+		/* The dimensions match the display mode */
+		.w = 640,
+		.h = 480,
+	},
+};
+
+malidp_buffers = {
+	{ /* Layer 1, primary interface descriptor */
+		.adf_buffer_index = 0,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		.display_width = 640,
+		.display_height = 480,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	{ /* Layer 1, memory interface descriptor */
+		.adf_buffer_index = 0,
+		.adf_intf_id = MALIDP_INTERFACE_MEMORY,
+		.display_width = 640,
+		.display_height = 480,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	{ /* Layer 2, primary interface descriptor */
+		.adf_buffer_index = 1,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		/* Centered on screen */
+		.display_top = 120,
+		.display_left = 160,
+		.display_width = 320,
+		.display_height = 240,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_LAYER,
+		.layer_alpha = 128, /* 50% transparent */
+	},
+	{ /* Layer 2, memory interface descriptor */
+		.adf_buffer_index = 1,
+		.adf_intf_id = MALIDP_INTERFACE_MEMORY,
+		/* Centered on screen */
+		.display_top = 120,
+		.display_left = 160,
+		.display_width = 320,
+		.display_height = 240,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_LAYER,
+		.layer_alpha = 128, /* 50% transparent */
+	},
+	{ /* Output buffer */
+		.adf_buffer_index = 2,
+		.adf_intf_id = MALIDP_INTERFACE_MEMORY,
+		/* No scaling */
+		.display_width = 640,
+		.display_height = 480,
+		.flags = MALIDP_FLAG_BUFFER_OUTPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+};
+
+Example 3 - Compose 2 layers, display and write-back downscaled composition
+---------------------------------------------------------------------------
+adf_buffers = {
+	{ /* Input buffer, layer 1 */
+		.overlay_engine = MALIDP_OVERLAY_VIDEO,
+		.format = RGB888,
+		.w = 640,
+		.h = 480,
+	},
+	{ /* Input buffer, layer 2 */
+		.overlay_engine = MALIDP_OVERLAY_GRAPHICS1,
+		.format = RGB565,
+		.w = 320,
+		.h = 240,
+	},
+	{ /* Output buffer for writing to */
+		.overlay_engine = X, /* Don't care */
+		.format = XRGB8888,
+		/* Downscale - The dimensions are 50% of the display mode */
+		.w = 320,
+		.h = 240,
+	},
+};
+
+malidp_buffers = {
+	{ /* Layer 1, primary interface descriptor */
+		.adf_buffer_index = 0,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		/* Full-size on primary interface */
+		.display_width = 640,
+		.display_height = 480,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	{ /* Layer 1, memory interface descriptor */
+		.adf_buffer_index = 0,
+		.adf_intf_id = MALIDP_INTERFACE_MEMORY,
+		/* Dimensions downscaled by 50% for memory interface */
+		.display_width = 320,
+		.display_height = 240,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	{ /* Layer 2, primary interface descriptor */
+		.adf_buffer_index = 1,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		/* Full-size, centered on primary interface */
+		.display_top = 120,
+		.display_left = 160,
+		.display_width = 320,
+		.display_height = 240,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_LAYER,
+		.layer_alpha = 128, /* 50% transparent */
+	},
+	{ /* Layer 2, memory interface descriptor */
+		.adf_buffer_index = 1,
+		.adf_intf_id = MALIDP_INTERFACE_MEMORY,
+		/* Dimensions downscaled by 50% for memory interface */
+		.display_top = 60,
+		.display_left = 80,
+		.display_width = 160,
+		.display_height = 120,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_LAYER,
+		.layer_alpha = 128, /* 50% transparent */
+	},
+	{ /* Output buffer */
+		.adf_buffer_index = 2,
+		.adf_intf_id = MALIDP_INTERFACE_MEMORY,
+		/* Dimensions match physical buffer */
+		.display_width = 320,
+		.display_height = 240,
+		.flags = MALIDP_FLAG_BUFFER_OUTPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+};
+
+Example 4 - Compose 2 layers for display, write-back a single stretched layer
+-----------------------------------------------------------------------------
+adf_buffers = {
+	{ /* Input buffer, layer 1 */
+		.overlay_engine = MALIDP_OVERLAY_VIDEO,
+		.format = RGB888,
+		.w = 640,
+		.h = 480,
+	},
+	{ /* Input buffer, layer 2 */
+		.overlay_engine = MALIDP_OVERLAY_GRAPHICS1,
+		.format = RGB565,
+		.w = 320,
+		.h = 240,
+	},
+	{ /* Output buffer for writing to */
+		.overlay_engine = X, /* Don't care */
+		.format = XRGB8888,
+		/* We will "stretch" layer 2 into this buffer */
+		.w = 640,
+		.h = 240,
+	},
+};
+
+malidp_buffers = {
+	{ /* Layer 1, primary interface descriptor */
+		.adf_buffer_index = 0,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		/* Full-size on primary interface */
+		.display_width = 640,
+		.display_height = 480,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	/* No memory interface descriptor for layer 1 - don't write it to memory */
+	{ /* Layer 2, primary interface descriptor */
+		.adf_buffer_index = 1,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		/* Full-size, centered on primary interface */
+		.display_top = 120,
+		.display_left = 160,
+		.display_width = 320,
+		.display_height = 240,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	{ /* Layer 2, memory interface descriptor */
+		.adf_buffer_index = 1,
+		.adf_intf_id = MALIDP_INTERFACE_MEMORY,
+		/* x-dimension doubled, for "stretch" */
+		.display_width = 640,
+		.display_height = 240,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	{ /* Output buffer */
+		.adf_buffer_index = 2,
+		.adf_intf_id = MALIDP_INTERFACE_MEMORY,
+		/* Dimensions match physical buffer */
+		.display_width = 640,
+		.display_height = 240,
+		.flags = MALIDP_FLAG_BUFFER_OUTPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+};
+
+Example 5 - Display 4 non-overlapped layers with smart layer overlay engine
+---------------------------------------------------------------------------
+adf_buffers = {
+	{ /* Input buffer, smart layer 1 */
+		.overlay_engine = MALIDP_OVERLAY_SMART1,
+		.format = ARGB8888,
+		.w = 320,
+		.h = 240,
+	},
+	{ /* Input buffer, smart layer 2 */
+		.overlay_engine = MALIDP_OVERLAY_SMART1,
+		.format = ARGB8888,
+		.w = 160,
+		.h = 120,
+	},
+	{ /* Input buffer, smart layer 3 */
+		.overlay_engine = MALIDP_OVERLAY_SMART1,
+		.format = ARGB8888,
+		.w = 160,
+		.h = 120,
+	},
+	{ /* Input buffer, smart layer 4 */
+		.overlay_engine = MALIDP_OVERLAY_SMART1,
+		.format = ARGB8888,
+		.w = 160,
+		.h = 120,
+	},
+};
+
+malidp_buffers = {
+	{ /* Smart Layer 1, primary interface descriptor */
+		.adf_buffer_index = 0,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		.display_top = 10,
+		.display_left = 20,
+		.display_width = 320,
+		.display_height = 240,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	{ /* Smart Layer 2, primary interface descriptor */
+		.adf_buffer_index = 1,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		.display_top = 270,
+		.display_left = 50,
+		.display_width = 160,
+		.display_height = 120,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	{ /* Smart Layer 3, primary interface descriptor */
+		.adf_buffer_index = 2,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		.display_top = 260,
+		.display_left = 240,
+		.display_width = 160,
+		.display_height = 120,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+	{ /* Smart Layer 4, primary interface descriptor */
+		.adf_buffer_index = 3,
+		.adf_intf_id = MALIDP_INTERFACE_PRIMARY,
+		.display_top = 30,
+		.display_left = 360,
+		.display_width = 160,
+		.display_height = 120,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE,
+	},
+};
diff --git a/Documentation/devicetree/bindings/video/mali-dp.txt b/Documentation/devicetree/bindings/video/mali-dp.txt
new file mode 100644
index 0000000..b64e725
--- /dev/null
+++ b/Documentation/devicetree/bindings/video/mali-dp.txt
@@ -0,0 +1,107 @@
+#
+# (C) COPYRIGHT 2014-2015 ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+
+* ARM Mali-DP Display devices
+
+Required properties:
+- compatible: Should be "arm,mali-dpxxx" where "xxx" is the product number
+- reg: Physical base address and length of the registers in the system
+- interrupts: the interrupt line numbers of the device in the system
+- interrupt-names: contains the names of the IRQs in the order they were
+provided in the "interrupts" property. Must contain: "SE", "DE".
+- clocks: should contain a phandle + clock-specifier pair for each clock
+entry in clock-names.
+- clock-names: should contain:
+      * "mclk": main clock
+      * "pclk": APB interface clock
+      * "aclk": AXI interface clock
+      * "pxclk": pixel clock
+
+Optional properties:
+- de-axi-burst-length: this is the burst length in bytes that the DE will use
+for reading data from the AXI interface.
+  Allowed parameters are: <1>, <2>, <4>, <8>, <16>, <32>, <64>, <128>, <256>
+- de-axi-poutstdcab: this is AXI outstanding transcations capability during
+  prefetch region. Valid value range 1 - 32. This property is only available
+  in DP550.
+- de-axi-outstanding-transactions: this is the number of outstanding
+transactions which can be generated by the DE. Valid values range 1-32.
+- de-axi-arqos-threshold-low: the DE input FIFO level low threshold. Valid value
+range 1 - (FIFO size - 1).
+- de-axi-arqos-threshold-high: the DE input FIFO level high threshold. Valid
+value range 1 - (FIFO size - 1) and should not be less than value indicated by
+de-axi-arqos-threshold-low.
+- de-axi-arqos-red: Close to underflow ARQOS value. Valid value range 0 - 15.
+- de-axi-arqos-green: Normal conditions ARQOS value. Valid value range 0 - 15.
+- se-axi-burst-length: this is the burst length in bytes  the SE will use for
+writing data to the AXI interface.
+  Allowed parameters are: <1>, <2>, <4>, <8>, <16>, <32>, <64>, <128>, <256>
+- se-axi-outstanding-transactions: this is the number of outstanding
+transactions which can be generated by the SE. Valid values range 1-32.
+- se-axi-awqos: identifier used by the AXI4 interface to establish a QoS mechanism.
+  Values must be in the range [0-15].
+- se-axi-awcache: memory type as defined by the AXI4 specification.
+  Values must be in the range [0-15].
+- rotmem: the size (in KB) of the available rotation memory
+
+The device node should contain one 'port' child node with one child 'endpoint'
+node, according to the bindings defined in Documentation/devicetree/bindings/
+media/video-interfaces.txt. The endpoint has the following required
+properties:
+- remote-endpoint: The phandle of the 'input' endpoint of the attached video
+transmitter device.
+
+Note: Each Mali-DP node should have an alias "malidpX" where X is a correct
+number in the "aliases" node.
+
+Example:
+
+aliases {
+	malidp0 = &dp0;
+};
+
+dp0: display {
+	compatible = "arm,mali-dp500";
+	reg = <0xf0040000 0x1000>;
+	interrupts = <0 39 4>, <0 40 4>;
+	interrupt-names = "SE", "DE";
+	clocks = <&db2oscclk2>, <&db2oscclk2>, <&db2oscclk0>, <&db2oscclk0>;
+	clock-names = "pxclk", "mclk", "aclk", "pclk";
+	de-axi-burst-length = <32>;
+	de-axi-outstanding-transactions = <15>;
+	de-axi-arqos-threshold-low = <112>;
+	de-axi-arqos-threshold-high = <128>;
+	de-axi-arqos-red = <1>;
+	de-axi-arqos-green = <0>;
+	se-axi-burst-length = <32>;
+	se-axi-outstanding-transactions = <15>;
+	se-axi-awqos = <15>;
+	se-axi-awcache = <0>;
+	rotmem = <64>;
+	port {
+		dp0_out: endpoint {
+			remote-endpoint = <&tx0_in>;
+		};
+	};
+};
+
+tx0: video-transmitter {
+	compatible = "foo,bar-tx";
+	port {
+		tx0_in: endpoint {
+			remote-endpoint = <&dp0_out>;
+		};
+	};
+};
diff --git a/Documentation/devicetree/bindings/video/senc_tx.txt b/Documentation/devicetree/bindings/video/senc_tx.txt
new file mode 100644
index 0000000..69352af
--- /dev/null
+++ b/Documentation/devicetree/bindings/video/senc_tx.txt
@@ -0,0 +1,51 @@
+#
+# (C) COPYRIGHT 2015 ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+
+* DRM slave encoder video-tx wrapper
+
+This node is for a virtual device which provides a shim to interface a DRM
+slave encoder with the video-tx framework.
+
+Required properties:
+- compatible: Should be "generic,slave_enc_video_tx"
+- i2c-slave: The phandle of the slave encoder's node
+
+Optional properties:
+- type: The connector type the transmitter uses
+  Allowed values: "HDMI", "DVI"
+- type-idx: The number of the connector of the given type, for instance
+  HDMI-0 and HDMI-1 would have type-idx = <0> and <1> respectively.
+
+The device node should contain one 'port' child node with one child 'endpoint'
+node according to the bindings defined in Documentation/devicetree/bindings/
+media/video-interfaces.txt. The endpoint has the following required
+properties:
+- remote-endpoint: The phandle of the 'output' endpoint of the attached video
+source device.
+
+Example:
+
+tx0: video_tx@0 {
+	compatible = "generic,slave_enc_video_tx";
+	reg = <0>;
+	i2c-slave = <&dvi2>;
+	type = "HDMI";
+	type-idx = <0>;
+	port {
+		tx0_in: endpoint {
+			remote-endpoint = <&dp0_out>;
+		};
+	};
+};
diff --git a/Documentation/devicetree/bindings/video/test_video_tx.txt b/Documentation/devicetree/bindings/video/test_video_tx.txt
new file mode 100644
index 0000000..9b1b0bc
--- /dev/null
+++ b/Documentation/devicetree/bindings/video/test_video_tx.txt
@@ -0,0 +1,37 @@
+#
+# (C) COPYRIGHT 2014 ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+
+* Dummy Video Transmitter driver
+
+Required properties:
+- compatible: Should be "generic,video_transmitter"
+
+The device node should contain one 'port' child node with one child 'endpoint'
+node, according to the bindings defined in Documentation/devicetree/bindings/
+media/video-interfaces.txt. The endpoint has the following required
+properties:
+- remote-endpoint: The phandle of the 'output' endpoint of the attached video
+source device.
+
+Example:
+
+tx0: video-transmitter {
+	compatible = "generic,video_transmitter";
+	port {
+		tx0_in: endpoint {
+			remote-endpoint = < ... >;
+		};
+	};
+};
diff --git a/drivers/video/adf/arm/Kbuild b/drivers/video/adf/arm/Kbuild
new file mode 100644
index 0000000..c78151b
--- /dev/null
+++ b/drivers/video/adf/arm/Kbuild
@@ -0,0 +1,32 @@
+#
+# (C) COPYRIGHT ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+mali-dp-y += malidp_drv.o \
+		malidp_sysfs.o \
+		malidp_se_device.o \
+		malidp_de_device.o \
+		malidp_adf.o \
+		malidp_adf_overlay.o \
+		malidp_adf_interface.o \
+		malidp_adf_format.o \
+		malidp_hw.o \
+		malidp_iommu.o \
+		malidp_of_graph.o \
+		product/malidp_product_dp500.o \
+		product/malidp_product_dp550.o
+
+ccflags-y += -Idrivers/staging/android  -I$(src) -I$(src)/product
+
+ccflags-$(CONFIG_MALI_DP_DEBUG) += -DDEBUG
+obj-$(CONFIG_MALI_DP) += mali-dp.o
diff --git a/drivers/video/adf/arm/Kconfig b/drivers/video/adf/arm/Kconfig
new file mode 100644
index 0000000..90f67d5
--- /dev/null
+++ b/drivers/video/adf/arm/Kconfig
@@ -0,0 +1,27 @@
+#
+# (C) COPYRIGHT ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+config MALI_DP
+	depends on ADF
+	select VIDEO_TX
+	tristate "Mali-DPxxx ADF driver"
+	---help---
+	  This Atomic Display Framework driver is for the Mali-DP series
+	  of display processors.
+
+config MALI_DP_DEBUG
+	depends on MALI_DP
+	bool "Mali-DP driver debug output enable"
+	---help---
+	  This enables debug output for the Mali-DP driver
diff --git a/drivers/video/adf/arm/Makefile b/drivers/video/adf/arm/Makefile
new file mode 100644
index 0000000..a5fd521
--- /dev/null
+++ b/drivers/video/adf/arm/Makefile
@@ -0,0 +1,35 @@
+#
+# (C) COPYRIGHT 2013-2014 ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+
+# linux build system bootstrap for out-of-tree module
+
+# default to building for the host
+ARCH ?= $(shell uname -m)
+
+ifeq ($(KDIR),)
+$(error Must specify KDIR to point to the kernel to target))
+endif
+
+all: mali-dp
+
+debug:
+	$(MAKE) ARCH=$(ARCH) -C $(KDIR) M=$(CURDIR) KBUILD_EXTRA_SYMBOLS=$(CURDIR)/../../video-tx/Module.symvers EXTRA_CFLAGS="-I$(CURDIR)/../../../../include -I$(KDIR)/drivers/staging/android" CONFIG_MALI_DP=m CONFIG_MALI_DP_DEBUG=y
+
+mali-dp:
+	$(MAKE) ARCH=$(ARCH) -C $(KDIR) M=$(CURDIR) KBUILD_EXTRA_SYMBOLS=$(CURDIR)/../../video-tx/Module.symvers EXTRA_CFLAGS="-I$(CURDIR)/../../../../include -I$(KDIR)/drivers/staging/android" CONFIG_MALI_DP=m
+
+clean:
+	$(MAKE) ARCH=$(ARCH) -C $(KDIR) M=$(CURDIR) clean
+
diff --git a/drivers/video/adf/arm/malidp_adf.c b/drivers/video/adf/arm/malidp_adf.c
new file mode 100644
index 0000000..dfe01c7
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_adf.c
@@ -0,0 +1,1556 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/device.h>
+#include <linux/slab.h>
+#include <video/adf.h>
+#include <sw_sync.h>
+
+#include <uapi/video/malidp_adf.h>
+
+#include "malidp_adf.h"
+#include "malidp_adf_format.h"
+#include "malidp_hw.h"
+#include "malidp_iommu.h"
+
+/*
+ * Fuzzyness applied to the common scaling factor to deal with cases where
+ * some dimensions are not divisible.
+ * The value has been calculated for the worst possible scaling factor, which
+ * is 7.5 (8 was used to make it more simple).
+ *
+ */
+#define SF_FRACT_FUZZYNESS 0x00006189 /* 0.381 in 16,16 binary fixed point */
+
+static int malidp_allow_attachments(struct malidp_device *dp_dev);
+static const struct adf_device_ops *malidp_get_dev_ops(
+		struct malidp_device *dp_dev);
+static void malidp_adf_state_free(struct adf_device *dev, void *driver_state);
+
+static void malidp_dump_malidp_buffer_config(struct malidp_device *dp_dev,
+		struct malidp_buffer_config *buf)
+{
+	dev_dbg(dp_dev->device, "malidp_buffer_config:\n");
+	dev_dbg(dp_dev->device, "  adf_buffer_index: %i\n",
+		buf->adf_buffer_index);
+	dev_dbg(dp_dev->device, "  adf_intf_id: %i\n", buf->adf_intf_id);
+	dev_dbg(dp_dev->device, "  display rect: (%i, %i) %ix%i\n",
+			buf->display_left, buf->display_top,
+			buf->display_width, buf->display_height);
+	dev_dbg(dp_dev->device, "  transform: %i\n", buf->transform);
+	dev_dbg(dp_dev->device, "  flags: 0x%08x\n", buf->flags);
+	dev_dbg(dp_dev->device, "  alpha_mode: %i\n", buf->alpha_mode);
+	dev_dbg(dp_dev->device, "  layer_alpha: %i\n", buf->layer_alpha);
+}
+
+static void malidp_dump_adf_buffer(struct malidp_device *dp_dev,
+		struct adf_buffer *buf)
+{
+	int i;
+
+	dev_dbg(dp_dev->device, "adf_buffer:\n");
+	dev_dbg(dp_dev->device, "  overlay_engine: %i (%s)\n",
+			buf->overlay_engine->base.id,
+			buf->overlay_engine->base.name);
+	dev_dbg(dp_dev->device, "  size: %ix%i\n", buf->w, buf->h);
+	dev_dbg(dp_dev->device, "  format: 0x%08x\n", buf->format);
+	dev_dbg(dp_dev->device, "  n_planes: %i\n", buf->n_planes);
+
+	dev_dbg(dp_dev->device, "  dma_bufs:");
+	for (i = 0; i < buf->n_planes; i++) {
+		dev_dbg(dp_dev->device, "    %p", buf->dma_bufs[i]);
+	}
+
+	dev_dbg(dp_dev->device, "  offset: ");
+	for (i = 0; i < buf->n_planes; i++) {
+		dev_dbg(dp_dev->device, "    %i", buf->offset[i]);
+	}
+
+	dev_dbg(dp_dev->device, "  pitch: ");
+	for (i = 0; i < buf->n_planes; i++) {
+		dev_dbg(dp_dev->device, "    %i", buf->pitch[i]);
+	}
+
+	dev_dbg(dp_dev->device, "  acquire_fence: %p\n", buf->acquire_fence);
+}
+
+/*
+ * These cleanup functions are copied from ADF core so that we can use
+ * them here. Some modifications have been made so that if we cleanup
+ * within our driver the ADF framework won't clean up again.
+ */
+static void malidp_adf_buffer_cleanup(struct adf_buffer *buf)
+{
+	size_t i;
+	for (i = 0; i < ARRAY_SIZE(buf->dma_bufs); i++)
+		if (buf->dma_bufs[i]) {
+			dma_buf_put(buf->dma_bufs[i]);
+			buf->dma_bufs[i] = NULL;
+		}
+
+	if (buf->acquire_fence) {
+		sync_fence_put(buf->acquire_fence);
+		buf->acquire_fence = NULL;
+	}
+}
+
+static void malidp_adf_buffer_mapping_cleanup(struct adf_buffer_mapping *mapping,
+		struct adf_buffer *buf, enum dma_data_direction dir)
+{
+	/*
+	 * calling adf_buffer_mapping_cleanup() is safe even if mapping is
+	 * uninitialized or partially-initialized, as long as it was
+	 * zeroed on allocation
+	 */
+	size_t i;
+
+	for (i = 0; i < ARRAY_SIZE(mapping->sg_tables); i++) {
+		if (mapping->sg_tables[i]) {
+			dma_buf_unmap_attachment(mapping->attachments[i],
+					mapping->sg_tables[i], dir);
+			mapping->sg_tables[i] = NULL;
+		}
+		if (mapping->attachments[i]) {
+			dma_buf_detach(buf->dma_bufs[i],
+					mapping->attachments[i]);
+			mapping->attachments[i] = NULL;
+		}
+	}
+}
+
+static void malidp_unmap_all_buffers(struct adf_device *dev,
+		struct adf_pending_post *post)
+{
+	struct malidp_driver_state *state = post->state;
+	struct malidp_device *dp_dev = to_malidp_device(dev);
+	int output_buffer = -1;
+	size_t i, j;
+
+	if (state->mw_cfg)
+		output_buffer = state->mw_cfg->mw_buf_index;
+
+	for (i = 0; i < post->config.n_bufs; i++) {
+		struct adf_buffer *buf = &post->config.bufs[i];
+		enum dma_data_direction dir;
+
+		if (i == output_buffer)
+			dir = DMA_FROM_DEVICE;
+		else
+			dir = DMA_TO_DEVICE;
+
+		if (dp_dev->iommu_domain) {
+			for (j = 0; j < buf->n_planes; j++) {
+				struct sg_table *sgt =
+					post->config.mappings[i].sg_tables[j];
+				if (sgt) {
+					dev_dbg(dp_dev->device, "%s: unmap sgt = %p\n", __func__, sgt);
+					malidp_iommu_unmap_sgt(dp_dev->iommu_domain,
+						       state->iommu_maps[i][j]);
+				}
+			}
+		}
+
+		malidp_adf_buffer_mapping_cleanup(&post->config.mappings[i],
+				&post->config.bufs[i], dir);
+		malidp_adf_buffer_cleanup(&post->config.bufs[i]);
+	}
+}
+
+void malidp_adf_post_cleanup(struct adf_device *dev,
+		struct adf_pending_post *post)
+{
+	BUG_ON(!post->state);
+
+	dev->ops->state_free(dev, post->state);
+
+	kfree(post->config.custom_data);
+	kfree(post->config.mappings);
+	kfree(post->config.bufs);
+	kfree(post);
+}
+
+static void malidp_adf_post(struct adf_device *dev, struct adf_post *cfg,
+		void *driver_state)
+{
+	struct malidp_device *dp_dev = to_malidp_device(dev);
+	struct malidp_driver_state *state = driver_state;
+	u8 primary_dpms_state = DRM_MODE_DPMS_ON;
+	int res;
+	int i;
+
+	dev_dbg(dp_dev->device, "%s : %s post\n", __func__, dev->base.name);
+
+	for (i = 0; i < state->n_intfs; i++) {
+		malidp_intf_prepare(state->intf_list[i], state->mw_cfg);
+		/*
+		 * Retrieve the state of the primary interface. This field
+		 * doesn't need to be protected because the blank()
+		 * implementation always flushes the worker thread for both
+		 * blank and unblank.
+		 */
+		if (malidp_adf_intf_get_dp_type(state->intf_list[i]) ==
+		    MALIDP_HW_INTF_PRIMARY)
+			primary_dpms_state = state->intf_list[i]->dpms_state;
+	}
+
+	/*
+	 * If the interface is off we have to just drop the frame.
+	 * We will commit the most recent one on un-blank
+	 */
+	if (primary_dpms_state == DRM_MODE_DPMS_ON) {
+		res = malidp_hw_commit(dp_dev->hw_dev, &state->hw_state);
+		if (res < 0) {
+			dev_err(dp_dev->device, "%s : post failed\n", __func__);
+			return;
+		}
+
+		for (i = 0; i < state->n_intfs; i++)
+			malidp_intf_wait(state->intf_list[i], dp_dev);
+	}
+}
+
+static void expand_smart_layer_bbox(struct malidp_hw_smart_layer_state *ls_state,
+		const struct malidp_hw_buffer *hw_buf)
+{
+	u16 top    = hw_buf->v_offset;
+	u16 left   = hw_buf->h_offset;
+	u16 bottom = top + hw_buf->cmp_rect.src_h;
+	u16 right  = left + hw_buf->cmp_rect.src_w;
+
+	if (ls_state->ls_bbox_top > top)
+		ls_state->ls_bbox_top = top;
+
+	if (ls_state->ls_bbox_left > left)
+		ls_state->ls_bbox_left = left;
+
+	if (ls_state->ls_bbox_bottom < bottom)
+		ls_state->ls_bbox_bottom = bottom;
+
+	if (ls_state->ls_bbox_right < right)
+		ls_state->ls_bbox_right = right;
+}
+
+static int malidp_adf_dp_buf_to_hw_buf(struct malidp_device *dp_dev,
+		struct malidp_buffer_config *dp_buf, struct malidp_hw_buffer *hw_buf,
+		struct malidp_hw_smart_layer_state *ls_state,
+		int verify)
+{
+	if (verify) {
+
+		/* Ignore the special buffer used to set the bbox */
+		if (dp_buf->flags == MALIDP_FLAG_SMART_BBOX) {
+			return 0;
+		}
+
+		if (dp_buf->flags != hw_buf->flags) {
+			dev_err(dp_dev->device, "%s : Buffer flags do not match, 0x%08x != 0x%08x\n",
+					__func__, dp_buf->flags, hw_buf->flags);
+			return -EINVAL;
+		}
+
+		if (dp_buf->transform != hw_buf->transform) {
+			dev_err(dp_dev->device, "%s : Buffer transforms do not match, 0x%08x != 0x%08x\n",
+					__func__, dp_buf->transform, hw_buf->transform);
+			return -EINVAL;
+		}
+
+		if (hw_buf->flags & MALIDP_FLAG_AFBC) {
+			if ((hw_buf->afbc_crop_l != dp_buf->afbc_crop_l) ||
+				(hw_buf->afbc_crop_r != dp_buf->afbc_crop_r) ||
+				(hw_buf->afbc_crop_t != dp_buf->afbc_crop_t) ||
+				(hw_buf->afbc_crop_b != dp_buf->afbc_crop_b)) {
+				dev_err(dp_dev->device, "%s: DP buffers disagree about AFBC crop\n",
+						__func__);
+				return -EINVAL;
+			}
+		}
+
+		if (hw_buf->alpha_mode != dp_buf->alpha_mode) {
+			dev_err(dp_dev->device, "%s: DP buffers disagree about alpha mode\n",
+					__func__);
+			return -EINVAL;
+		}
+
+		if (hw_buf->layer_alpha != dp_buf->layer_alpha) {
+			dev_err(dp_dev->device, "%s: DP buffers disagree about layer alpha\n",
+					__func__);
+			return -EINVAL;
+		}
+
+	} else {
+		hw_buf->flags = dp_buf->flags;
+		hw_buf->transform = dp_buf->transform;
+		if (dp_buf->transform != MALIDP_TRANSFORM_R0)
+			hw_buf->requirements |= MALIDP_LAYER_FEATURE_TRANSFORM;
+
+		if (dp_buf->flags & MALIDP_FLAG_AFBC) {
+			hw_buf->afbc_crop_l = dp_buf->afbc_crop_l;
+			hw_buf->afbc_crop_r = dp_buf->afbc_crop_r;
+			hw_buf->afbc_crop_t = dp_buf->afbc_crop_t;
+			hw_buf->afbc_crop_b = dp_buf->afbc_crop_b;
+			hw_buf->requirements |= MALIDP_LAYER_FEATURE_AFBC;
+		}
+
+		hw_buf->alpha_mode = dp_buf->alpha_mode;
+		hw_buf->layer_alpha = dp_buf->layer_alpha;
+
+		hw_buf->h_offset = dp_buf->display_left;
+		hw_buf->v_offset = dp_buf->display_top;
+
+		if (hw_buf->hw_layer->type == MALIDP_HW_LAYER_SMART) {
+			hw_buf->ls_rect_idx = ls_state->n_smart_layers;
+			ls_state->n_smart_layers++;
+
+			if (!ls_state->ls_bbox_from_user)
+				expand_smart_layer_bbox(ls_state, hw_buf);
+
+			ls_state->ls_hw_layer = hw_buf->hw_layer;
+		}
+	}
+
+	return 0;
+}
+
+static void malidp_adf_remap_mw_buf(struct adf_buffer_mapping *map,
+		struct adf_buffer *adf_buf, struct malidp_hw_buffer *hw_buf)
+{
+	int i;
+
+	for (i = 0; i < adf_buf->n_planes; i++) {
+		dma_buf_unmap_attachment(map->attachments[i],
+			map->sg_tables[i], DMA_TO_DEVICE);
+		map->sg_tables[i] = dma_buf_map_attachment(map->attachments[i],
+					DMA_FROM_DEVICE);
+	}
+	for (i = 0; i < adf_buf->n_planes; i++) {
+		hw_buf->addr[i] = sg_dma_address(map->sg_tables[i]->sgl) + adf_buf->offset[i];
+		hw_buf->pitch[i] = adf_buf->pitch[i];
+	}
+}
+
+struct malidp_adf_transposed_config {
+	int *n_dp_bufs;
+	struct malidp_buffer_config ***buf_lists;
+};
+
+/* We get the scaling factor in a binary fixed point 16,16 representation */
+static inline u32 get_fp_sf(u16 src, u16 dst)
+{
+	u32 tmp = dst << 16;
+
+	return (tmp / src);
+}
+
+/* Is fp1 greater than fp2 ? */
+static inline bool check_fp_gt(u32 fp1, u32 fp2)
+{
+	if (fp1 > fp2)
+		return true;
+	else
+		return false;
+}
+
+static inline u32 get_fp_diff(u32 big, u32 small)
+{
+	return (big - small);
+}
+
+static inline u32 fp_get_integer(u32 fp)
+{
+	return (fp >> 16);
+}
+
+static inline u32 fp_get_fractional(u32 fp)
+{
+	return (fp & 0xffff);
+}
+
+static bool sf_compare_fuzzyness(u32 sf1, u32 sf2)
+{
+	u32 diff;
+
+	/* Find the difference between the highest and the smallest sf */
+	if (check_fp_gt(sf2, sf1))
+		diff = get_fp_diff(sf2, sf1);
+	else
+		diff = get_fp_diff(sf1, sf2);
+
+	if (check_fp_gt(SF_FRACT_FUZZYNESS, diff))
+		return true;
+	else
+		return false;
+}
+
+static bool check_scaling_in_dp_buf(struct malidp_device *dp_dev,
+				    struct malidp_buffer_config **dp_bufs,
+				    int n_dp_bufs, u32 csf_w,
+				    u32 csf_h)
+{
+	int i;
+	int dp_buf_disp = -1, dp_buf_mem = -1;
+	enum malidp_hw_intf_type dp_type;
+	u32 tmp_sf;
+
+	/*
+	 * Every buffer has to have 2 DP buffers, one must target the display
+	 * and the other one the memory. The top and left values need to be
+	 * scaled by the same scaling factor as the width and the height.
+	 */
+
+	if (n_dp_bufs != 2)
+		return false;
+
+	for (i = 0; i < n_dp_bufs; i++) {
+		struct adf_interface *adf_intf;
+
+		adf_intf = idr_find(&dp_dev->adf_dev.interfaces,
+				    dp_bufs[i]->adf_intf_id);
+		dp_type = malidp_adf_intf_get_dp_type(adf_intf);
+		if (dp_type == MALIDP_HW_INTF_MEMORY)
+			dp_buf_mem = i;
+		else
+			dp_buf_disp = i;
+	}
+
+	/*
+	 * Something very wrong has happened if we don't get a memory and
+	 * a display buffer at this point.
+	 */
+	BUG_ON(dp_buf_mem == -1 ||  dp_buf_disp == -1);
+
+	if ((dp_bufs[dp_buf_disp]->display_top == 0) &&
+	    (dp_bufs[dp_buf_mem]->display_top != 0)) {
+		return false;
+	} else if (dp_bufs[dp_buf_disp]->display_top != 0) {
+		tmp_sf = get_fp_sf(dp_bufs[dp_buf_disp]->display_top,
+					dp_bufs[dp_buf_mem]->display_top);
+		if (!sf_compare_fuzzyness(tmp_sf, csf_h))
+			return false;
+	}
+
+	if ((dp_bufs[dp_buf_disp]->display_left == 0) &&
+	    (dp_bufs[dp_buf_mem]->display_left != 0)) {
+		return false;
+	} else if (dp_bufs[dp_buf_disp]->display_left != 0) {
+		tmp_sf = get_fp_sf(dp_bufs[dp_buf_disp]->display_left,
+					dp_bufs[dp_buf_mem]->display_left);
+		if (!sf_compare_fuzzyness(tmp_sf, csf_w))
+			return false;
+	}
+
+	return true;
+}
+
+static bool composition_is_scaled(struct malidp_device *dp_dev,
+			struct malidp_hw_buffer *hw_bufs,
+			struct malidp_adf_transposed_config *transpose,
+			int nbufs, int output_buffer, u32 mode_h,
+			u32 mode_w)
+{
+	struct malidp_hw_buffer *hw_buf;
+	/* common scaling factor (csf) */
+	u32 csf_w_max = 0, csf_h_max = 0;
+	u32 csf_w_min = 0, csf_h_min = 0;
+	u32 tmp_csf_h, tmp_csf_w;
+	bool first_sf = true;
+	int i;
+
+	/*
+	 * Make sure all the layers need to be scaled to memory and not to
+	 * display, and they share the same scaling factor.
+	 *
+	 * In this loop we only get the minimum and the maximum.
+	 */
+	for (i = 0; i < nbufs; i++) {
+		hw_buf = &hw_bufs[i];
+
+		if (i == output_buffer)
+			continue;
+
+		if (hw_buf->mw_scaling_enable && !hw_buf->cmp_scaling_enable) {
+			tmp_csf_h = get_fp_sf(hw_buf->mw_rect.src_h,
+					    hw_buf->mw_rect.dest_h);
+			tmp_csf_w = get_fp_sf(hw_buf->mw_rect.src_w,
+					    hw_buf->mw_rect.dest_w);
+
+			if (first_sf) {
+				csf_w_max = tmp_csf_w;
+				csf_w_min = tmp_csf_w;
+				csf_h_max = tmp_csf_h;
+				csf_h_min = tmp_csf_h;
+			} else {
+				if (check_fp_gt(tmp_csf_w, csf_w_max))
+					csf_w_max = tmp_csf_w;
+				if (check_fp_gt(csf_w_min, tmp_csf_w))
+					csf_w_min = tmp_csf_w;
+				if (check_fp_gt(tmp_csf_h, csf_h_max))
+					csf_h_max = tmp_csf_h;
+				if (check_fp_gt(csf_h_min, tmp_csf_h))
+					csf_h_min = tmp_csf_h;
+			}
+
+			if (!check_scaling_in_dp_buf(dp_dev,
+			      transpose->buf_lists[i], transpose->n_dp_bufs[i],
+			      tmp_csf_w, tmp_csf_h))
+				return false;
+
+			first_sf = false;
+		} else {
+			return false;
+		}
+	}
+
+	/* Check the fuzzyness of the max and min sf for each dimensions */
+	if (!sf_compare_fuzzyness(csf_w_max, csf_w_min))
+		return false;
+
+	if (!sf_compare_fuzzyness(csf_h_max, csf_h_min))
+		return false;
+
+	/*
+	 * We still have to validate that the output buffer has the dimensions
+	 * suitable to fit the scaled composition.
+	 */
+	BUG_ON(output_buffer == -1);
+
+	tmp_csf_w = get_fp_sf(mode_w, hw_bufs[output_buffer].natural_w);
+	if (!sf_compare_fuzzyness(tmp_csf_w, csf_w_max) &&
+	    !sf_compare_fuzzyness(tmp_csf_w, csf_w_min))
+		return false;
+
+	tmp_csf_h = get_fp_sf(mode_h, hw_bufs[output_buffer].natural_h);
+	if (!sf_compare_fuzzyness(tmp_csf_h, csf_h_max) &&
+	    !sf_compare_fuzzyness(tmp_csf_h, csf_h_min))
+		return false;
+
+	dev_dbg(dp_dev->device,
+		"found scaling factors: w: 0x%04x.%04x, h: 0x%04x.%04x\n",
+		fp_get_integer(csf_w_max), fp_get_fractional(csf_w_max),
+		fp_get_integer(csf_h_max), fp_get_fractional(csf_h_max));
+
+	return true;
+}
+
+static bool composition_is_written_out(struct malidp_hw_buffer *hw_bufs,
+				     int nbufs, int output_buffer, u32 mode_h,
+				     u32 mode_w)
+{
+	bool write_out_composition = false;
+	int i;
+
+	/*
+	 * If only 2 ADF buffers are used, one input buffer and one output
+	 * buffer, we need to tell the difference between writing-out/scaling
+	 * the result of the composition and writing-out/scaling only the
+	 * input buffer by comparing the display sizes:
+	 *  - the sizes do not match -> write the result of the composition
+	 *  - the sizes match the mode -> write the result of the composition
+	 *  - the sizes match (but not the mode) -> write only the layer
+	 *    matching the input buffer
+	 */
+	if ((nbufs == 2) && (output_buffer != -1)) {
+		struct malidp_hw_buffer *out_hw_buf = &hw_bufs[output_buffer];
+		struct malidp_hw_buffer *in_hw_buf = NULL;
+		int input_buffer;
+		write_out_composition = false;
+
+		input_buffer = !output_buffer;
+
+		in_hw_buf = &hw_bufs[input_buffer];
+
+		/* Buffer sizes don't match */
+		if ((in_hw_buf->mw_rect.dest_w != out_hw_buf->natural_w) ||
+		    (in_hw_buf->mw_rect.dest_h != out_hw_buf->natural_h)) {
+			write_out_composition = true;
+
+		/* Buffer sizes match the mode */
+		} else if ((in_hw_buf->mw_rect.dest_w == out_hw_buf->natural_w) &&
+				(in_hw_buf->mw_rect.dest_h == out_hw_buf->natural_h) &&
+				(out_hw_buf->cmp_rect.src_w == mode_w) &&
+				(out_hw_buf->cmp_rect.src_h == mode_h)) {
+			write_out_composition = true;
+		}
+	} else if (output_buffer != -1) {
+		struct malidp_hw_buffer *hw_buf;
+		write_out_composition = true;
+
+		for (i = 0; i < nbufs; i++) {
+			hw_buf = &hw_bufs[i];
+			if (!(hw_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT) &&
+			    !(hw_buf->write_out_enable))
+				write_out_composition = false;
+		}
+	}
+
+	return write_out_composition;
+}
+
+static bool check_rect_sizes(struct malidp_hw_scale_rect *rect)
+{
+	if (rect->src_w == 0 || rect->src_h == 0 || rect->dest_w == 0 ||
+	    rect->dest_h == 0)
+		return false;
+
+	return true;
+}
+
+static void reset_smart_layer_state(struct malidp_hw_smart_layer_state *ls_state)
+{
+	memset(ls_state, 0, sizeof(struct malidp_hw_smart_layer_state));
+	ls_state->ls_bbox_top  = USHRT_MAX;
+	ls_state->ls_bbox_left = USHRT_MAX;
+}
+
+static int malidp_adf_build_hw_bufs(struct malidp_device *dp_dev,
+		struct adf_post *cfg, struct malidp_adf_transposed_config *transpose,
+		struct malidp_driver_state *state)
+{
+	struct malidp_hw_buffer *hw_bufs = state->hw_state.bufs;
+	struct malidp_hw_smart_layer_state *ls_state = &state->hw_state.ls_state;
+	enum malidp_hw_intf_type dp_type;
+	struct malidp_buffer_config *dp_buf;
+	struct malidp_buffer_config **list;
+	struct malidp_hw_buffer *hw_buf;
+	struct adf_interface *adf_intf;
+	struct adf_buffer *adf_buf;
+	struct adf_buffer_mapping *map;
+	u32 mode_w = 0;
+	u32 mode_h = 0;
+	int output_buffer = -1;
+	int i, j = 0;
+	int res = -EINVAL;
+
+	/*
+	 * We make no guarantees that this configuration is possible,
+	 * we just set the parameters userspace asked for.
+	 * hw_validate will make the decision about whether we can
+	 * fulfil it
+	 */
+
+	/* Reset the smart layer state */
+	reset_smart_layer_state(ls_state);
+
+	/* First do the common things for each ADF buffer */
+	for (i = 0; i < cfg->n_bufs; i++) {
+		list = transpose->buf_lists[i];
+		adf_buf = &cfg->bufs[i];
+		map = &cfg->mappings[i];
+		hw_buf = &hw_bufs[i];
+
+		malidp_dump_adf_buffer(dp_dev, adf_buf);
+
+		hw_buf->fmt = adf_buf->format;
+		hw_buf->n_planes = adf_buf->n_planes;
+
+		/* These may be ignored/overriden for output buffers */
+		hw_buf->hw_layer = malidp_adf_ovr_get_hw_layer(adf_buf->overlay_engine);
+		if (!hw_buf->hw_layer) {
+			dev_err(dp_dev->device, "%s : Couldn't get hw layer for ADF buffer %i\n",
+					__func__, i);
+			res = -EINVAL;
+			goto error;
+		}
+
+		hw_buf->natural_w = adf_buf->w;
+		hw_buf->natural_h = adf_buf->h;
+
+		/* The source size for the scaling rectangles is always the
+		 * size of the buffers in memory.
+		 */
+		hw_buf->cmp_rect.src_w = adf_buf->w;
+		hw_buf->cmp_rect.src_h = adf_buf->h;
+		hw_buf->mw_rect.src_w = adf_buf->w;
+		hw_buf->mw_rect.src_h = adf_buf->h;
+
+		/* Default values for the destination rectangles. The DP buffer
+		 * is not yet available here.
+		 */
+		hw_buf->cmp_rect.dest_w = adf_buf->w;
+		hw_buf->cmp_rect.dest_h = adf_buf->h;
+		hw_buf->mw_rect.dest_w = adf_buf->w;
+		hw_buf->mw_rect.dest_h = adf_buf->h;
+
+		/* Normally, an ADF has less than 3 DP buffers */
+		if (transpose->n_dp_bufs[i] > 2) {
+			for (res = 0; res < transpose->n_dp_bufs[i]; res++)
+				if (list[res]->flags ==
+						MALIDP_FLAG_SMART_BBOX) {
+					res = 0;
+					break;
+				}
+			/* For bindingbox, it can have 3 DP buffers */
+			if (res || transpose->n_dp_bufs[i] > 3) {
+				dev_err(dp_dev->device, "%s : A maximum of %d DP buffers are allowed for this ADF buffer\n",
+						__func__, (res == 0) ? 3 : 2);
+				res = -EINVAL;
+				goto error;
+			}
+		}
+
+		/* Then combine the list of DP bufs into a single hw buf */
+		for (j = 0; j < transpose->n_dp_bufs[i]; j++) {
+			dp_buf = list[j];
+
+			malidp_dump_malidp_buffer_config(dp_dev, dp_buf);
+
+			if (dp_buf->flags == MALIDP_FLAG_SMART_BBOX) {
+				/* These fields of dp_buf are used for bbox test */
+				ls_state->ls_bbox_argb = dp_buf->alpha_mode;
+				if (dp_buf->display_top > 0 ||
+				    dp_buf->display_left > 0 ||
+				    dp_buf->display_height > 0 ||
+				    dp_buf->display_width > 0) {
+					ls_state->ls_bbox_top = dp_buf->display_top;
+					ls_state->ls_bbox_left = dp_buf->display_left;
+					ls_state->ls_bbox_bottom = dp_buf->display_top + dp_buf->display_height;
+					ls_state->ls_bbox_right = dp_buf->display_left + dp_buf->display_width;
+					ls_state->ls_bbox_from_user = true;
+				}
+				continue;
+			}
+
+			/*
+			 * If this is the first time we hit this ADF buffer, then
+			 * translate the dp_buf to a hw_buf.
+			 * If not, verify that this dp_buf is compatible with the
+			 * other one
+			 */
+			res = malidp_adf_dp_buf_to_hw_buf(dp_dev, dp_buf, hw_buf, ls_state, j);
+			if (res)
+				goto error;
+
+			if (hw_buf->hw_layer->type == MALIDP_HW_LAYER_SMART)
+				ls_state->ls_hw_buf_idx[hw_buf->ls_rect_idx] = i;
+
+			adf_intf = idr_find(&dp_dev->adf_dev.interfaces, dp_buf->adf_intf_id);
+			dp_type = malidp_adf_intf_get_dp_type(adf_intf);
+
+			switch (dp_type) {
+			case MALIDP_HW_INTF_MEMORY:
+			{
+				if (hw_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT) {
+
+					if (transpose->n_dp_bufs[i] > 1) {
+						dev_err(dp_dev->device, "%s : More than one DP buffer uses the output ADF buffer\n",
+								__func__);
+						res = -EINVAL;
+						goto error;
+					}
+
+					if (output_buffer >= 0) {
+						dev_err(dp_dev->device, "%s : More than one output buffer specified\n", __func__);
+						res = -EINVAL;
+						goto error;
+					}
+
+					/*
+					 * ADF will map all buffers using DMA_TO_DEVICE but
+					 * output buffers need to be mapped as DMA_FROM_DEVICE.
+					 */
+					malidp_adf_remap_mw_buf(map, adf_buf, hw_buf);
+
+					output_buffer = i;
+					hw_buf->hw_layer = NULL;
+				} else {
+					hw_buf->write_out_enable = true;
+					if (hw_buf->transform & MALIDP_TRANSFORM_R90) {
+						hw_buf->mw_rect.src_w = hw_buf->natural_h;
+						hw_buf->mw_rect.src_h = hw_buf->natural_w;
+						hw_buf->mw_rect.dest_w = dp_buf->display_height;
+						hw_buf->mw_rect.dest_h = dp_buf->display_width;
+					} else {
+						hw_buf->mw_rect.dest_w = dp_buf->display_width;
+						hw_buf->mw_rect.dest_h = dp_buf->display_height;
+					}
+					if ((hw_buf->mw_rect.dest_h != hw_buf->mw_rect.src_h) ||
+					    (hw_buf->mw_rect.dest_w != hw_buf->mw_rect.src_w)) {
+						hw_buf->mw_scaling_enable = true;
+						if (!check_rect_sizes(&hw_buf->mw_rect)) {
+							dev_err(dp_dev->device, "wrong mw rect sizes\n");
+							res = -EINVAL;
+							goto error;
+						}
+					}
+				}
+
+				break;
+			}
+			case MALIDP_HW_INTF_PRIMARY:
+			{
+				if (hw_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT) {
+					dev_err(dp_dev->device, "%s : Output buffers are only supported for the memory interface\n",
+							__func__);
+					res = -EINVAL;
+					goto error;
+				}
+
+				if (j && !hw_buf->write_out_enable) {
+					dev_err(dp_dev->device, "%s : Multiple DP buffer configs provided for ADF buffer %i, interface %i\n",
+							__func__, i, dp_buf->adf_intf_id);
+					res = -EINVAL;
+					goto error;
+				}
+
+				if (hw_buf->transform & MALIDP_TRANSFORM_R90) {
+					hw_buf->cmp_rect.src_w = hw_buf->natural_h;
+					hw_buf->cmp_rect.src_h = hw_buf->natural_w;
+					hw_buf->cmp_rect.dest_w = dp_buf->display_height;
+					hw_buf->cmp_rect.dest_h = dp_buf->display_width;
+				} else {
+					hw_buf->cmp_rect.src_w = hw_buf->natural_w;
+					hw_buf->cmp_rect.src_h = hw_buf->natural_h;
+					hw_buf->cmp_rect.dest_w = dp_buf->display_width;
+					hw_buf->cmp_rect.dest_h = dp_buf->display_height;
+				}
+
+				if ((hw_buf->cmp_rect.src_w != hw_buf->cmp_rect.dest_w) ||
+						(hw_buf->cmp_rect.src_h != hw_buf->cmp_rect.dest_h)) {
+					/*
+					 * With the current HW, a layer that needs to be scaled
+					 * for the composition will have to be scaled for the
+					 * memory as well.
+					 */
+					hw_buf->cmp_scaling_enable = true;
+					hw_buf->mw_scaling_enable = true;
+					hw_buf->requirements |= MALIDP_LAYER_FEATURE_SCALING;
+					hw_buf->mw_rect.dest_w = hw_buf->cmp_rect.dest_w;
+					hw_buf->mw_rect.dest_h = hw_buf->cmp_rect.dest_h;
+					if (!check_rect_sizes(&hw_buf->cmp_rect)) {
+						dev_err(dp_dev->device, "wrong cmp rect sizes\n");
+						res = -EINVAL;
+						goto error;
+					}
+				}
+
+				mode_w = adf_intf->current_mode.hdisplay;
+				mode_h = adf_intf->current_mode.vdisplay;
+				if (((hw_buf->cmp_rect.dest_w + hw_buf->h_offset) > mode_w) ||
+						((hw_buf->cmp_rect.dest_h + hw_buf->v_offset) > mode_h)) {
+					dev_err(dp_dev->device, "%s : Buffer falls outside of display region\n", __func__);
+					res = -ENOSPC;
+					goto error;
+				}
+
+				break;
+			}
+			default:
+				BUG();
+			}
+		}
+
+		for (j = 0; j < adf_buf->n_planes; j++) {
+			if (dp_dev->iommu_domain) {
+				enum dma_data_direction dir;
+				if (output_buffer == i)
+					dir = DMA_FROM_DEVICE;
+				else
+					dir = DMA_TO_DEVICE;
+
+				state->iommu_maps[i][j] = malidp_iommu_map_sgt(dp_dev->iommu_domain,
+									       map->sg_tables[j], dir);
+				if (!state->iommu_maps[i][j]) {
+					dev_err(dp_dev->device, "could not map sg table in the iommu");
+					res = -ENOMEM;
+					goto error;
+				}
+				hw_buf->addr[j] = malidp_iommu_dma_addr(dp_dev->iommu_domain,
+					state->iommu_maps[i][j]) + adf_buf->offset[j];
+			} else {
+				hw_buf->addr[j] = sg_dma_address(map->sg_tables[j]->sgl) +
+						adf_buf->offset[j];
+			}
+			hw_buf->pitch[j] = adf_buf->pitch[j];
+		}
+	}
+
+	/*
+	 * There is no output buffer. We cannot scale to memory or write out to
+	 * memory.
+	 */
+	if (output_buffer == -1) {
+		for (i = 0; i < cfg->n_bufs; i++) {
+			if (hw_bufs[i].write_out_enable) {
+				dev_err(dp_dev->device,
+				  "cannot write out to memory with no output buffer");
+				res = -EINVAL;
+				goto error;
+			}
+		}
+	} else {
+		hw_bufs[output_buffer].mw_scaling_enable =
+			composition_is_scaled(dp_dev, hw_bufs, transpose,
+				cfg->n_bufs, output_buffer, mode_h, mode_w);
+		if (hw_bufs[output_buffer].mw_scaling_enable) {
+			/* If the composition is scaled the src dimensions
+			 * always have to match the mode
+			 */
+			hw_bufs[output_buffer].mw_rect.src_h = mode_h;
+			hw_bufs[output_buffer].mw_rect.src_w = mode_w;
+		}
+
+		hw_bufs[output_buffer].write_out_enable =
+			composition_is_written_out(hw_bufs, cfg->n_bufs,
+					output_buffer, mode_h, mode_w);
+
+		/*
+		 * Check that if a layer is written to memory it fits in the
+		 * output buffer.
+		 */
+		if (!hw_bufs[output_buffer].write_out_enable) {
+			u16 out_w = hw_bufs[output_buffer].natural_w;
+			u16 out_h = hw_bufs[output_buffer].natural_h;
+			for (i = 0; i < cfg->n_bufs; i++) {
+				u16 in_dst_w = hw_bufs[i].mw_rect.dest_w;
+				u16 in_dst_h = hw_bufs[i].mw_rect.dest_h;
+
+				if (i == output_buffer)
+					continue;
+
+				if (hw_bufs[i].mw_scaling_enable)
+					hw_bufs[i].requirements |=
+						MALIDP_LAYER_FEATURE_SCALING;
+
+				if (hw_bufs[i].write_out_enable &&
+					((in_dst_w != out_w) ||
+					(in_dst_h != out_h))) {
+					dev_err(dp_dev->device,
+						"output buffer is too small");
+					res = -EINVAL;
+					goto error;
+				}
+			}
+		}
+	}
+
+	/* Clipping the smart layers' v/h offset with the bbox */
+	if (ls_state->ls_hw_layer) {
+		for (i = 0; i < cfg->n_bufs; i++) {
+			if (hw_bufs[i].hw_layer &&
+			    hw_bufs[i].hw_layer->type == MALIDP_HW_LAYER_SMART) {
+				if (hw_bufs[i].v_offset >= ls_state->ls_bbox_top)
+					hw_bufs[i].v_offset -= ls_state->ls_bbox_top;
+				else {
+					dev_err(dp_dev->device, "%s : Invalid bbox top %d for active rect top %d\n",
+						__func__, ls_state->ls_bbox_top, hw_bufs[i].v_offset);
+					res = -EINVAL;
+					goto error;
+				}
+				if (hw_bufs[i].h_offset >= ls_state->ls_bbox_left)
+					hw_bufs[i].h_offset -= ls_state->ls_bbox_left;
+				else {
+					dev_err(dp_dev->device, "%s : Invalid bbox left %d for active rect left %d\n",
+						__func__, ls_state->ls_bbox_left, hw_bufs[i].h_offset);
+					res = -EINVAL;
+					goto error;
+				}
+			}
+		}
+	}
+
+	return 0;
+
+error:
+	if (dp_dev->iommu_domain) {
+		for (i = 0; i < cfg->n_bufs; i++) {
+			adf_buf = &cfg->bufs[i];
+			for (j = 0; j < adf_buf->n_planes; j++)
+				malidp_iommu_unmap_sgt(dp_dev->iommu_domain,
+						state->iommu_maps[i][j]);
+		}
+	}
+	dev_err(dp_dev->device, "%s : Validation failed for ADF buffer %i (DP buffer %i)\n",
+			__func__, i, j);
+	return res;
+}
+
+static int malidp_adf_non_afbc_validate(struct malidp_device *dp_dev,
+					struct adf_buffer *adf_buf,
+					struct malidp_buffer_config *dp_buf)
+{
+	int res = 0;
+	uint32_t i;
+
+	/* Pitch alignment matters for non-AFBC buffers */
+	for (i = 0; i < adf_buf->n_planes; i++) {
+		if (adf_buf->pitch[i] % 8) {
+			dev_err(dp_dev->device, "%s : all buffer pitches must be 64-bit aligned\n", __func__);
+			res = -EINVAL;
+		}
+	}
+
+	if (dp_buf->flags & MALIDP_FLAG_AFBC_YTR) {
+		dev_err(dp_dev->device, "%s : YTR is not valid for non-AFBC buffers\n",
+			__func__);
+		res = -EINVAL;
+	}
+
+	if (dp_buf->flags & MALIDP_FLAG_AFBC_SPLITBLK) {
+		dev_err(dp_dev->device, "%s : Split block is not valid for non-AFBC buffers\n",
+			__func__);
+		res = -EINVAL;
+	}
+
+	if (malidp_adf_format_is_afbc_only(adf_buf->format)) {
+		dev_err(dp_dev->device, "%s : format 0x%08x is only valid for AFBC buffers\n",
+			__func__, adf_buf->format);
+		res = -EINVAL;
+	}
+
+	return res;
+}
+
+static bool malidp_custom_data_size_valid(struct malidp_custom_data *blob,
+		size_t blob_size)
+{
+	size_t expected_size = sizeof(struct malidp_custom_data);
+
+	if (!blob)
+		return false;
+
+	/* First make sure there's space to access the other fields */
+	if (blob_size < expected_size)
+		return false;
+
+	/* Add on space for the buffers */
+	expected_size += blob->sizeof_malidp_buffer_config *
+		blob->n_malidp_buffer_configs;
+
+	return blob_size == expected_size;
+}
+
+static int malidp_adf_validate(struct adf_device *dev, struct adf_post *cfg,
+			void **driver_state)
+{
+	struct malidp_device *dp_dev = to_malidp_device(dev);
+	struct malidp_custom_data *blob =
+		(struct malidp_custom_data *)cfg->custom_data;
+	struct malidp_adf_transposed_config transpose = {0};
+	struct adf_interface *intf;
+	struct adf_buffer *adf_buf;
+	struct malidp_driver_state *state;
+	size_t state_size;
+	uint32_t n_input_buffers = 0;
+	int i, j;
+	int res = 0;
+
+	dev_dbg(dp_dev->device, "%s : %s validate\n", __func__,
+			dev->base.name);
+
+#ifdef CONFIG_PM_SLEEP
+	if (atomic_read(&dp_dev->suspending)) {
+		dev_dbg(dp_dev->device, "%s: Pending system suspend\n", __func__);
+		return -EAGAIN;
+	}
+#endif /* CONFIG_PM_SLEEP */
+
+	if (!malidp_custom_data_size_valid(blob, cfg->custom_data_size)) {
+		dev_err(dp_dev->device, "%s : invalid custom data size: %zu\n",
+			__func__, cfg->custom_data_size);
+		dev_err(dp_dev->device, "%s : could be user/kernel header mismatch?\n",
+			__func__);
+		return -EINVAL;
+	}
+
+	if (cfg->n_bufs == 0) {
+		dev_err(dp_dev->device, "%s: no ADF buffers found\n",
+			__func__);
+		return -EINVAL;
+	}
+
+	if (blob->n_malidp_buffer_configs == 0) {
+		dev_err(dp_dev->device, "%s: no DP buffers found\n",
+			__func__);
+		return -EINVAL;
+	}
+
+	*driver_state = NULL;
+
+	state_size = sizeof(*state) + sizeof(*state->hw_state.bufs) * cfg->n_bufs;
+	state = kzalloc(state_size, GFP_KERNEL);
+	if (!state)
+		return -ENOMEM;
+	state->hw_state.n_bufs = cfg->n_bufs;
+	state->hw_state.bufs = (struct malidp_hw_buffer *)((u8 *)state + sizeof(*state));
+	state->n_intfs = 0;
+
+	transpose.n_dp_bufs = kzalloc(sizeof(*transpose.n_dp_bufs) * cfg->n_bufs, GFP_KERNEL);
+	if (transpose.n_dp_bufs == NULL) {
+		res = -ENOMEM;
+		goto exit_state;
+	}
+
+	/* Independent checks per-buffer */
+	for (i = 0; i < blob->n_malidp_buffer_configs; i++) {
+		struct malidp_buffer_config *dp_buf = &blob->buffers[i];
+		bool new_intf = true;
+
+		/* Skip the special dp_buf for smart layer bounding box */
+		if (dp_buf->flags == MALIDP_FLAG_SMART_BBOX)
+			continue;
+
+		intf = idr_find(&dev->interfaces, dp_buf->adf_intf_id);
+		if (intf == NULL) {
+			dev_err(dp_dev->device, "%s : invalid interface %i\n",
+					__func__, dp_buf->adf_intf_id);
+			res = -EINVAL;
+			goto exit_n_bufs;
+		}
+
+		/* Construct the interfaces list */
+		for (j = 0; j < state->n_intfs + 1; j++) {
+			if (state->intf_list[j] == intf)
+				new_intf = false;
+		}
+		if (new_intf) {
+			state->intf_list[state->n_intfs] = intf;
+			state->n_intfs++;
+		}
+
+		/* Basic field sanity checks */
+		if (dp_buf->adf_buffer_index >= cfg->n_bufs) {
+			dev_err(dp_dev->device,	"malidp_buf[%i] adf buffer index (%d) out of range\n",
+				i, dp_buf->adf_buffer_index);
+			res = -EINVAL;
+			goto exit_n_bufs;
+		}
+		adf_buf = &cfg->bufs[dp_buf->adf_buffer_index];
+
+		/* Is this an input buffer? */
+		if (!(dp_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT))
+			n_input_buffers++;
+
+		/* Add one to the buffer count for this ADF buffer */
+		transpose.n_dp_bufs[dp_buf->adf_buffer_index]++;
+
+		/* Format/memory-layout Validation */
+		if (dp_buf->flags & MALIDP_FLAG_AFBC) {
+			res = malidp_adf_format_afbc_validate(dev, adf_buf,
+							      dp_buf);
+			if (res)
+				goto exit_n_bufs;
+		} else {
+			res = malidp_adf_non_afbc_validate(dp_dev, adf_buf,
+							   dp_buf);
+			if (res)
+				goto exit_n_bufs;
+		}
+	}
+
+	/* Check for output buffer with no input content */
+	if (!n_input_buffers && cfg->n_bufs) {
+		dev_err(dp_dev->device, "%s : no input buffers provided, but write-out requested\n",
+				__func__);
+		res = -EINVAL;
+		goto exit_n_bufs;
+	}
+
+	/* Pointers to lists of DP buffers per ADF buffer */
+	transpose.buf_lists =
+		kzalloc(sizeof(struct malidp_buffer_config **) * cfg->n_bufs, GFP_KERNEL);
+	if (transpose.buf_lists == NULL) {
+		res = -ENOMEM;
+		goto exit_n_bufs;
+	}
+
+	/* The lists for each ADF buffer */
+	for (i = 0; i < cfg->n_bufs; i++) {
+		transpose.buf_lists[i] =
+			kzalloc(sizeof(struct malidp_buffer_config *) * transpose.n_dp_bufs[i], GFP_KERNEL);
+		if (transpose.buf_lists[i] == NULL) {
+			res = -ENOMEM;
+			goto exit_lists;
+		}
+		/* Reset the counter so we can use it for insertions */
+		transpose.n_dp_bufs[i] = 0;
+	}
+
+	/* Finally populate the lists */
+	for (i = 0; i < blob->n_malidp_buffer_configs; i++) {
+		struct malidp_buffer_config *dp_buf = &blob->buffers[i];
+
+		for (j = 0; j < cfg->n_bufs; j++) {
+
+			if (j == dp_buf->adf_buffer_index) {
+				int index = transpose.n_dp_bufs[j];
+
+				transpose.buf_lists[j][index] = dp_buf;
+				transpose.n_dp_bufs[j]++;
+			}
+		}
+	}
+
+	/* Generate HW buffers */
+	res = malidp_adf_build_hw_bufs(dp_dev, cfg, &transpose, state);
+	if (res)
+		goto exit_lists;
+
+	/* Check against hardware constraints */
+	res = malidp_hw_validate(dp_dev->hw_dev, &state->hw_state);
+	if (res) {
+		dev_err(dp_dev->device, "%s : HW validate failed\n", __func__);
+		goto exit_map;
+	}
+
+	/* Nothing wrong, so save state for later */
+	*driver_state = state;
+
+	/* Clean up temporal memory */
+	for (i = 0; i < cfg->n_bufs; i++) {
+		kfree(transpose.buf_lists[i]);
+	}
+	kfree(transpose.buf_lists);
+	kfree(transpose.n_dp_bufs);
+
+	return 0;
+
+exit_map:
+	if (dp_dev->iommu_domain && *driver_state == NULL) {
+		for (i = 0; i < cfg->n_bufs; i++) {
+			adf_buf = &cfg->bufs[i];
+			for (j = 0; j < adf_buf->n_planes; j++)
+				malidp_iommu_unmap_sgt(dp_dev->iommu_domain,
+						state->iommu_maps[i][j]);
+		}
+	}
+exit_lists:
+	for (i = 0; i < cfg->n_bufs; i++) {
+		kfree(transpose.buf_lists[i]);
+	}
+	kfree(transpose.buf_lists);
+exit_n_bufs:
+	kfree(transpose.n_dp_bufs);
+exit_state:
+	kfree(state);
+
+	return res;
+}
+
+/*
+ * Copied from adf_sw_complete_fence() and adf_sw_advance_timeline() in the ADF
+ * core. Remove them if they are exported by the framework in the future.
+ */
+
+static struct sync_fence *malidp_adf_sw_complete_fence(struct adf_device *dev)
+{
+	struct sync_pt *pt;
+	struct sync_fence *complete_fence;
+
+	if (!dev->timeline) {
+		dev->timeline = sw_sync_timeline_create(dev->base.name);
+		if (!dev->timeline)
+			return ERR_PTR(-ENOMEM);
+		dev->timeline_max = 1;
+	}
+
+	dev->timeline_max++;
+	pt = sw_sync_pt_create(dev->timeline, dev->timeline_max);
+	if (!pt)
+		goto err_pt_create;
+	complete_fence = sync_fence_create(dev->base.name, pt);
+	if (!complete_fence)
+		goto err_fence_create;
+
+	return complete_fence;
+
+err_fence_create:
+	sync_pt_free(pt);
+err_pt_create:
+	dev->timeline_max--;
+	return ERR_PTR(-ENOSYS);
+}
+
+static void adf_sw_advance_timeline(struct adf_device *dev)
+{
+#ifdef CONFIG_SW_SYNC
+	sw_sync_timeline_inc(dev->timeline, 1);
+#else
+	BUG();
+#endif
+}
+/* End of sync functions copied from the ADF core */
+
+static struct sync_fence *malidp_adf_complete_fence(struct adf_device *dev,
+				struct adf_post *cfg, void *driver_state)
+{
+	struct malidp_custom_data *blob =
+		(struct malidp_custom_data *)cfg->custom_data;
+	struct malidp_driver_state *state = driver_state;
+	int i;
+
+	/*
+	 * For output buffers we need to set up an additional fence, which is
+	 * handled internally in the adf interface.
+	 */
+	for (i = 0; i < blob->n_malidp_buffer_configs; i++) {
+		struct malidp_buffer_config *dp_buf = &blob->buffers[i];
+		struct adf_buffer *buf = &cfg->bufs[dp_buf->adf_buffer_index];
+		struct adf_buffer_mapping *map = &cfg->mappings[dp_buf->adf_buffer_index];
+
+		if (dp_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT) {
+			struct malidp_device *dp_dev = to_malidp_device(dev);
+			struct adf_interface *adf_intf;
+
+			adf_intf = idr_find(&dev->interfaces, dp_buf->adf_intf_id);
+			state->mw_cfg = malidp_intf_create_mw_cfg(adf_intf,
+				dp_dev, buf, dp_buf->adf_buffer_index, map,
+				state->iommu_maps[dp_buf->adf_buffer_index]);
+			if (!state->mw_cfg) {
+				dev_err(dp_dev->device, "could not create mw_cfg");
+				return ERR_PTR(-EINVAL);
+			}
+		}
+	}
+
+	return malidp_adf_sw_complete_fence(dev);
+}
+
+/* This has to be implemented so that ADF core does not complain */
+static void malidp_adf_advance_timeline(struct adf_device *dev,
+				struct adf_post *cfg, void *driver_state)
+{
+	return adf_sw_advance_timeline(dev);
+}
+
+static void malidp_adf_state_free(struct adf_device *dev, void *driver_state)
+{
+	struct malidp_device *dp_dev = to_malidp_device(dev);
+	struct malidp_driver_state *state = driver_state;
+	int i;
+
+	if (state->mw_cfg) {
+		for (i = 0; i < state->n_intfs; i++) {
+			if (malidp_adf_intf_get_dp_type(state->intf_list[i]) == MALIDP_HW_INTF_MEMORY) {
+				dev_dbg(dp_dev->device, "%s: clean output fence if needed\n", __func__);
+				malidp_adf_intf_destroy_mw_cfg(state->intf_list[i],
+							       state->mw_cfg);
+			}
+		}
+	}
+
+	/*
+	 * Release the buffers uisng the right direction parameters for output
+	 * buffers and unmapping the iommu maps if required.
+	 */
+	if (dev->onscreen)
+		malidp_unmap_all_buffers(dev, dev->onscreen);
+
+	malidp_hw_state_free(dp_dev->hw_dev, &state->hw_state);
+	kfree(state);
+}
+
+static int malidp_adf_custom_data(struct adf_obj *obj, void *data, size_t *size)
+{
+	struct malidp_adf_device_custom_data custom_data;
+	struct adf_device *adf_dev = adf_obj_to_device(obj);
+	struct malidp_device *malidp_dev = to_malidp_device(adf_dev);
+	const struct malidp_hw_topology *topology =
+		malidp_hw_get_topology(malidp_dev->hw_dev);
+	enum malidp_hw_partition_type type;
+	uint32_t array_size;
+
+	memset(&custom_data, 0, sizeof(custom_data));
+
+	/* Obtain values from the device */
+
+	/* Scaler information */
+	custom_data.n_scalers = topology->n_scalers;
+
+	/* AFBC information */
+	BUG_ON(topology->n_supported_afbc_formats > MALIDP_MAX_N_FORMATS);
+
+	array_size = sizeof(topology->supported_afbc_formats[0]) *
+		topology->n_supported_afbc_formats;
+	custom_data.n_supported_afbc_formats =
+		topology->n_supported_afbc_formats;
+	memcpy(&custom_data.supported_afbc_formats,
+	       topology->supported_afbc_formats,
+	       array_size);
+	custom_data.supported_afbc_splitblk = topology->supported_afbc_splitblk;
+
+	/* MW information */
+	BUG_ON(topology->n_mw_formats > MALIDP_MAX_N_FORMATS);
+
+	array_size = sizeof(topology->mw_formats[0]) * topology->n_mw_formats;
+	custom_data.n_supported_mw_formats = topology->n_mw_formats;
+	memcpy(&custom_data.supported_mw_formats, topology->mw_formats,
+	       array_size);
+
+	/* Rotation memory information */
+	custom_data.rotation_memory_size =
+		malidp_hw_rotmem_size_get(malidp_dev->hw_dev);
+	type = malidp_hw_rotmem_type_get(malidp_dev->hw_dev);
+
+	/* Min/max supported dimensions */
+	malidp_hw_supported_dimensions_get(malidp_dev->hw_dev,
+		&custom_data.min_width, &custom_data.min_height,
+		&custom_data.max_width, &custom_data.max_height);
+
+	/* Unsupported rotation formats */
+	custom_data.n_xform_invalid_formats =
+		topology->n_xform_invalid_formats;
+	array_size = sizeof(topology->xform_invalid_formats[0]) *
+		topology->n_xform_invalid_formats;
+	memcpy(&custom_data.xform_invalid_formats,
+	       topology->xform_invalid_formats,
+	       array_size);
+
+	/* Convert to user-facing value */
+	switch (type) {
+	case MALIDP_HW_PARTITION_FIXED: {
+		custom_data.rotation_memory_strategy =
+			MALIDP_ROTMEM_PARTITION_FIXED;
+		break;
+	};
+
+	default:
+		BUG();
+	}
+
+	memcpy(data, &custom_data, sizeof(custom_data));
+
+	*size = sizeof(custom_data);
+
+	return 0;
+}
+
+static const struct adf_device_ops malidp_adf_ops = {
+	.owner = THIS_MODULE,
+	.base = {
+		.custom_data = malidp_adf_custom_data,
+	},
+	.quirks = {
+		.buffer_padding = ADF_BUFFER_UNPADDED,
+	},
+	.validate_custom_format = malidp_adf_format_validate,
+	.validate = malidp_adf_validate,
+	.post = malidp_adf_post,
+	.complete_fence = malidp_adf_complete_fence,
+	.advance_timeline = malidp_adf_advance_timeline,
+	.state_free = malidp_adf_state_free,
+};
+
+/*
+ * Initialises (and allocates) the ADF parts of a malidp_device.
+ *
+ * @dp_dev The malidp_device which contains the adf_device to be initialised.
+ * @hw_desc The description of the hardware for which ADF representations
+ *          should be made
+ * Returns 0 on success, an error (<0) on failure
+ */
+int malidp_adf_init(struct malidp_device *dp_dev,
+		struct malidp_hw_description *hw_desc,
+		struct video_tx_device *tx)
+{
+	const struct adf_device_ops *dev_ops;
+	const struct malidp_hw_topology *topo = hw_desc->topology;
+	int ret;
+
+	dev_ops = malidp_get_dev_ops(dp_dev);
+	if (NULL == dev_ops)
+		return -EINVAL;
+
+	ret = adf_device_init(&dp_dev->adf_dev, dp_dev->device, dev_ops,
+			"%s%u", dp_dev->name, dp_dev->id);
+	if (ret)
+		return ret;
+
+	ret = malidp_adf_ovr_add_layers(dp_dev, topo->layers, topo->n_layers);
+	if (ret)
+		goto destroy_device;
+
+	ret = malidp_adf_intf_add_interfaces(dp_dev, topo->interfaces,
+			topo->n_interfaces, tx);
+	if (ret)
+		goto destroy_device;
+
+	ret = malidp_allow_attachments(dp_dev);
+	if (ret)
+		goto destroy_device;
+
+	return ret;
+
+destroy_device:
+	malidp_adf_destroy(dp_dev);
+	return ret;
+}
+
+static int attach_overlay_engine(int id, void *p, void *opaque)
+{
+	struct adf_interface *intf = (struct adf_interface *)opaque;
+	struct adf_overlay_engine *eng = (struct adf_overlay_engine *)p;
+	struct adf_device *dev = intf->base.parent;
+
+	dev_dbg(&dev->base.dev, "Allowing attachment %s->%s\n", intf->base.name,
+			eng->base.name);
+	return adf_attachment_allow(dev, eng, intf);
+}
+
+static int attach_interface(int id, void *p, void *opaque)
+{
+	struct adf_interface *intf = (struct adf_interface *)p;
+	struct adf_device *dev = intf->base.parent;
+	return idr_for_each(&dev->overlay_engines, attach_overlay_engine,
+				intf);
+}
+
+static int malidp_allow_attachments(struct malidp_device *dp_dev)
+{
+	struct adf_device *adf_dev = &dp_dev->adf_dev;
+
+	/*
+	 * For now we attach all interfaces to all overlays, so we will just
+	 * iterate the interface and overlay lists and attach them all.
+	 */
+	return idr_for_each(&adf_dev->interfaces, attach_interface, NULL);
+}
+
+int malidp_adf_destroy(struct malidp_device *dp_dev)
+{
+	struct adf_device *adf_dev = &dp_dev->adf_dev;
+
+	malidp_adf_intf_destroy_interfaces(dp_dev);
+	malidp_adf_ovr_destroy_layers(dp_dev);
+
+	adf_device_destroy(adf_dev);
+	return 0;
+}
+
+static const struct adf_device_ops *malidp_get_dev_ops(
+		struct malidp_device *dp_dev)
+{
+	/* LEOSW-410: Return operations appropriate for dp_dev->hwver */
+	return &malidp_adf_ops;
+}
+
+int malidp_adf_runtime_resume(struct malidp_device *dp_dev)
+{
+	malidp_adf_intf_restore_drmmode(dp_dev);
+	return 0;
+}
+
+void malidp_adf_cleanup_signaled_mw(struct malidp_driver_state *state)
+{
+	if (state->mw_cfg && state->mw_cfg->signaled == true)
+		malidp_hw_clear_mw(&state->hw_state);
+}
+
+void malidp_adf_waiting_for_mw(struct malidp_driver_state *state)
+{
+	if (state->mw_cfg == NULL || state->mw_cfg->signaled == true)
+		return;
+	sync_fence_wait(state->mw_cfg->mw_fence, 250);
+}
diff --git a/drivers/video/adf/arm/malidp_adf.h b/drivers/video/adf/arm/malidp_adf.h
new file mode 100644
index 0000000..178445e
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_adf.h
@@ -0,0 +1,56 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_ADF_H_
+#define _MALIDP_ADF_H_
+
+#include <linux/types.h>
+#include <video/adf.h>
+#include <video/video_tx.h>
+
+#include "malidp_drv.h"
+#include "malidp_hw.h"
+#include "malidp_iommu.h"
+#include "malidp_adf_interface.h"
+#include "malidp_adf_overlay.h"
+
+#define to_malidp_device(dev) container_of(dev, \
+			struct malidp_device, adf_dev)
+
+#define MALIDP_MAX_INTERFACES 2
+#define MALIDP_MAX_BUFFERS 10
+
+struct malidp_driver_state {
+	int n_intfs;
+	struct adf_interface *intf_list[MALIDP_MAX_INTERFACES];
+	struct malidp_hw_state hw_state;
+	struct malidp_intf_memory_cfg *mw_cfg;
+	struct malidp_iommu_mapping *iommu_maps[MALIDP_MAX_BUFFERS][ADF_MAX_PLANES];
+};
+
+int malidp_adf_init(struct malidp_device *dp_dev,
+		struct malidp_hw_description *hw_desc,
+		struct video_tx_device *tx);
+int malidp_adf_destroy(struct malidp_device *dp_dev);
+
+void malidp_adf_post_cleanup(struct adf_device *dev,
+		struct adf_pending_post *post);
+
+int malidp_adf_runtime_resume(struct malidp_device *dp_dev);
+void malidp_adf_cleanup_signaled_mw(struct malidp_driver_state *state);
+void malidp_adf_waiting_for_mw(struct malidp_driver_state *state);
+#endif /* _MALIDP_ADF_H_ */
diff --git a/drivers/video/adf/arm/malidp_adf_format.c b/drivers/video/adf/arm/malidp_adf_format.c
new file mode 100644
index 0000000..020f9c7
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_adf_format.c
@@ -0,0 +1,308 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include "malidp_adf.h"
+#include "malidp_adf_format.h"
+#include <video/adf_format.h>
+#include <uapi/video/malidp_adf.h>
+
+#define AFBC_HEADER_SIZE 16
+#define AFBC_SUPERBLOCK_SIZE 16
+
+/** Validate a buffer using a tiled pixel format
+ *
+ * @dev: ADF device performing the validation
+ * @buf: buffer to validate
+ * @num_planes: expected number of planes
+ * @tile_w: the width in pixels of each tile
+ * @tile_h: the height in pixels of each tile
+ * @cpt: expected bytes per tile for each plane (length @num_planes)
+ *
+ * Returns 0 if @buf has the expected number of planes and each plane
+ * has sufficient size, or -EINVAL otherwise.
+ */
+static int malidp_adf_format_validate_tiled(struct adf_device *dev,
+	struct adf_buffer *buf, u8 num_planes, u8 tile_w, u8 tile_h, u8 cpt[])
+{
+	u8 i;
+
+	if (num_planes != buf->n_planes) {
+		char format_str[ADF_FORMAT_STR_SIZE];
+		adf_format_str(buf->format, format_str);
+		dev_err(&dev->base.dev, "%u planes expected for format %s but %u planes provided\n",
+			num_planes, format_str, buf->n_planes);
+		return -EINVAL;
+	}
+
+	if (buf->w == 0 || buf->w % tile_w) {
+		dev_err(&dev->base.dev, "bad buffer width %u\n", buf->w);
+		return -EINVAL;
+	}
+
+	if (buf->h == 0 || buf->h % tile_h) {
+		dev_err(&dev->base.dev, "bad buffer height %u\n", buf->h);
+		return -EINVAL;
+	}
+
+	for (i = 0; i < num_planes; i++) {
+		u32 width = buf->w / tile_w;
+		u32 height = buf->h / tile_h;
+
+		if (buf->pitch[i] < (u64) width * cpt[i]) {
+			dev_err(&dev->base.dev, "plane %u pitch is shorter than buffer width (pitch = %u, tile width = %u, cpt = %u)\n",
+				i, buf->pitch[i], width, cpt[i]);
+			return -EINVAL;
+		}
+
+		if ((u64) ((height - 1) * buf->pitch[i]) + (width * cpt[i]) +
+				buf->offset[i] > buf->dma_bufs[i]->size) {
+			dev_err(&dev->base.dev, "plane %u buffer too small (tile height = %u, tile width = %u, pitch = %u, offset = %u, size = %zu)\n",
+				i, height, width, buf->pitch[i],
+				buf->offset[i], buf->dma_bufs[i]->size);
+			return -EINVAL;
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * This is a copy of adf_format_validate_yuv which removes the call to
+ * adf_format_plane_cpp to allow its use for custom pixel formats.
+ * This appears to be the intended original behaviour, as indicated by this
+ * comment:
+ *
+ * "adf_format_validate_yuv() is intended to be called as a helper from @dev's
+ * validate_custom_format() op."
+ *
+ * and otherwise the cpp argument is redundant.
+ */
+static int malidp_adf_format_validate_yuv(struct adf_device *dev,
+		struct adf_buffer *buf,	u8 num_planes, u8 hsub, u8 vsub, u8 cpp[])
+{
+	u8 i;
+
+	if (num_planes != buf->n_planes) {
+		char format_str[ADF_FORMAT_STR_SIZE];
+		adf_format_str(buf->format, format_str);
+		dev_err(&dev->base.dev, "%u planes expected for format %s but %u planes provided\n",
+				num_planes, format_str, buf->n_planes);
+		return -EINVAL;
+	}
+
+	if (buf->w == 0 || buf->w % hsub) {
+		dev_err(&dev->base.dev, "bad buffer width %u\n", buf->w);
+		return -EINVAL;
+	}
+
+	if (buf->h == 0 || buf->h % vsub) {
+		dev_err(&dev->base.dev, "bad buffer height %u\n", buf->h);
+		return -EINVAL;
+	}
+
+	for (i = 0; i < num_planes; i++) {
+		u32 width = buf->w / (i != 0 ? hsub : 1);
+		u32 height = buf->h / (i != 0 ? vsub : 1);
+
+		if (buf->pitch[i] < (u64) width * cpp[i]) {
+			dev_err(&dev->base.dev, "plane %u pitch is shorter than buffer width (pitch = %u, width = %u, bpp = %u)\n",
+					i, buf->pitch[i], width, cpp[i] * 8);
+			return -EINVAL;
+		}
+
+		if ((u64) ((height - 1) * buf->pitch[i]) + (width * cpp[i]) +
+				buf->offset[i] > buf->dma_bufs[i]->size) {
+			dev_err(&dev->base.dev, "plane %u buffer too small (height = %u, width = %u, pitch = %u, offset = %u, size = %zu)\n",
+					i, height, width, buf->pitch[i],
+					buf->offset[i], buf->dma_bufs[i]->size);
+			return -EINVAL;
+		}
+	}
+
+	return 0;
+}
+
+int malidp_adf_format_validate(struct adf_device *dev,
+		struct adf_buffer *buf)
+{
+	struct malidp_device *dp_dev = to_malidp_device(dev);
+	u8 cpp[2];
+
+	dev_dbg(dp_dev->device, "%s", __func__);
+
+	switch (buf->format) {
+	case MALIDP_FORMAT_XYUV:
+	case MALIDP_FORMAT_VYU30:
+		cpp[0] = 4;
+		return malidp_adf_format_validate_yuv(dev, buf, 1, 1, 1, cpp);
+	case MALIDP_FORMAT_Y0L2:
+		cpp[0] = 8;
+		return malidp_adf_format_validate_tiled(dev, buf, 1, 2, 2, cpp);
+	case MALIDP_FORMAT_P010:
+		cpp[0] = 2;
+		cpp[1] = 4;
+		return malidp_adf_format_validate_yuv(dev, buf, 2, 2, 2, cpp);
+	case MALIDP_FORMAT_NV12AFBC:
+	case MALIDP_FORMAT_NV16AFBC:
+	case MALIDP_FORMAT_YUV10_420AFBC:
+		/*
+		 * We have to pass this validation because the malidp_buffer
+		 * is not available. A proper validation will be done by
+		 * malidp_adf_validate
+		 */
+		return 0;
+	default:
+		return -EINVAL;
+	}
+}
+
+/*
+ * Returns bits-per-pixel for AFBC compressed formats.
+ *
+ * This function returns the number of bits actually required by AFBC in the
+ * "worst" case (uncompressed block). It's possible that the earlier validation
+ * stage has already enforced a larger size requirement than this.
+ */
+static int malidp_adf_format_afbc_bpp(u32 format)
+{
+	switch (format) {
+	case DRM_FORMAT_ARGB2101010:
+	case DRM_FORMAT_ABGR2101010:
+	case DRM_FORMAT_RGBA1010102:
+	case DRM_FORMAT_BGRA1010102:
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_BGRA8888:
+		return 32;
+	case MALIDP_FORMAT_VYU30:
+		return 30;
+	case DRM_FORMAT_RGB888:
+	case DRM_FORMAT_BGR888:
+	case MALIDP_FORMAT_XYUV:
+		return 24;
+	case DRM_FORMAT_ABGR1555:
+	case DRM_FORMAT_RGBA5551:
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_BGR565:
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_UYVY:
+	case MALIDP_FORMAT_NV16AFBC:
+		return 16;
+	case MALIDP_FORMAT_YUV10_420AFBC:
+		return 15;
+	case MALIDP_FORMAT_NV12AFBC:
+		return 12;
+	default:
+		return 0;
+	}
+}
+
+bool malidp_adf_format_is_afbc_only(u32 format)
+{
+	switch (format) {
+	case MALIDP_FORMAT_NV12AFBC:
+	case MALIDP_FORMAT_NV16AFBC:
+	case MALIDP_FORMAT_YUV10_420AFBC:
+		return true;
+	default:
+		return false;
+	}
+}
+
+int malidp_adf_format_afbc_validate(struct adf_device *dev,
+		struct adf_buffer *adf_buf,
+		struct malidp_buffer_config *dp_buf)
+{
+	struct malidp_device *dp_dev = to_malidp_device(dev);
+	u32 n_superblocks;
+	u32 total_w, total_h;
+	u32 max_afbc_size, max_superblock_size;
+	u32 format;
+	u8 hss, vss;
+	u8 bpp;
+
+	if (adf_buf->n_planes != 1) {
+		dev_err(dp_dev->device, "%s : AFBC buffers require 1 plane",
+				__func__);
+		return -EINVAL;
+	}
+
+	total_w = adf_buf->w + dp_buf->afbc_crop_l + dp_buf->afbc_crop_r;
+	total_h = adf_buf->h + dp_buf->afbc_crop_t + dp_buf->afbc_crop_b;
+	if ((total_w % 16) || (total_h % 16)) {
+		dev_err(dp_dev->device, "%s : AFBC buffers must be aligned to 16 pixels",
+				__func__);
+		return -EINVAL;
+	}
+
+	switch (adf_buf->format) {
+	case MALIDP_FORMAT_NV12AFBC:
+		format = DRM_FORMAT_NV12;
+		break;
+	case MALIDP_FORMAT_NV16AFBC:
+		format = DRM_FORMAT_NV16;
+		break;
+	case MALIDP_FORMAT_YUV10_420AFBC:
+		format = DRM_FORMAT_YUV420;
+		break;
+	default:
+		format = adf_buf->format;
+	}
+	hss = adf_format_horz_chroma_subsampling(format);
+	vss = adf_format_vert_chroma_subsampling(format);
+	if ((dp_buf->afbc_crop_l % hss) ||
+		(dp_buf->afbc_crop_r % hss) ||
+		(dp_buf->afbc_crop_t % vss) ||
+		(dp_buf->afbc_crop_b % vss)) {
+		dev_err(dp_dev->device, "%s : AFBC cropping not compatible with subsampling",
+				__func__);
+		return -EINVAL;
+	}
+
+	bpp = malidp_adf_format_afbc_bpp(adf_buf->format);
+	if (!bpp) {
+		char format_buf[ADF_FORMAT_STR_SIZE];
+		adf_format_str(adf_buf->format, format_buf);
+		dev_err(dp_dev->device, "%s : pixel format %s not supported for AFBC",
+				__func__, format_buf);
+		return -EINVAL;
+	}
+
+	n_superblocks = (total_w / AFBC_SUPERBLOCK_SIZE) *
+		(total_h / AFBC_SUPERBLOCK_SIZE);
+
+	BUG_ON((bpp * total_w * total_h) % 8);
+
+	/* In sparse mode superblocks are 128-byte aligned */
+	max_superblock_size = ALIGN(bpp *
+		(AFBC_SUPERBLOCK_SIZE * AFBC_SUPERBLOCK_SIZE >> 3), 128);
+
+	/* Space for the header and 64-byte alignment for body buffer */
+	max_afbc_size = ALIGN(n_superblocks * AFBC_HEADER_SIZE, 64);
+	/* Space for the body buffer */
+	max_afbc_size += max_superblock_size * n_superblocks;
+
+	if (max_afbc_size > (adf_buf->dma_bufs[0]->size - adf_buf->offset[0])) {
+		dev_err(dp_dev->device, "%s : buffer size (%zu) with offset %i too small for %ix%i",
+			__func__, adf_buf->dma_bufs[0]->size,
+			adf_buf->offset[0], total_w, total_h);
+		return -EINVAL;
+	}
+
+	return 0;
+}
diff --git a/drivers/video/adf/arm/malidp_adf_format.h b/drivers/video/adf/arm/malidp_adf_format.h
new file mode 100644
index 0000000..1464030
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_adf_format.h
@@ -0,0 +1,32 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2014 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_ADF_FORMAT_H_
+#define _MALIDP_ADF_FORMAT_H_
+
+#include <video/adf.h>
+
+int malidp_adf_format_validate(struct adf_device *dev,
+		struct adf_buffer *buf);
+
+int malidp_adf_format_afbc_validate(struct adf_device *dev,
+		struct adf_buffer *adf_buf,
+		struct malidp_buffer_config *dp_buf);
+
+bool malidp_adf_format_is_afbc_only(u32 format);
+
+#endif /* _MALIDP_ADF_FORMAT_H_ */
diff --git a/drivers/video/adf/arm/malidp_adf_interface.c b/drivers/video/adf/arm/malidp_adf_interface.c
new file mode 100644
index 0000000..d60aaca
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_adf_interface.c
@@ -0,0 +1,1171 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/mutex.h>
+#include <linux/slab.h>
+#include <linux/types.h>
+#include <linux/uaccess.h>
+#include <linux/wait.h>
+
+#include <drm/drm_crtc.h>
+#include <sw_sync.h>
+#include <video/adf.h>
+#include <video/adf_client.h>
+
+#include <uapi/video/malidp_adf.h>
+
+#include "malidp_adf.h"
+#include "malidp_hw.h"
+
+#define to_malidp_interface(adf_intf) container_of(adf_intf, \
+			struct malidp_interface, intf)
+
+#define MALIDP_INTF_TIMEOUT_MS 250
+
+struct malidp_interface {
+	char name[ADF_NAME_LEN];
+	u32 idx;
+	struct adf_interface intf;
+	enum adf_interface_type adf_type;
+	u32 adf_flags;
+	const struct adf_interface_ops *ops;
+	const struct malidp_intf_hw_info *hw_info;
+	struct notifier_block nb;
+	struct video_tx_display_info disp_info;
+	/* these fields should only be used for the memory interface */
+	struct sw_sync_timeline *mw_timeline;
+	int mw_timeline_max;
+	struct sync_fence *mw_latest_fence;
+	struct malidp_intf_memory_cfg *mw_latest_cfg;
+	struct malidp_intf_memory_cfg *mw_prev_cfg;
+	/* This spinlock protects access to per-post state */
+	struct mutex post_lock;
+	atomic_t flip_occurred;
+	atomic_t report_vsync;
+	atomic_t report_flip;
+	wait_queue_head_t wq;
+	struct video_tx_device *tx;
+	ktime_t prepare_ts;
+};
+
+int malidp_adf_intf_get_dp_type(struct adf_interface *adf_intf)
+{
+	struct malidp_interface *intf = to_malidp_interface(adf_intf);
+
+	return intf->hw_info->type;
+};
+
+static int malidp_primary_blank(struct adf_interface *intf, u8 state)
+{
+	struct adf_device *dev = adf_interface_parent(intf);
+	struct malidp_device *dp_dev = to_malidp_device(dev);
+	struct malidp_interface *dp_intf = to_malidp_interface(intf);
+	struct malidp_driver_state *driver_state;
+	int i, res;
+
+	dev_dbg(&intf->base.dev, "Blank (%i) on %s\n", state, intf->base.name);
+
+	res = video_tx_dpms(dp_intf->tx, state);
+	if (res < 0) {
+		dev_dbg(dp_dev->device, "%s: transmitter reported error\n",
+			__func__);
+		return res;
+	}
+
+	switch (state) {
+	case DRM_MODE_DPMS_ON:
+		/* Refuse if the current mode doesn't look sensible */
+		if (!intf->current_mode.hdisplay || !intf->current_mode.vdisplay) {
+			dev_err(dp_dev->device, "%s: No mode currently set - cannot unblank", __func__);
+			return -EINVAL;
+		}
+
+		/*
+		 * Flush all pending posts. Then dev->onscreen will contain
+		 * the last submitted post or NULL if no posts were made.
+		 *
+		 * There is no possible race when accessing dev->onscreen
+		 * because we have just flushed the worker thread and the client
+		 * lock is being held by blank() so no new posts can be queued
+		 * in the meantime.
+		 */
+		flush_kthread_worker(&dev->post_worker);
+		malidp_hw_display_switch(dp_dev->hw_dev, true);
+		/*
+		 * If we "dropped" any frames whilst we were blanked, then
+		 * display the most recent one now
+		 */
+		if (dev->onscreen) {
+			driver_state = dev->onscreen->state;
+			malidp_hw_commit(dp_dev->hw_dev, &driver_state->hw_state);
+			for (i = 0; i < driver_state->n_intfs; i++)
+				malidp_intf_wait(driver_state->intf_list[i], dp_dev);
+		}
+
+		break;
+	case DRM_MODE_DPMS_STANDBY:
+	case DRM_MODE_DPMS_SUSPEND:
+	case DRM_MODE_DPMS_OFF:
+		if (intf->dpms_state == DRM_MODE_DPMS_ON)
+			malidp_hw_display_switch(dp_dev->hw_dev, false);
+
+		/*
+		 * The last flushed post will be considered onscreen by ADF.
+		 * We need to clean that one up too.
+		 */
+		if (dev->onscreen) {
+			struct adf_pending_post *post;
+
+			post = dev->onscreen;
+			dev->timeline_max++;
+			dev->ops->advance_timeline(dev, &post->config,
+				post->state);
+			malidp_adf_post_cleanup(dev, post);
+			/*
+			 * Set it to NULL and ADF won't try to clean it up again
+			 * when we resume normal service
+			 */
+			dev->onscreen = NULL;
+		}
+
+		break;
+	default:
+		BUG();
+	}
+
+	dp_dev->current_dpms = state;
+	/*
+	 * This should propagate the video_tx return value if nothing more
+	 * important happened. Note that the ADF blank implementation assumes
+	 * that we did nothing if we return < 0 here.
+	 */
+	return res;
+}
+
+static bool malidp_adf_intf_validate_mode(struct malidp_device *dev,
+	struct drm_mode_modeinfo *mode)
+{
+	u32 max_w, max_h, rate_diff, full_frame;
+
+	/* Interlaced modes not supported */
+	if (mode->flags & DRM_MODE_FLAG_INTERLACE) {
+		dev_dbg(dev->device, "%s: mode '%.*s' failed flag check!\n",
+			__func__, DRM_DISPLAY_MODE_LEN, mode->name);
+		return false;
+	}
+
+	/* Sanity check dimensions */
+	if ((mode->hdisplay == 0) || (mode->htotal == 0) ||
+	    (mode->hsync_start < mode->hdisplay) ||
+	    (mode->hsync_end < mode->hsync_start) ||
+	    (mode->htotal < mode->hsync_end) ||
+	    (mode->vdisplay == 0) || (mode->vtotal == 0) ||
+	    (mode->vsync_start < mode->vdisplay) ||
+	    (mode->vsync_end < mode->vsync_start) ||
+	    (mode->vtotal < mode->vsync_end) ||
+	    (mode->clock == 0)) {
+		dev_dbg(dev->device, "%s: mode '%.*s' failed timing check!\n",
+			__func__, DRM_DISPLAY_MODE_LEN, mode->name);
+		return false;
+	}
+
+	/*
+	 * Check refresh rate/clock. We allow for up to 1 Hz of error
+	 * full_frame == pixels per frame
+	 * full_frame * mode->vrefresh == pixels per second
+	 * mode->clock * 1000 == clocks per second
+	 */
+	full_frame = (u32)mode->htotal * (u32)mode->vtotal;
+	rate_diff = abs((full_frame * mode->vrefresh) - (mode->clock * 1000));
+	if (rate_diff > full_frame) {
+		dev_dbg(dev->device, "%s: mode '%.*s' failed rate check!\n",
+			__func__, DRM_DISPLAY_MODE_LEN, mode->name);
+		return false;
+	}
+
+	/* Check against max supported dimensions */
+	malidp_hw_supported_dimensions_get(dev->hw_dev, NULL, NULL,
+					   &max_w, &max_h);
+	if ((mode->hdisplay > max_w) || (mode->vdisplay > max_h)) {
+		dev_dbg(dev->device, "%s: mode '%.*s' failed dimension check!\n",
+			__func__, DRM_DISPLAY_MODE_LEN, mode->name);
+		return false;
+	}
+
+	return true;
+}
+
+static int malidp_primary_modeset(struct adf_interface *intf,
+		struct drm_mode_modeinfo *mode)
+{
+	struct malidp_device *dp_dev = to_malidp_device(intf->base.parent);
+	struct malidp_interface *dp_intf = to_malidp_interface(intf);
+	int ret;
+
+	dev_dbg(dp_dev->device, "%s : (%ix%i) on %s\n", __func__,
+			mode->hdisplay, mode->vdisplay, intf->base.name);
+
+	if (intf->dpms_state == DRM_MODE_DPMS_ON) {
+		dev_err(dp_dev->device, "%s : Can't set mode with display turned on\n",
+				__func__);
+		return -EBUSY;
+	}
+
+	if (!malidp_adf_intf_validate_mode(dp_dev, mode))
+		return -EINVAL;
+
+	ret = video_tx_set_mode(dp_intf->tx, mode);
+	if (ret == 0)
+		ret = malidp_hw_modeset(dp_dev->hw_dev, mode);
+
+	/* If modeset failed, we should attempt to restore the old one */
+	if (ret) {
+		struct drm_mode_modeinfo *fallback = &intf->current_mode;
+		if (fallback->hdisplay && fallback->vdisplay) {
+			int err;
+			dev_err(dp_dev->device, "%s: Modeset failed. Attempting fallback\n",
+				__func__);
+
+			err = video_tx_set_mode(dp_intf->tx, fallback);
+			if (malidp_hw_modeset(dp_dev->hw_dev, fallback) || err)
+				dev_err(dp_dev->device, "%s: Modeset and fallback failed. Display state undefined!\n",
+					__func__);
+		}
+	}
+
+	return ret;
+}
+
+static int malidp_primary_describe_simple_post(struct adf_interface *intf,
+		struct adf_buffer *buf, void *data, size_t *size)
+{
+	struct malidp_custom_data *blob_p;
+	struct drm_mode_modeinfo mode;
+	struct malidp_custom_data blob = {
+		.n_malidp_buffer_configs = 1,
+		.sizeof_malidp_buffer_config = sizeof(struct malidp_buffer_config),
+	};
+	struct malidp_buffer_config malidp_buf = {
+		.adf_buffer_index = 0,
+		.adf_intf_id = intf->base.id,
+		.display_width = buf->w,
+		.display_height = buf->h,
+		.transform = 0,
+		.flags = MALIDP_FLAG_BUFFER_INPUT,
+		.alpha_mode = MALIDP_ALPHA_MODE_NONE
+	};
+
+	/* Get the current mode and use its dimensions to center the image */
+	adf_interface_current_mode(intf, &mode);
+	malidp_buf.display_top = (mode.vdisplay - buf->h) / 2,
+	malidp_buf.display_left = (mode.hdisplay - buf->w) / 2,
+
+	*size = sizeof(blob) + sizeof(malidp_buf);
+	if (ADF_MAX_CUSTOM_DATA_SIZE < *size)
+		return -ENOMEM;
+
+	blob_p = (struct malidp_custom_data *)data;
+	memcpy(blob_p, &blob, sizeof(blob));
+	memcpy(&blob_p->buffers, &malidp_buf, sizeof(malidp_buf));
+
+	return 0;
+}
+
+static bool malidp_interface_supports_event(struct adf_obj *obj,
+				     enum adf_event_type type)
+{
+	bool supported;
+
+	switch ((int)type) {
+	case ADF_EVENT_VSYNC:
+	case MALIDP_ADF_EVENT_FLIP:
+	case ADF_EVENT_HOTPLUG:
+		supported = true;
+		break;
+	default:
+		supported = false;
+	}
+	return supported;
+}
+
+static void malidp_interface_set_event(struct adf_obj *obj,
+				    enum adf_event_type type, bool enabled)
+{
+	struct adf_interface *adf_intf = container_of(obj,
+				struct adf_interface, base);
+	struct malidp_interface *malidp_intf = to_malidp_interface(adf_intf);
+	int val = (enabled == true) ? 1 : 0;
+
+	switch ((int)type) {
+	case ADF_EVENT_VSYNC:
+		atomic_set(&malidp_intf->report_vsync, val);
+		break;
+	case MALIDP_ADF_EVENT_FLIP:
+		atomic_set(&malidp_intf->report_flip, val);
+		break;
+	default:
+		break;
+	}
+}
+
+enum adf_interface_type malidp_drm_conn_type_to_adf(u32 drm_type)
+{
+	switch (drm_type) {
+	case DRM_MODE_CONNECTOR_VGA:
+		return ADF_INTF_VGA;
+	case DRM_MODE_CONNECTOR_DVII:
+	case DRM_MODE_CONNECTOR_DVID:
+	case DRM_MODE_CONNECTOR_DVIA:
+		return ADF_INTF_DVI;
+	case DRM_MODE_CONNECTOR_LVDS:
+		return MALIDP_INTF_LVDS;
+	case DRM_MODE_CONNECTOR_DisplayPort:
+		return ADF_INTF_DPI;
+	case DRM_MODE_CONNECTOR_HDMIA:
+	case DRM_MODE_CONNECTOR_HDMIB:
+		return ADF_INTF_HDMI;
+	case DRM_MODE_CONNECTOR_eDP:
+		return ADF_INTF_eDP;
+	case DRM_MODE_CONNECTOR_VIRTUAL:
+		return MALIDP_INTF_VIRTUAL;
+	default:
+		return MALIDP_INTF_UNKNOWN;
+	}
+}
+
+static const char *malidp_interface_type_str(struct adf_interface *intf)
+{
+	switch ((u32)intf->type) {
+	case MALIDP_INTF_LVDS:
+		return "LVDS";
+	case MALIDP_INTF_VIRTUAL:
+		return "virtual";
+	case MALIDP_INTF_MEMORY:
+		return "memory";
+	case MALIDP_INTF_UNKNOWN:
+	default:
+		return "unknown";
+	}
+}
+
+static long malidp_memory_ioctl(struct adf_obj *obj, unsigned int cmd,
+			       unsigned long arg)
+{
+	struct malidp_adf_get_output_fence data;
+	struct adf_interface *adf_intf = container_of(obj,
+				struct adf_interface, base);
+	struct malidp_interface *malidp_intf = to_malidp_interface(adf_intf);
+	int fence_fd;
+
+	switch (cmd) {
+	case MALIDP_ADF_IOCTL_GET_OUTPUT_FENCE:
+		if (malidp_adf_intf_get_dp_type(adf_intf) != MALIDP_HW_INTF_MEMORY)
+			return -EINVAL;
+
+		mutex_lock(&malidp_intf->post_lock);
+		if (malidp_intf->mw_latest_fence == NULL) {
+			mutex_unlock(&malidp_intf->post_lock);
+			return -ENOENT;
+		}
+
+		fence_fd = get_unused_fd();
+		if (fence_fd < 0) {
+			mutex_unlock(&malidp_intf->post_lock);
+			return fence_fd;
+		}
+
+		sync_fence_install(malidp_intf->mw_latest_fence, fence_fd);
+		data.output_fence = (s64)fence_fd;
+		/* Increase reference count of sync fence.
+		 * The fence is not only used by userland but also used
+		 * by system pm notifier.
+		 */
+		sync_fence_fdget(fence_fd);
+
+		/* Destroying this fence is not our problem anymore */
+		malidp_intf->mw_latest_fence = NULL;
+		mutex_unlock(&malidp_intf->post_lock);
+
+		if (copy_to_user((void *)arg, &data, sizeof(data)))
+			return -EFAULT;
+
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+int malidp_adf_ioctl_set_gamma(struct malidp_device *dev,
+			       struct malidp_adf_set_gamma *gamma)
+{
+	bool gamma_enabled;
+	u32 *gamma_coeffs;
+
+	if (get_user(gamma_enabled, &gamma->enable))
+		return -EFAULT;
+
+	gamma_coeffs = kzalloc(sizeof(u32) * MALIDP_N_GAMMA_COEFFS, GFP_KERNEL);
+	if (!gamma_coeffs)
+		return -ENOMEM;
+
+	if (copy_from_user(gamma_coeffs, gamma->coefficient,
+			   sizeof(u32) * MALIDP_N_GAMMA_COEFFS)) {
+		kfree(gamma_coeffs);
+		return -EFAULT;
+	}
+
+	mutex_lock(&dev->adf_dev.client_lock);
+
+	malidp_hw_update_gamma_settings(dev->hw_dev,
+					gamma_enabled,
+					gamma_coeffs);
+
+	mutex_unlock(&dev->adf_dev.client_lock);
+
+	kfree(gamma_coeffs);
+
+	return 0;
+}
+
+static long malidp_primary_ioctl(struct adf_obj *obj, unsigned int cmd,
+			       unsigned long arg)
+{
+	struct adf_interface *adf_intf = container_of(obj,
+			struct adf_interface, base);
+	struct malidp_device *dp_dev = to_malidp_device(adf_intf->base.parent);
+
+	if (malidp_adf_intf_get_dp_type(adf_intf) != MALIDP_HW_INTF_PRIMARY)
+		return -EINVAL;
+
+	switch (cmd) {
+	case MALIDP_ADF_IOCTL_SET_GAMMA:
+		return malidp_adf_ioctl_set_gamma(dp_dev,
+					(struct malidp_adf_set_gamma *)arg);
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int malidp_adf_intf_custom_data(struct adf_obj *obj,
+				       void *data,
+				       size_t *size)
+{
+	struct malidp_adf_intf_custom_data *custom_data = data;
+	struct adf_interface *adf_intf = container_of(obj,
+				struct adf_interface, base);
+	struct malidp_interface *malidp_intf = to_malidp_interface(adf_intf);
+	struct malidp_device *dp_dev =
+			to_malidp_device(malidp_intf->intf.base.parent);
+
+	memset(custom_data, 0, sizeof(*custom_data));
+
+	custom_data->gamma = malidp_intf->disp_info.gamma;
+	custom_data->downscaling_threshold =
+		malidp_hw_downscaling_threshold(dp_dev->hw_dev);
+
+	*size = sizeof(*custom_data);
+
+	return 0;
+}
+
+static int malidp_primary_screen_size(struct adf_interface *intf,
+				      u16 *width_mm, u16 *height_mm)
+{
+	struct malidp_interface *malidp_intf = to_malidp_interface(intf);
+
+	*width_mm = malidp_intf->disp_info.width_mm;
+	*height_mm = malidp_intf->disp_info.height_mm;
+
+	return 0;
+}
+
+static const struct adf_interface_ops malidp_intf_ops[] = {
+	[MALIDP_HW_INTF_PRIMARY] = {
+		.base = {
+			.ioctl = malidp_primary_ioctl,
+			.supports_event = malidp_interface_supports_event,
+			.set_event = malidp_interface_set_event,
+			.custom_data = malidp_adf_intf_custom_data,
+		},
+		.blank = malidp_primary_blank,
+		.describe_simple_post =
+			malidp_primary_describe_simple_post,
+		.modeset = malidp_primary_modeset,
+		.type_str = malidp_interface_type_str,
+		.screen_size = malidp_primary_screen_size,
+	},
+	[MALIDP_HW_INTF_MEMORY] = {
+		.base = {
+			.ioctl = malidp_memory_ioctl,
+		},
+		.type_str = malidp_interface_type_str,
+	},
+};
+
+static void malidp_adf_flip_notify(struct adf_interface *intf, ktime_t timestamp)
+{
+	struct malidp_adf_flip_event flip_event;
+
+	flip_event.base.type = MALIDP_ADF_EVENT_FLIP;
+	flip_event.base.length = sizeof(flip_event);
+	flip_event.timestamp = ktime_to_ns(timestamp);
+	adf_event_notify(&intf->base,  &flip_event.base);
+}
+
+static void malidp_adf_intf_flip_de_cb(struct device *dev, void *opaque,
+				    struct malidp_hw_event_queue *queue)
+{
+	struct malidp_interface *dp_intf = opaque;
+	struct malidp_hw_event event;
+	char errstring[50];
+
+	mutex_lock(&dp_intf->post_lock);
+
+	malidp_hw_event_queue_dequeue(queue, &event);
+	while (event.type != MALIDP_HW_EVENT_NONE) {
+		if (event.type & MALIDP_HW_EVENT_FLIP) {
+			if (atomic_read(&dp_intf->report_flip))
+				malidp_adf_flip_notify(&dp_intf->intf, event.timestamp);
+
+			/* Only wake up if this flip isn't "stale" */
+			if (ktime_compare(dp_intf->prepare_ts, event.timestamp) < 0) {
+				atomic_set(&dp_intf->flip_occurred, 1);
+				wake_up(&dp_intf->wq);
+			}
+		}
+		if (event.type & MALIDP_HW_EVENT_VSYNC) {
+			if (atomic_read(&dp_intf->report_vsync))
+				adf_vsync_notify(&dp_intf->intf, event.timestamp);
+		}
+
+		if (event.type & MALIDP_HW_EVENT_ERROR) {
+			dev_err(dev, "%s: %s interface returned (%s) event",
+				__func__, dp_intf->intf.base.name,
+				malidp_hw_get_event_string(errstring, 50, &event));
+		} else if (event.type != MALIDP_HW_EVENT_VSYNC) {
+			dev_dbg(dev, "%s: %s interface returned (%s) event",
+				__func__, dp_intf->intf.base.name,
+				malidp_hw_get_event_string(errstring, 50, &event));
+		}
+		malidp_hw_event_queue_dequeue(queue, &event);
+	}
+
+	mutex_unlock(&dp_intf->post_lock);
+}
+
+/*
+ * This function needs to be called with the post_lock mutex held in order to
+ * protect mw_cf->signaled.
+ */
+static void malidp_adf_int_cleanup_output_buffer(struct malidp_interface *dp_intf,
+				struct malidp_intf_memory_cfg *mw_cfg)
+{
+	struct malidp_device *dp_dev = to_malidp_device(dp_intf->intf.base.parent);
+	struct adf_buffer *buf;
+	struct adf_buffer_mapping *map;
+	int i;
+
+	buf = mw_cfg->mw_buf;
+	map = mw_cfg->mw_map;
+
+	if (mw_cfg->signaled) {
+		dev_dbg(&dp_intf->intf.base.dev, "%s: %p already signaled\n", __func__, mw_cfg);
+		return;
+	}
+
+	BUG_ON(!buf | !map);
+
+	for (i = 0; i < buf->n_planes; i++) {
+		if (dp_dev->iommu_domain) {
+			struct malidp_iommu_mapping *iommu_map =
+				*(mw_cfg->iommu_map + i);
+			dev_dbg(&dp_intf->intf.base.dev, "%s: unmap sgt = %p\n",
+				__func__, map->sg_tables[i]);
+			malidp_iommu_unmap_sgt(dp_dev->iommu_domain, iommu_map);
+		}
+		dma_buf_unmap_attachment(map->attachments[i],
+			map->sg_tables[i], DMA_FROM_DEVICE);
+		dma_buf_detach(buf->dma_bufs[i],
+			       map->attachments[i]);
+		if (buf->dma_bufs[i])
+			dma_buf_put(buf->dma_bufs[i]);
+		if (buf->acquire_fence)
+			sync_fence_put(buf->acquire_fence);
+
+		/*
+		* The ADF framework will want to do this too when the post is
+		* no longer on screen. This trick will prevent double clean up.
+		*/
+		map->sg_tables[i] = NULL;
+		map->attachments[i] = NULL;
+		buf->dma_bufs[i] = NULL;
+		buf->acquire_fence = NULL;
+	}
+
+	sw_sync_timeline_inc(dp_intf->mw_timeline, 1);
+
+	mw_cfg->signaled = true;
+
+	dev_dbg(&dp_intf->intf.base.dev, "%s: signal mw_cfg = %p\n", __func__, mw_cfg);
+}
+
+static void malidp_adf_intf_flip_se_cb(struct device *dev, void *opaque,
+				    struct malidp_hw_event_queue *queue)
+{
+	struct malidp_interface *dp_intf = opaque;
+	struct malidp_hw_event event;
+	char errstring[50];
+
+	mutex_lock(&dp_intf->post_lock);
+
+	dev_dbg(dev, "%s: start\n", __func__);
+	malidp_hw_event_queue_dequeue(queue, &event);
+	while (event.type != MALIDP_HW_EVENT_NONE) {
+		/*
+		 * Ignore stale events which will be/will have been correctly
+		 * handled by state free.
+		 */
+		if (ktime_compare(event.timestamp, dp_intf->prepare_ts) < 0) {
+			malidp_hw_event_queue_dequeue(queue, &event);
+			continue;
+		}
+
+		if (event.type & MALIDP_HW_EVENT_FLIP) {
+			dev_dbg(dev, "%s: wake memory wq\n", __func__);
+			atomic_set(&dp_intf->flip_occurred, 1);
+			wake_up(&dp_intf->wq);
+		}
+
+		if (event.type & MALIDP_HW_EVENT_STOP) {
+			if (dp_intf->mw_prev_cfg) {
+				dev_dbg(dev, "%s: releasing (prev) mw_cfg = %p\n",
+					__func__, dp_intf->mw_prev_cfg);
+				malidp_adf_int_cleanup_output_buffer(dp_intf,
+					dp_intf->mw_prev_cfg);
+				dp_intf->mw_prev_cfg = NULL;
+			} else if (dp_intf->mw_latest_cfg) {
+				dev_dbg(dev, "%s: releasing (latest) mw_cfg = %p\n",
+					__func__, dp_intf->mw_latest_cfg);
+				malidp_adf_int_cleanup_output_buffer(dp_intf,
+					dp_intf->mw_latest_cfg);
+				dp_intf->mw_latest_cfg = NULL;
+			}
+		}
+
+		if (event.type & MALIDP_HW_EVENT_ERROR) {
+			dev_err(dev, "%s: %s interface returned (%s) event",
+				__func__, dp_intf->intf.base.name,
+				malidp_hw_get_event_string(errstring, 50, &event));
+		} else {
+			dev_dbg(dev, "%s: %s interface returned (%s) event",
+				__func__, dp_intf->intf.base.name,
+				malidp_hw_get_event_string(errstring, 50, &event));
+		}
+
+		malidp_hw_event_queue_dequeue(queue, &event);
+	}
+	dev_dbg(dev, "%s: done\n", __func__);
+
+	mutex_unlock(&dp_intf->post_lock);
+}
+
+void malidp_intf_prepare(struct adf_interface *adf_intf,
+			 struct malidp_intf_memory_cfg *mw_cfg)
+{
+	struct malidp_interface *dp_intf = to_malidp_interface(adf_intf);
+
+	mutex_lock(&dp_intf->post_lock);
+
+	if (malidp_adf_intf_get_dp_type(adf_intf) == MALIDP_HW_INTF_MEMORY) {
+		if (dp_intf->mw_latest_cfg) {
+			dev_dbg(&adf_intf->base.dev,
+				"%s: moving %p to 'mw_prev_cfg'\n",
+				__func__, dp_intf->mw_latest_cfg);
+			dp_intf->mw_prev_cfg = dp_intf->mw_latest_cfg;
+		}
+		dp_intf->mw_latest_cfg = mw_cfg;
+		dev_dbg(&adf_intf->base.dev, "%s: add %p to 'mw_latest_cfg'\n",
+			__func__, mw_cfg);
+	}
+
+	dp_intf->prepare_ts = ktime_get();
+	atomic_set(&dp_intf->flip_occurred, 0);
+	mutex_unlock(&dp_intf->post_lock);
+}
+
+void malidp_intf_wait(struct adf_interface *adf_intf,
+			      struct malidp_device *dp_dev)
+{
+	int ret;
+	struct malidp_interface *dp_intf = to_malidp_interface(adf_intf);
+	const char *intf_name = dp_intf->hw_info->name;
+
+	dev_dbg(dp_dev->device, "%s: waiting on interface \"%s\"\n",
+		__func__, intf_name);
+
+	ret = wait_event_interruptible_timeout(dp_intf->wq,
+			(atomic_read(&dp_intf->flip_occurred) == 1),
+			msecs_to_jiffies(MALIDP_INTF_TIMEOUT_MS));
+	if (ret == 0) {
+		dev_err(dp_dev->device, "%s: timeout on interface \"%s\"\n",
+			__func__, intf_name);
+	} else if (ret == -ERESTARTSYS) {
+		dev_err(dp_dev->device, "%s: signal received on interface \"%s\"\n",
+			__func__, intf_name);
+	} else {
+		dev_dbg(dp_dev->device, "%s: flip on interface \"%s\"\n",
+			__func__, intf_name);
+	}
+}
+
+/*
+ * Create a fence for the interface timeline that will be used to signal
+ * output buffer when the memory write out interface has finished writting.
+ */
+struct malidp_intf_memory_cfg *malidp_intf_create_mw_cfg(struct adf_interface *adf_intf,
+				     struct malidp_device *dp_dev,
+				     struct adf_buffer *buf, int buf_index,
+				     struct adf_buffer_mapping *map,
+				     struct malidp_iommu_mapping **iommu_map)
+{
+	struct malidp_interface *dp_intf = to_malidp_interface(adf_intf);
+	struct malidp_intf_memory_cfg *mw_cfg = NULL;
+	struct sync_pt *pt;
+
+	if (malidp_adf_intf_get_dp_type(adf_intf) == MALIDP_HW_INTF_MEMORY) {
+		struct sync_fence *fence;
+
+		mw_cfg = kzalloc(sizeof(struct malidp_intf_memory_cfg),
+				 GFP_KERNEL);
+		if (!mw_cfg)
+			return NULL;
+
+		mutex_lock(&dp_intf->post_lock);
+
+		dp_intf->mw_timeline_max++;
+		pt = sw_sync_pt_create(dp_intf->mw_timeline,
+				       dp_intf->mw_timeline_max);
+		if (!pt)
+			goto err_pt_create;
+
+		fence = sync_fence_create(adf_intf->base.name, pt);
+		if (!fence)
+			goto err_fence_create;
+
+		mw_cfg->signaled = false;
+		mw_cfg->mw_fence = fence;
+
+		mw_cfg->mw_buf = buf;
+		mw_cfg->mw_map = map;
+		mw_cfg->iommu_map = iommu_map;
+		mw_cfg->mw_buf_index = buf_index;
+
+		dp_intf->mw_latest_fence = fence;
+
+		dev_dbg(dp_dev->device, "%s: mw_cfg = %p\n", __func__, mw_cfg);
+
+		mutex_unlock(&dp_intf->post_lock);
+	}
+
+	return mw_cfg;
+
+err_fence_create:
+	sync_pt_free(pt);
+err_pt_create:
+	dp_intf->mw_timeline_max--;
+	mutex_unlock(&dp_intf->post_lock);
+	kfree(mw_cfg);
+
+	return NULL;
+}
+
+void malidp_adf_intf_destroy_mw_cfg(struct adf_interface *adf_intf,
+				struct malidp_intf_memory_cfg *mw_cfg)
+{
+	struct malidp_interface *dp_intf = to_malidp_interface(adf_intf);
+	struct device *dev = &adf_intf->base.dev;
+
+	if (malidp_adf_intf_get_dp_type(adf_intf) != MALIDP_HW_INTF_MEMORY)
+		return;
+	dev_dbg(&adf_intf->base.dev, "%s: trying to get mutex mw_cfg = %p\n",
+		__func__, mw_cfg);
+
+	mutex_lock(&dp_intf->post_lock);
+	dev_dbg(&adf_intf->base.dev, "%s: got mutex mw_cfg = %p\n",
+		__func__, mw_cfg);
+
+
+	/* If a STOP event hasn't already, we need to free the buffer */
+	if (!mw_cfg->signaled) {
+		dev_dbg(dev, "%s: clean up mw_cfg = %p\n", __func__, mw_cfg);
+		malidp_adf_int_cleanup_output_buffer(dp_intf, mw_cfg);
+		if (mw_cfg == dp_intf->mw_latest_cfg)
+			dp_intf->mw_latest_cfg = NULL;
+		else if (mw_cfg == dp_intf->mw_prev_cfg)
+			dp_intf->mw_prev_cfg = NULL;
+	} else {
+		dev_dbg(dev, "%s: mw_cfg = %p already cleaned\n", __func__, mw_cfg);
+	}
+
+	sync_fence_put(mw_cfg->mw_fence);
+
+	kfree(mw_cfg);
+	mutex_unlock(&dp_intf->post_lock);
+}
+
+/*
+ * Remove any invalid modes by consolidating all the valid ones at the start
+ * of the list.
+ * Returns the number of valid modes in the list.
+ */
+static int malidp_adf_intf_prune_modes(struct malidp_device *dp_dev,
+	struct drm_mode_modeinfo *modes, int n_modes)
+{
+	struct drm_mode_modeinfo *gap = NULL;
+	int i, n_valid = n_modes;
+
+	for (i = 0; i < n_modes; i++) {
+		struct drm_mode_modeinfo *mode = &modes[i];
+		bool mode_valid = true;
+
+		if (!malidp_hw_pxclk_ok(dp_dev->hw_dev, mode->clock * 1000))
+			mode_valid = false;
+		else if (!malidp_adf_intf_validate_mode(dp_dev, mode))
+			mode_valid = false;
+
+		if (mode_valid) {
+			if (gap) {
+				memcpy(gap, mode, sizeof(*mode));
+				gap++;
+			}
+		} else {
+			if (!gap)
+				gap = mode;
+			n_valid--;
+		}
+	}
+
+	return n_valid;
+}
+
+static int malidp_primary_set_modes(struct malidp_device *dp_dev,
+	struct malidp_interface *malidp_intf)
+{
+	struct drm_mode_modeinfo *modes;
+	int n, ret;
+	bool done = false;
+
+	do {
+		n = video_tx_get_modes(malidp_intf->tx, NULL, 0);
+		if (n < 0) {
+			dev_err(dp_dev->device, "could not get number of modes\n");
+			return n;
+		}
+
+		modes = kzalloc(n * sizeof(struct drm_mode_modeinfo),
+				GFP_KERNEL);
+		if (!modes) {
+			dev_err(dp_dev->device, "could not allocate the modes\n");
+			return -ENOMEM;
+		}
+
+		ret = video_tx_get_modes(malidp_intf->tx, modes, n);
+		if (ret < 0) {
+			dev_err(dp_dev->device, "could not retrieve the modes\n");
+			kfree(modes);
+			return ret;
+		} else if (ret != n) {
+			dev_err(dp_dev->device, "mode list changed!\n");
+			kfree(modes);
+		} else {
+		    done = true;
+		}
+	} while (!done);
+
+	n = malidp_adf_intf_prune_modes(dp_dev, modes, n);
+
+	ret = adf_hotplug_notify_connected(&malidp_intf->intf, modes, n);
+
+	/* The ADF framework takes a copy of the modes so we can free it */
+	kfree(modes);
+
+	return ret;
+}
+
+static int malidp_adf_notifier_fn(struct notifier_block *nb,
+			unsigned long cmd, void *ptr)
+{
+	struct video_tx_device *tx = ptr;
+	struct malidp_interface *malidp_intf =
+			container_of(nb, struct malidp_interface, nb);
+	struct malidp_device *dp_dev =
+			to_malidp_device(malidp_intf->intf.base.parent);
+	struct video_tx_display_info display_info;
+	int ret;
+
+	switch (cmd) {
+	case connector_status_connected:
+		ret = video_tx_get_display_info(tx, &display_info);
+		if (ret != 0) {
+			dev_err(dp_dev->device, "get display info error\n");
+			return NOTIFY_BAD;
+		}
+
+		malidp_hw_update_color_adjustment(dp_dev->hw_dev,
+				display_info.red_x, display_info.red_y,
+				display_info.green_x, display_info.green_y,
+				display_info.blue_x, display_info.blue_y,
+				display_info.white_x, display_info.white_y);
+
+		malidp_intf->disp_info = display_info;
+
+		malidp_primary_set_modes(dp_dev, malidp_intf);
+
+		dev_dbg(dp_dev->device, "display is connected.\n");
+		break;
+	case connector_status_disconnected:
+		adf_hotplug_notify_disconnected(&malidp_intf->intf);
+		dev_dbg(dp_dev->device, "display is disconnected.\n");
+		break;
+	case connector_status_unknown:
+		break;
+	}
+	return NOTIFY_DONE;
+}
+
+static int malidp_interface_init(struct malidp_device *dp_dev,
+			struct malidp_interface *malidp_intf,
+			const struct malidp_intf_hw_info *hw_info,
+			struct video_tx_device *tx)
+{
+	int ret;
+	struct video_tx_info info;
+
+	init_waitqueue_head(&malidp_intf->wq);
+	atomic_set(&malidp_intf->report_vsync, 0);
+	atomic_set(&malidp_intf->report_flip, 0);
+
+	mutex_init(&malidp_intf->post_lock);
+
+	malidp_intf->mw_latest_cfg = NULL;
+	malidp_intf->mw_prev_cfg = NULL;
+	malidp_intf->mw_latest_fence = NULL;
+	malidp_intf->ops = &malidp_intf_ops[hw_info->type];
+	malidp_intf->hw_info = hw_info;
+	malidp_intf->tx = tx;
+	malidp_intf->prepare_ts = ktime_get();
+
+	switch (hw_info->type) {
+	case MALIDP_HW_INTF_PRIMARY:
+		if (!malidp_intf->tx) {
+			dev_err(dp_dev->device, "%s: primary interface should have a transmitter\n",
+				__func__);
+			return -EINVAL;
+		}
+
+		ret = video_tx_get_info(malidp_intf->tx, &info);
+		if (ret) {
+			dev_err(dp_dev->device, "%s: couldn't query transmitter info\n",
+				__func__);
+			return ret;
+		}
+
+		snprintf(malidp_intf->name, ADF_NAME_LEN, "%s", info.name);
+		malidp_intf->adf_type =
+			malidp_drm_conn_type_to_adf(info.connector_type);
+		malidp_intf->adf_flags = ADF_INTF_FLAG_PRIMARY;
+		malidp_intf->idx = info.idx;
+
+		malidp_hw_set_de_output_depth(dp_dev->hw_dev, info.red_bits,
+					      info.green_bits, info.blue_bits);
+
+		malidp_hw_set_callback(dp_dev->hw_dev, malidp_intf->hw_info,
+				       &malidp_adf_intf_flip_de_cb,
+				       malidp_intf);
+
+		malidp_intf->nb.notifier_call = malidp_adf_notifier_fn;
+		video_tx_hotplug_notifier_register(malidp_intf->tx,
+				&malidp_intf->nb);
+		break;
+	case MALIDP_HW_INTF_MEMORY:
+		snprintf(malidp_intf->name, ADF_NAME_LEN, "%s", hw_info->name);
+		malidp_intf->adf_type = MALIDP_INTF_MEMORY;
+		malidp_intf->adf_flags = ADF_INTF_FLAG_EXTERNAL;
+		malidp_intf->idx = hw_info->idx;
+
+		/* Create a sync timeline for this interface */
+		malidp_intf->mw_timeline =
+			sw_sync_timeline_create(malidp_intf->hw_info->name);
+		if (!malidp_intf->mw_timeline) {
+			dev_err(dp_dev->device,
+				"could not create timeline for interface %s",
+				malidp_intf->hw_info->name);
+			return -ENOMEM;
+		}
+		malidp_intf->mw_timeline_max = 0;
+
+		malidp_hw_set_callback(dp_dev->hw_dev, malidp_intf->hw_info,
+				       &malidp_adf_intf_flip_se_cb,
+				       malidp_intf);
+		break;
+	default:
+		BUG();
+	}
+
+	return 0;
+}
+
+/*
+ * Add an interface to the adf_device. Allocates an interface with the
+ * parameters specified in info, and initialises it on the given adf
+ * device.
+ *
+ * @dp_dev The adf device which the interface will belong to
+ * @hw_info Describes the interface to be instantiated
+ * @tx (optional) A transmitter which should be associated with the interface,
+ *     or NULL if not required.
+ *
+ * Returns the adf object id if successful, an error code (<0) on error.
+ */
+static int malidp_add_interface(struct malidp_device *dp_dev,
+		const struct malidp_intf_hw_info *hw_info,
+		struct video_tx_device *tx)
+{
+	int ret;
+	struct adf_device *dev = &dp_dev->adf_dev;
+	struct malidp_interface *malidp_intf;
+	struct adf_interface *adf_intf;
+
+	malidp_intf = kzalloc(sizeof(struct malidp_interface), GFP_KERNEL);
+	if (NULL == malidp_intf)
+		return -ENOMEM;
+	adf_intf = &malidp_intf->intf;
+
+	ret = malidp_interface_init(dp_dev, malidp_intf, hw_info, tx);
+	if (ret < 0)
+		goto fail;
+
+	ret = adf_interface_init(&malidp_intf->intf, dev,
+			malidp_intf->adf_type, malidp_intf->idx,
+			malidp_intf->adf_flags, malidp_intf->ops,
+			"%s", malidp_intf->name);
+	if (ret)
+		goto fail;
+
+	if (hw_info->type == MALIDP_HW_INTF_PRIMARY &&
+		video_tx_detect(tx) == connector_status_connected)
+		malidp_adf_notifier_fn(&malidp_intf->nb,
+					connector_status_connected,
+					tx);
+
+	return malidp_intf->intf.base.id;
+
+fail:
+	kfree(malidp_intf);
+	return ret;
+}
+
+int malidp_adf_intf_add_interfaces(struct malidp_device *dp_dev,
+		const struct malidp_intf_hw_info *interfaces, u32 n_interfaces,
+		struct video_tx_device *tx)
+{
+	int i, ret = 0;
+
+	for (i = 0; i < n_interfaces; i++) {
+		const struct malidp_intf_hw_info *hw_info = &interfaces[i];
+		switch (hw_info->type) {
+		case MALIDP_HW_INTF_PRIMARY:
+			ret = malidp_add_interface(dp_dev, hw_info, tx);
+			break;
+		case MALIDP_HW_INTF_MEMORY:
+			ret = malidp_add_interface(dp_dev, hw_info, NULL);
+			break;
+		default:
+			BUG();
+		}
+		if (ret < 0)
+			return ret;
+	}
+
+	return 0;
+}
+
+static int malidp_intf_destroy_cb(int id, void *p, void *opaque)
+{
+	struct adf_interface *intf = (struct adf_interface *)p;
+	struct malidp_interface *malidp_intf =
+			to_malidp_interface(intf);
+
+	dev_dbg(&intf->base.dev, "%s : Destroying interface %s-%i\n",
+			__func__, adf_interface_type_str(intf),
+			intf->idx);
+
+	adf_interface_blank(intf, DRM_MODE_DPMS_OFF);
+
+	if (malidp_adf_intf_get_dp_type(intf) == MALIDP_HW_INTF_MEMORY) {
+		/*
+		* sw_sync implementation should export something to destroy
+		* a sw fence instead.
+		*/
+		sync_timeline_destroy(&malidp_intf->mw_timeline->obj);
+	} else
+		video_tx_hotplug_notifier_unregister(malidp_intf->tx,
+			&malidp_intf->nb);
+
+	adf_interface_destroy(intf);
+	kfree(malidp_intf);
+
+	return 0;
+}
+
+int malidp_adf_intf_destroy_interfaces(struct malidp_device *dp_dev)
+{
+	struct adf_device *adf_dev = &dp_dev->adf_dev;
+
+	return idr_for_each(&adf_dev->interfaces, malidp_intf_destroy_cb,
+			NULL);
+}
+
+static int is_interface_primary(int id, void *p, void *data)
+{
+	struct adf_interface *intf = (struct adf_interface *)p;
+
+	if (malidp_adf_intf_get_dp_type(intf) == MALIDP_HW_INTF_PRIMARY) {
+		*((struct adf_interface **)data) = intf;
+		return 1;
+	}
+	return 0;
+}
+
+static struct adf_interface *find_primary_intf(struct malidp_device *dev)
+{
+	struct adf_interface *intf = NULL;
+	idr_for_each(&dev->adf_dev.interfaces, is_interface_primary, &intf);
+	return intf;
+}
+
+void malidp_adf_intf_restore_drmmode(struct malidp_device *dev)
+{
+	struct adf_interface *intf = find_primary_intf(dev);
+
+	if (malidp_adf_intf_validate_mode(dev, &intf->current_mode) == true)
+		malidp_hw_modeset(dev->hw_dev, &intf->current_mode);
+}
diff --git a/drivers/video/adf/arm/malidp_adf_interface.h b/drivers/video/adf/arm/malidp_adf_interface.h
new file mode 100644
index 0000000..4f49bec
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_adf_interface.h
@@ -0,0 +1,62 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_ADF_INTERFACE_H_
+#define _MALIDP_ADF_INTERFACE_H_
+
+#include <uapi/video/malidp_adf.h>
+#include <uapi/video/adf.h>
+#include <video/adf.h>
+#include <video/video_tx.h>
+
+#include "malidp_drv.h"
+#include "malidp_hw.h"
+#include "malidp_iommu.h"
+
+struct malidp_intf_memory_cfg {
+	struct sync_fence *mw_fence;
+	struct adf_buffer *mw_buf;
+	struct adf_buffer_mapping *mw_map;
+	struct malidp_iommu_mapping **iommu_map;
+	int mw_buf_index;
+	bool signaled;
+};
+
+struct malidp_intf_memory_cfg *malidp_intf_create_mw_cfg(struct adf_interface *adf_intf,
+				     struct malidp_device *dp_dev,
+				     struct adf_buffer *buf, int buf_index,
+				     struct adf_buffer_mapping *map,
+				     struct malidp_iommu_mapping **iommu_map);
+
+void malidp_adf_intf_destroy_mw_cfg(struct adf_interface *adf_intf,
+				struct malidp_intf_memory_cfg *mw_cfg);
+
+void malidp_intf_wait(struct adf_interface *adf_intf,
+			      struct malidp_device *dp_dev);
+
+void malidp_intf_prepare(struct adf_interface *adf_intf,
+			 struct malidp_intf_memory_cfg *mw_cfg);
+
+int malidp_adf_intf_get_dp_type(struct adf_interface *adf_intf);
+
+int malidp_adf_intf_add_interfaces(struct malidp_device *dp_dev,
+		const struct malidp_intf_hw_info *interfaces, u32 n_interfaces,
+		struct video_tx_device *tx);
+int malidp_adf_intf_destroy_interfaces(struct malidp_device *dp_dev);
+
+void malidp_adf_intf_restore_drmmode(struct malidp_device *dev);
+#endif /* _MALIDP_ADF_INTERFACE_H_ */
diff --git a/drivers/video/adf/arm/malidp_adf_overlay.c b/drivers/video/adf/arm/malidp_adf_overlay.c
new file mode 100644
index 0000000..fe48e6d
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_adf_overlay.c
@@ -0,0 +1,154 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <video/adf.h>
+#include <uapi/video/malidp_adf.h>
+
+#include "malidp_adf.h"
+
+/* Private, driver-specific overlay structure */
+struct malidp_overlay {
+	struct adf_overlay_engine eng;
+	struct adf_overlay_engine_ops ops;
+	const struct malidp_layer_hw_info *hw_info;
+};
+
+#define to_malidp_overlay(adf_eng) container_of(adf_eng, \
+		struct malidp_overlay, eng)
+
+const struct malidp_layer_hw_info *malidp_adf_ovr_get_hw_layer(struct adf_overlay_engine *eng)
+{
+	struct malidp_overlay *malidp_ovl = to_malidp_overlay(eng);
+
+	return malidp_ovl->hw_info;
+}
+
+static int malidp_ovr_custom_data(struct adf_obj *obj, void *vdata, size_t *size)
+{
+	struct adf_overlay_engine *ovl = adf_obj_to_overlay_engine(obj);
+	struct malidp_overlay *malidp_ovl = to_malidp_overlay(ovl);
+	struct malidp_adf_overlay_custom_data *data = vdata;
+
+	memset(data, 0, sizeof(*data));
+
+	data->supports_scaling = malidp_ovl->hw_info->features &
+		MALIDP_LAYER_FEATURE_SCALING;
+	data->features = malidp_ovl->hw_info->features;
+	data->n_supported_layers = malidp_ovl->hw_info->n_supported_layers;
+
+	*size = sizeof(*data);
+
+	return 0;
+}
+
+static const struct adf_overlay_engine_ops malidp_ovr_ops = {
+	.base = {
+		.custom_data = malidp_ovr_custom_data,
+	},
+};
+
+static int malidp_ovr_hw_info_to_adf(struct malidp_overlay *malidp_ovl,
+				     const struct malidp_layer_hw_info *hw_info)
+{
+	size_t *ptr_n_supported_formats = (size_t *)&malidp_ovl->ops.n_supported_formats;
+	struct adf_overlay_engine_ops *ops = (struct adf_overlay_engine_ops *)&malidp_ovl->ops;
+
+	/* Assign ops */
+	memcpy(ops, &malidp_ovr_ops, sizeof(*ops));
+	*ptr_n_supported_formats = hw_info->n_supported_formats;
+	malidp_ovl->ops.supported_formats = hw_info->supported_formats;
+
+	malidp_ovl->hw_info = hw_info;
+
+	return 0;
+}
+
+/*
+ * Add a layer to the adf_device. Allocates an overlay engine with the
+ * parameters of the specified type, and initialises it on the given adf
+ * device.
+ *
+ * @dev: The adf device which the overlay engine will belong to
+ * @info: The HW description of the layer to add
+ *
+ * Returns the adf object id if successful, an error code (<0) on error.
+ */
+static int malidp_add_layer(struct malidp_device *dp_dev,
+		const struct malidp_layer_hw_info *info)
+{
+	struct adf_device *dev = &dp_dev->adf_dev;
+	struct malidp_overlay *malidp_ovl;
+	int ret;
+
+	malidp_ovl = kzalloc(sizeof(struct malidp_overlay), GFP_KERNEL);
+	if (!malidp_ovl)
+		return -ENOMEM;
+
+	/* Convert HW layer information into ADF information */
+	ret = malidp_ovr_hw_info_to_adf(malidp_ovl, info);
+	if (ret < 0)
+		goto fail;
+
+	ret = adf_overlay_engine_init(&malidp_ovl->eng, dev, &malidp_ovl->ops,
+			"%s", malidp_ovl->hw_info->name);
+	if (ret)
+		goto fail;
+
+	return malidp_ovl->eng.base.id;
+
+fail:
+	kfree(malidp_ovl);
+
+	return ret;
+}
+
+int malidp_adf_ovr_add_layers(struct malidp_device *dp_dev,
+		const struct malidp_layer_hw_info *layers, int n_layers)
+{
+	int i, ret = 0;
+
+	for (i = 0; i < n_layers; i++) {
+		ret = malidp_add_layer(dp_dev, &layers[i]);
+		if (ret < 0)
+			return ret;
+	}
+	return 0;
+}
+
+static int malidp_eng_destroy_cb(int id, void *p, void *opaque)
+{
+	struct adf_overlay_engine *eng = (struct adf_overlay_engine *)p;
+	struct malidp_overlay *ovl = to_malidp_overlay(eng);
+
+	dev_dbg(&eng->base.dev, "Destroying overlay engine %s\n", eng->base.name);
+
+	adf_overlay_engine_destroy(eng);
+	kfree(ovl);
+
+	return 0;
+}
+
+int malidp_adf_ovr_destroy_layers(struct malidp_device *dp_dev)
+{
+	struct adf_device *adf_dev = &dp_dev->adf_dev;
+
+	return idr_for_each(&adf_dev->overlay_engines, malidp_eng_destroy_cb,
+			NULL);
+}
+
diff --git a/drivers/video/adf/arm/malidp_adf_overlay.h b/drivers/video/adf/arm/malidp_adf_overlay.h
new file mode 100644
index 0000000..8c3f5ea
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_adf_overlay.h
@@ -0,0 +1,28 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2014 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_ADF_OVERLAY_H_
+#define _MALIDP_ADF_OVERLAY_H_
+
+const struct malidp_layer_hw_info *malidp_adf_ovr_get_hw_layer(struct adf_overlay_engine *eng);
+
+int malidp_adf_ovr_add_layers(struct malidp_device *dp_dev,
+		const struct malidp_layer_hw_info *layers, int n_layers);
+
+int malidp_adf_ovr_destroy_layers(struct malidp_device *dp_dev);
+
+#endif /* _MALIDP_ADF_OVERLAY_H_ */
diff --git a/drivers/video/adf/arm/malidp_de_device.c b/drivers/video/adf/arm/malidp_de_device.c
new file mode 100644
index 0000000..ace2b10
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_de_device.c
@@ -0,0 +1,1213 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/clk.h>
+#include <linux/ioport.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/platform_device.h>
+#include <linux/io.h>
+#include <asm/uaccess.h>
+#include <uapi/drm/drm_mode.h>
+#include <uapi/drm/drm_fourcc.h>
+#include <uapi/video/malidp_adf.h>
+
+#include "malidp_hw_types.h"
+#include "malidp_product_api.h"
+#include "malidp_de_device.h"
+
+#define DE_N_QUEUE_EVENTS 24
+
+#define DE_N_YUV2RGB_COEFFS 12
+#define DE_MAX_OUT_DEPTH 12
+#define DE_MIN_OUT_DEPTH 5
+
+const char *const op_mode_name[] = {
+	"MODE_NORMAL",
+	"MODE_CONFIG",
+	"MODE_POWERSAVE",
+	"MODE_TEST",
+	"MODE_UNKNOWN",
+};
+
+static const s32 malidp_de_bt601_narrow_coeffs[DE_N_YUV2RGB_COEFFS] = {
+	1192,    0, 1634,
+	1192, -401, -832,
+	1192, 2066,    0,
+
+	  64,  512,  512
+};
+
+static const s32 malidp_de_bt601_wide_coeffs[DE_N_YUV2RGB_COEFFS] = {
+	1024,    0, 1436,
+	1024, -352, -731,
+	1024, 1815,    0,
+
+	   0,  512,  512
+};
+
+static const s32 malidp_de_bt709_narrow_coeffs[DE_N_YUV2RGB_COEFFS] = {
+	1192,    0, 1836,
+	1192, -218, -546,
+	1192, 2163,    0,
+
+	  64,  512,  512
+};
+
+static const s32 malidp_de_bt709_wide_coeffs[DE_N_YUV2RGB_COEFFS] = {
+	1024,    0, 1613,
+	1024, -192, -479,
+	1024, 1900,    0,
+
+	   0,  512,  512
+};
+
+
+void malidp_de_write(struct malidp_de_device *dev,
+					  u32 value, u32 reg)
+{
+	writel(value, dev->regs + reg);
+}
+
+u32 malidp_de_read(struct malidp_de_device *dev, u32 reg)
+{
+	return readl(dev->regs + reg);
+}
+
+void malidp_de_setbits(struct malidp_de_device *dev, u32 mask,
+				     u32 reg)
+{
+	u32 data = malidp_de_read(dev, reg);
+	data |= mask;
+	malidp_de_write(dev, data, reg);
+}
+
+void malidp_de_clearbits(struct malidp_de_device *dev,
+				       u32 mask, u32 reg)
+{
+	u32 data = malidp_de_read(dev, reg);
+	data &= ~mask;
+	malidp_de_write(dev, data, reg);
+}
+
+static const struct malidp_layer_hw_info *
+malidp_de_get_layers(struct malidp_de_device *dev, int *n_layer)
+{
+	if (n_layer != NULL)
+		*n_layer = dev->hwdev->topology->n_layers;
+
+	return dev->hwdev->topology->layers;
+}
+
+/* Write the alpha lookup tables providing a linear interpolation */
+void malidp_de_write_alpha_lookup(struct malidp_de_device *dev)
+{
+	/* Write the alpha lookup table for all the layers */
+	const struct malidp_layer_hw_info *hw_layers;
+	int n_layers, i;
+
+	hw_layers = malidp_de_get_layers(dev, &n_layers);
+	for (i = 0; i < n_layers; i++) {
+		if (hw_layers[i].type != MALIDP_HW_LAYER_SMART) {
+			malidp_de_write(dev, DE_L_ALPHA3(255) | DE_L_ALPHA2(170) |
+					DE_L_ALPHA1(85) | DE_L_ALPHA0(0),
+					hw_layers[i].regs_base + DE_REG_L_COMPOSE);
+		}
+	}
+}
+
+
+irqreturn_t malidp_de_irq_thread_handler(int irq, void *data)
+{
+	struct malidp_de_device *dev = data;
+	void (*callback)(struct device *, void *, struct malidp_hw_event_queue *);
+	void *callback_opaque;
+	unsigned long flags;
+
+	spin_lock_irqsave(dev->hw_lock, flags);
+	callback = dev->flip_callback;
+	callback_opaque = dev->callback_opaque;
+	spin_unlock_irqrestore(dev->hw_lock, flags);
+
+	if (callback)
+		callback(dev->device, callback_opaque, dev->ev_queue);
+
+	return IRQ_HANDLED;
+}
+
+static int malidp_de_mode_drm2hw(struct malidp_de_device *dev,
+					 struct drm_mode_modeinfo *mode,
+					 struct malidp_de_hwmode *hwmode)
+{
+	/* Initialize the structure */
+	memset(hwmode, 0, sizeof(*hwmode));
+
+	/* Sanity checks */
+	if (mode->flags & DRM_MODE_FLAG_INTERLACE) {
+		dev_err(dev->device, "interlace mode not supported\n");
+		return -1;
+	}
+
+	/* drm_mode_modeinfo clocks are specified in kHz */
+	hwmode->clock = mode->clock * 1000;
+
+	hwmode->h_active = mode->hdisplay;
+	hwmode->hfp = mode->hsync_start - mode->hdisplay;
+	hwmode->hsw = mode->hsync_end - mode->hsync_start;
+	hwmode->hbp = mode->htotal - mode->hsync_end;
+
+	hwmode->v_active = mode->vdisplay;
+	hwmode->vfp = mode->vsync_start - mode->vdisplay;
+	hwmode->vsw = mode->vsync_end - mode->vsync_start;
+	hwmode->vbp = mode->vtotal - mode->vsync_end;
+
+	if (mode->flags & DRM_MODE_FLAG_PHSYNC)
+		hwmode->hsync_pol_pos = 1;
+
+	if (mode->flags & DRM_MODE_FLAG_PVSYNC)
+		hwmode->vsync_pol_pos = 1;
+
+	return 0;
+}
+
+int malidp_de_fmt_drm2hw(struct malidp_de_device *dev,
+		struct malidp_hw_buffer *buf)
+{
+	int i, idx;
+	int n_fmts = buf->hw_layer->n_supported_formats;
+	const u32 *fmts = buf->hw_layer->supported_formats;
+	const u32 *ids = buf->hw_layer->format_ids;
+	u32 drm_fmt = dev->hwdev->dp_api->de_api.fmt_fixup(buf->fmt, buf->flags);
+
+	for (i = 0; i < n_fmts; i++) {
+		if (ids)
+			idx = ids[i];
+		else
+			idx = i;
+
+		if (fmts[i] == drm_fmt)
+			return idx;
+	}
+
+	return -1;
+}
+
+void malidp_de_set_flip_callback(struct malidp_de_device *dev,
+		void (*callback)(struct device *, void *, struct malidp_hw_event_queue *),
+		void *opaque)
+{
+	dev->flip_callback = callback;
+	dev->callback_opaque = opaque;
+}
+
+void malidp_de_set_coeftab(struct malidp_de_device *dev,
+		u32 table, const u32 *coeffs)
+{
+	u32 i;
+	u16 coloradj = dev->de_regmap->coloradj_coeff;
+
+	malidp_de_write(dev, table | DE_COEFTAB_INTAB_ADDR(0),
+			coloradj + DE_REG_COEFTAB_ADDR);
+
+	for (i = 0; i < DE_N_COEFTAB_COEFS; i++)
+		malidp_de_write(dev, coeffs[i], coloradj + DE_REG_COEFTAB_DATA);
+}
+
+static void malidp_de_set_yuv2rgb_coeffs(struct malidp_de_device *dev,
+		struct malidp_hw_buffer *buf)
+{
+	int i;
+	u32 coeff_off = 0;
+	const s32 *coeffs;
+	const struct malidp_layer_hw_info *layer = buf->hw_layer;
+
+	dev_dbg(dev->device, "%s", __func__);
+
+	switch (buf->flags & MALIDP_FLAG_YUV_MASK) {
+	case (MALIDP_FLAG_YUV_BT601 | MALIDP_FLAG_YUV_NARROW):
+		coeffs = malidp_de_bt601_narrow_coeffs;
+		break;
+	case (MALIDP_FLAG_YUV_BT601 | MALIDP_FLAG_YUV_WIDE):
+		coeffs = malidp_de_bt601_wide_coeffs;
+		break;
+	case (MALIDP_FLAG_YUV_BT709 | MALIDP_FLAG_YUV_NARROW):
+		coeffs = malidp_de_bt709_narrow_coeffs;
+		break;
+	case (MALIDP_FLAG_YUV_BT709 | MALIDP_FLAG_YUV_WIDE):
+		coeffs = malidp_de_bt709_wide_coeffs;
+		break;
+	default:
+		BUG();
+	}
+
+	coeff_off = layer->yuv2rgb_reg_offset;
+	BUG_ON(coeff_off == 0);
+
+	if (coeffs != dev->yuv2rgb_coeffs[layer->index]) {
+		dev->yuv2rgb_coeffs[layer->index] = coeffs;
+		dev_dbg(dev->device, "%s : changing coefficients", __func__);
+		/*
+		 * This assumes the coefficient registers are adjacent in the
+		 * register map
+		 */
+		for (i = 0; i < DE_N_YUV2RGB_COEFFS; i++) {
+			malidp_de_write(dev, coeffs[i],
+					coeff_off + (i * 4));
+		}
+	}
+}
+
+void malidp_de_cfg_cmp_flow(struct malidp_de_device *dev,
+			enum malidp_de_flow_cmp_cfg cfg)
+{
+	const struct malidp_de_regmap *reg = dev->de_regmap;
+
+	malidp_de_clearbits(dev, DE_SET_FLOWCFG(DE_SET_FLOWCFG_MASK),
+			    reg->disp_func);
+	malidp_de_setbits(dev, DE_SET_FLOWCFG(cfg), reg->disp_func);
+}
+
+void malidp_de_cfg_layer_flow(struct malidp_de_device *dev,
+			const struct malidp_layer_hw_info *hw_layer,
+			enum malidp_de_flow_layer_cfg cfg)
+{
+	int loff = hw_layer->regs_base;
+
+	if (!(hw_layer->features & MALIDP_LAYER_FEATURE_SCALING))
+		return;
+
+	malidp_de_clearbits(dev, DE_L_FCFG(DE_L_FCFG_MASK),
+			    loff + DE_REG_L_CONTROL);
+	malidp_de_setbits(dev, DE_L_FCFG(cfg), loff + DE_REG_L_CONTROL);
+}
+
+enum malidp_de_flow_layer_cfg malidp_de_get_layer_flow(struct malidp_de_device *dev,
+							const struct malidp_layer_hw_info *hw_layer)
+{
+	int loff = hw_layer->regs_base;
+	u32 data;
+
+	if (!(hw_layer->features & MALIDP_LAYER_FEATURE_SCALING))
+		return MALIDP_DE_LAYER_FLOW_LOCAL;
+
+	data = malidp_de_read(dev, loff + DE_REG_L_CONTROL);
+
+	return DE_GET_L_FCFG(data);
+}
+
+static int malidp_de_set_alpha(struct malidp_de_device *dev,
+		struct malidp_hw_buffer *buf)
+{
+	int loff = buf->hw_layer->regs_base;
+	uint32_t mask = DE_L_PREMULT | DE_L_COMPOSE_BG | DE_L_COMPOSE_PIXEL | DE_L_ALPHA(0xFF);
+	uint32_t value = DE_L_ALPHA(buf->layer_alpha);
+
+	if (buf->alpha_mode & MALIDP_ALPHA_MODE_NONE) {
+		value = DE_L_COMPOSE_BG | DE_L_ALPHA(0xFF);
+	} else {
+		if (buf->alpha_mode & MALIDP_ALPHA_MODE_PIXEL)
+			value |= DE_L_COMPOSE_PIXEL;
+		if (buf->alpha_mode & MALIDP_ALPHA_MODE_W_BG)
+			value |= DE_L_COMPOSE_BG;
+		if (buf->alpha_mode & MALIDP_ALPHA_MODE_PREMULT)
+			value |= DE_L_PREMULT;
+	}
+
+	malidp_de_clearbits(dev, mask, loff + DE_REG_L_CONTROL);
+	dev_dbg(dev->device, "%s : Setting alpha bits: 0x%08x", __func__, value);
+	malidp_de_setbits(dev, value, loff + DE_REG_L_CONTROL);
+
+	return 0;
+}
+
+void malidp_de_cfg_smart_state(struct malidp_de_device *dev,
+			const struct malidp_hw_smart_layer_state *ls_state)
+{
+	int loff = ls_state->ls_hw_layer->regs_base;
+	u16 bbox_width, bbox_height;
+
+	bbox_width = ls_state->ls_bbox_right - ls_state->ls_bbox_left;
+	bbox_height = ls_state->ls_bbox_bottom - ls_state->ls_bbox_top;
+
+	malidp_de_write(dev, (DE_L_SIZE_V(bbox_height) | DE_L_SIZE_H(bbox_width)),
+			loff + DE_REG_L_SIZE);
+	malidp_de_write(dev, (DE_L_SIZE_V(bbox_height) | DE_L_SIZE_H(bbox_width)),
+			loff + DE_REG_L_SIZE_CMP);
+	malidp_de_write(dev, (DE_L_OFFSET_V(ls_state->ls_bbox_top) | DE_L_OFFSET_H(ls_state->ls_bbox_left)),
+			loff + DE_REG_L_OFFSET);
+	malidp_de_write(dev, ls_state->ls_bbox_argb, loff + DE_REG_LS_BBOX_ARGB);
+
+	/* Enable layer */
+	malidp_de_write(dev, DE_LS_EN_NUM(ls_state->n_smart_layers),
+			  loff + DE_REG_LS_ENABLE);
+	malidp_de_setbits(dev, DE_L_EN, loff + DE_REG_L_CONTROL);
+
+	dev->scene_changing = true;
+}
+
+static int malidp_de_cfg_smart_layer(struct malidp_de_device *dev,
+				     struct malidp_hw_buffer *buf)
+{
+	const struct malidp_layer_hw_info *hw_layer = buf->hw_layer;
+	const u32 ls_rect_reg_offset = buf->ls_rect_idx * DE_REG_LS_Rn_ADDR_DELTA;
+	const u32 ls_rn_in_size = hw_layer->ls_r1_in_size + ls_rect_reg_offset;
+	const u32 ls_rn_offset  = hw_layer->ls_r1_offset + ls_rect_reg_offset;
+	const u32 ls_rn_stride  = hw_layer->ls_r1_stride + ls_rect_reg_offset;
+	const u32 ls_rn_ptr_low = hw_layer->ls_r1_ptr_low + ls_rect_reg_offset;
+	const u32 ls_rn_ptr_high = hw_layer->ls_r1_ptr_high + ls_rect_reg_offset;
+	int loff = hw_layer->regs_base;
+
+	/* Sizes and offset */
+	malidp_de_write(dev, (DE_L_SIZE_V(buf->natural_h) | DE_L_SIZE_H(buf->natural_w)),
+			loff + ls_rn_in_size);
+	malidp_de_write(dev, (DE_L_OFFSET_V(buf->v_offset) | DE_L_OFFSET_H(buf->h_offset)),
+			loff + ls_rn_offset);
+
+	/* Only need set format and alpha of the first buffer because all the smart
+	 * layers are sharing a same format and alpha. */
+	if (buf->ls_rect_idx == 0) {
+		malidp_de_set_alpha(dev, buf);
+		malidp_de_clearbits(dev, DE_L_IGEN, loff + DE_REG_L_CONTROL);
+		if (buf->flags & MALIDP_FLAG_SRGB) {
+			malidp_de_clearbits(dev, DE_L_IGSEL_MASK,
+				loff + DE_REG_L_CONTROL);
+			malidp_de_setbits(dev, DE_L_IGEN | DE_L_IGSEL_SRGB,
+				loff + DE_REG_L_CONTROL);
+		}
+		malidp_de_clearbits(dev, DE_L_SET_FMT(DE_L_FMT_MASK),
+				    loff + DE_REG_L_FORMAT);
+		malidp_de_setbits(dev, DE_L_SET_FMT(buf->hw_fmt),
+				  loff + DE_REG_L_FORMAT);
+	}
+
+	/* Set HW pointers */
+	if (buf->n_planes > buf->hw_layer->n_max_planes)
+		return -EINVAL;
+
+	malidp_de_write(dev, buf->pitch[0], loff + ls_rn_stride);
+	malidp_de_write(dev, lower_32_bits(buf->addr[0]), loff + ls_rn_ptr_low);
+	malidp_de_write(dev, upper_32_bits(buf->addr[0]), loff + ls_rn_ptr_high);
+
+	return 0;
+}
+
+int malidp_de_cfg_layer(struct malidp_de_device *dev,
+			struct malidp_hw_buffer *buf)
+{
+	int loff = buf->hw_layer->regs_base;
+	bool fmt_is_yuv;
+	u32 w, h;
+	u32 comp_w, comp_h;
+
+	if (buf->hw_layer->type == MALIDP_HW_LAYER_SMART) {
+		return malidp_de_cfg_smart_layer(dev, buf);
+	}
+
+	comp_w = buf->cmp_rect.dest_w;
+	comp_h = buf->cmp_rect.dest_h;
+	w = buf->natural_w;
+	h = buf->natural_h;
+
+	malidp_de_clearbits(dev, DE_AD_EN | DE_AD_YTR | DE_AD_BS, buf->hw_layer->ad_ctrl_reg);
+	if (buf->flags & MALIDP_FLAG_AFBC) {
+		u32 ytr = buf->flags & MALIDP_FLAG_AFBC_YTR ? DE_AD_YTR : 0;
+		u32 bs = buf->flags & MALIDP_FLAG_AFBC_SPLITBLK ? DE_AD_BS : 0;
+		u32 crop_h, crop_v;
+
+		w = buf->natural_w + buf->afbc_crop_l + buf->afbc_crop_r;
+		h = buf->natural_h + buf->afbc_crop_t + buf->afbc_crop_b;
+
+		dev_dbg(dev->device, "%s : configuring for AFBC buffer", __func__);
+
+		crop_h = DE_AD_CROP_RIGHT(buf->afbc_crop_r) | DE_AD_CROP_LEFT(buf->afbc_crop_l);
+		crop_v = DE_AD_CROP_BOTTOM(buf->afbc_crop_b) | DE_AD_CROP_TOP(buf->afbc_crop_t);
+
+		malidp_de_write(dev, crop_h, buf->hw_layer->ad_crop_h_reg);
+		malidp_de_write(dev, crop_v, buf->hw_layer->ad_crop_v_reg);
+		malidp_de_setbits(dev, DE_AD_EN | ytr | bs, buf->hw_layer->ad_ctrl_reg);
+
+		dev_dbg(dev->device, "%s : dimensions: %ix%i, crop: 0x%08x, 0x%08x",
+				__func__, w, h, crop_h, crop_v);
+	}
+
+	/* Transform */
+	malidp_de_clearbits(dev, DE_L_TRANS_MASK, loff + DE_REG_L_CONTROL);
+	malidp_de_setbits(dev, DE_L_SET_TRANS(buf->transform), loff + DE_REG_L_CONTROL);
+
+	/* Sizes and offset */
+	malidp_de_write(dev, (DE_L_SIZE_V(h) | DE_L_SIZE_H(w)),
+			loff + DE_REG_L_SIZE);
+	malidp_de_write(dev, (DE_L_SIZE_V(comp_h) | DE_L_SIZE_H(comp_w)),
+			loff + DE_REG_L_SIZE_CMP);
+	malidp_de_write(dev, (DE_L_OFFSET_V(buf->v_offset) | DE_L_OFFSET_H(buf->h_offset)),
+			loff + DE_REG_L_OFFSET);
+
+	/* Set format of the buffer */
+	malidp_de_clearbits(dev, DE_L_SET_FMT(DE_L_FMT_MASK),
+			    loff + DE_REG_L_FORMAT);
+	malidp_de_setbits(dev, DE_L_SET_FMT(buf->hw_fmt),
+			  loff + DE_REG_L_FORMAT);
+
+	/* Set up alpha blending */
+	if (malidp_de_set_alpha(dev, buf) < 0)
+		return -EINVAL;
+
+	/* Set YUV coefficients if necessary */
+	fmt_is_yuv = malidp_hw_format_is_yuv(buf->fmt);
+	if (fmt_is_yuv)
+		malidp_de_set_yuv2rgb_coeffs(dev, buf);
+
+	/* Set inverse gamma/sRGB */
+	if (buf->flags & MALIDP_FLAG_SRGB) {
+		malidp_de_clearbits(dev, DE_L_IGSEL_MASK,
+			loff + DE_REG_L_CONTROL);
+		malidp_de_setbits(dev, DE_L_IGEN | DE_L_IGSEL_SRGB,
+			loff + DE_REG_L_CONTROL);
+	} else if (fmt_is_yuv && !(buf->flags & MALIDP_FLAG_FORCE_NO_IGAMMA)) {
+		dev_dbg(dev->device, "%s : enabling inverse gamma\n",
+			__func__);
+		if (malidp_hw_buf_support_srgb(buf) == true)
+			malidp_de_clearbits(dev, DE_L_IGSEL_MASK,
+				loff + DE_REG_L_CONTROL);
+		malidp_de_setbits(dev, DE_L_IGEN, loff + DE_REG_L_CONTROL);
+	} else {
+		dev_dbg(dev->device, "%s : disabling inverse gamma\n",
+			__func__);
+		malidp_de_clearbits(dev, DE_L_IGEN, loff + DE_REG_L_CONTROL);
+	}
+
+	/* Set HW pointers */
+	if (buf->n_planes > buf->hw_layer->n_max_planes)
+		return -EINVAL;
+
+	switch (buf->n_planes) {
+	case 3:
+		if (buf->hw_layer->p3_stride_offset)
+			malidp_de_write(dev, buf->pitch[2], loff + buf->hw_layer->p3_stride_offset);
+		malidp_de_write(dev, lower_32_bits(buf->addr[2]), loff + DE_REG_LV3_PTR0_LOW);
+		malidp_de_write(dev, upper_32_bits(buf->addr[2]), loff + DE_REG_LV3_PTR0_HIGH);
+		/* Fallthrough */
+	case 2:
+		malidp_de_write(dev, buf->pitch[1], loff + DE_REG_LV2_STRIDE);
+		malidp_de_write(dev, lower_32_bits(buf->addr[1]), loff + DE_REG_LV2_PTR0_LOW);
+		malidp_de_write(dev, upper_32_bits(buf->addr[1]), loff + DE_REG_LV2_PTR0_HIGH);
+		/* Fallthrough */
+	case 1:
+		malidp_de_write(dev, buf->pitch[0],
+				loff + buf->hw_layer->stride_offset);
+		malidp_de_write(dev, lower_32_bits(buf->addr[0]),
+				loff + buf->hw_layer->ptr0_low_offset);
+		malidp_de_write(dev, upper_32_bits(buf->addr[0]),
+				loff + buf->hw_layer->ptr0_high_offset);
+	}
+
+	/* Enable layer */
+	malidp_de_setbits(dev, DE_L_EN, loff + DE_REG_L_CONTROL);
+
+	dev->scene_changing = true;
+
+	return 0;
+}
+
+void malidp_de_disable_all_layers(struct malidp_de_device *dev)
+{
+	const struct malidp_layer_hw_info *hw_layers;
+	int n_layers, i;
+
+	hw_layers = malidp_de_get_layers(dev, &n_layers);
+	for (i = 0; i < n_layers; i++)
+		malidp_de_clearbits(dev, DE_L_EN,
+			hw_layers[i].regs_base + DE_REG_L_CONTROL);
+}
+
+void malidp_de_cleanup_yuv2rgb_coeffs(struct malidp_de_device *dev)
+{
+	int i;
+
+	for (i = 0; i < MALIDP_MAX_LAYERS; i++)
+		dev->yuv2rgb_coeffs[i] = NULL;
+}
+
+void malidp_de_store_output_depth(struct malidp_de_device *dev,
+	u8 red, u8 green, u8 blue)
+{
+	if ((red > DE_MAX_OUT_DEPTH) || (green > DE_MAX_OUT_DEPTH) ||
+	    (blue > DE_MAX_OUT_DEPTH)) {
+		dev_warn(dev->device, "%s : depth exceeds maximum (%d), values will be truncated\n",
+			 __func__, DE_MAX_OUT_DEPTH);
+		if (red > DE_MAX_OUT_DEPTH)
+			red = DE_MAX_OUT_DEPTH;
+		if (green > DE_MAX_OUT_DEPTH)
+			green = DE_MAX_OUT_DEPTH;
+		if (blue > DE_MAX_OUT_DEPTH)
+			blue = DE_MAX_OUT_DEPTH;
+	}
+	if ((red < DE_MIN_OUT_DEPTH) || (green < DE_MIN_OUT_DEPTH) ||
+	    (blue < DE_MIN_OUT_DEPTH)) {
+		dev_warn(dev->device, "%s : depth is less than minimum (%d), values will be increased\n",
+			 __func__, DE_MIN_OUT_DEPTH);
+		if (red < DE_MIN_OUT_DEPTH)
+			red = DE_MIN_OUT_DEPTH;
+		if (green < DE_MIN_OUT_DEPTH)
+			green = DE_MIN_OUT_DEPTH;
+		if (blue < DE_MIN_OUT_DEPTH)
+			blue = DE_MIN_OUT_DEPTH;
+	}
+
+	dev->red_bits = red;
+	dev->green_bits = green;
+	dev->blue_bits = blue;
+}
+
+static void malidp_de_set_output_depth(struct malidp_de_device *dev)
+{
+	const struct malidp_de_regmap *reg = dev->de_regmap;
+
+	malidp_de_write(dev, DE_OUT_DEPTH_R(dev->red_bits) |
+			DE_OUT_DEPTH_G(dev->green_bits) |
+			DE_OUT_DEPTH_B(dev->blue_bits),
+			reg->output_depth);
+}
+
+int malidp_de_modeset(struct malidp_de_device *dev,
+			     struct drm_mode_modeinfo *mode)
+{
+	struct malidp_de_hwmode hwmode;
+	int ret;
+	u32 reg_addr;
+	const struct malidp_de_regmap *reg = dev->de_regmap;
+	const struct malidp_de_product_api *de_api =
+				&dev->hwdev->dp_api->de_api;
+
+	ret = malidp_de_mode_drm2hw(dev, mode, &hwmode);
+	if (ret < 0)
+		return ret;
+
+	de_api->modeset(dev, &hwmode);
+	memcpy(&dev->current_mode, mode, sizeof(struct drm_mode_modeinfo));
+
+	/* Set up dithering */
+	malidp_de_set_output_depth(dev);
+
+	/* Program the gamma coefficients table */
+	if (dev->gamma_enabled) {
+		malidp_de_clearbits(dev, DE_GAMMA_EN, reg->disp_func);
+		de_api->set_gamma_coeff(dev, dev->gamma_coeffs);
+		malidp_de_setbits(dev, DE_GAMMA_EN, reg->disp_func);
+	} else {
+		malidp_de_clearbits(dev, DE_GAMMA_EN, reg->disp_func);
+	}
+
+	/* Writing color adjustments coefficients */
+	malidp_de_clearbits(dev, DE_CADJ_EN, reg->disp_func);
+	reg_addr = reg->coloradj_coeff;
+	for (ret = 0; ret < DE_N_COLORADJ_COEFS; ret++) {
+		malidp_de_write(dev, dev->color_adjustment_coeffs[ret],
+			reg_addr);
+		reg_addr += 4;
+	}
+	malidp_de_setbits(dev, DE_CADJ_EN, reg->disp_func);
+
+	/* Disable the layers to make sure we don't try to show a bad scene */
+	malidp_de_disable_all_layers(dev);
+
+	return 0;
+}
+
+void malidp_de_modeget(struct malidp_de_device *dev,
+		       struct drm_mode_modeinfo *mode)
+{
+	memcpy(mode, &dev->current_mode, sizeof(struct drm_mode_modeinfo));
+}
+
+enum malidp_op_mode malidp_de_get_op_mode(struct malidp_de_device *dev)
+{
+	return dev->op_mode;
+}
+
+bool malidp_de_attr_valid(struct malidp_de_device *dev,
+				 u32 attr, u32 val)
+{
+	u32 fifo_size = malidp_hw_get_fifo_size(dev->hwdev);
+
+	switch (attr) {
+	case MALIDP_ATTR_DE_RQOS_LOW:
+		if ((val < 1) || (val > dev->arqos_threshold_high))
+			return false;
+		break;
+	case MALIDP_ATTR_DE_RQOS_HIGH:
+		if ((val < dev->arqos_threshold_low) || (val > (fifo_size - 1)))
+			return false;
+		break;
+	case MALIDP_ATTR_DE_RQOS_RED:
+	case MALIDP_ATTR_DE_RQOS_GREEN:
+		if (val > 0xF)
+			return false;
+		break;
+	default:
+		return dev->hwdev->dp_api->de_api.axi_valid(attr, val);
+	}
+
+	return true;
+}
+
+void malidp_de_set_axi_cfg(struct malidp_de_device *dev, u32 outstran,
+				  u32 poutstdcab, u32 burstlen)
+{
+	/*TODO (LEOSW-312): need new object to handle AXI stuff */
+	const struct malidp_de_regmap *reg = dev->de_regmap;
+
+	dev_dbg(dev->device, "%s: outstran: %i, burstlen: %i\n",
+		__func__, outstran, burstlen);
+
+	dev->outstran = outstran;
+	dev->burstlen = burstlen;
+	dev->poutstdcab = poutstdcab;
+	malidp_de_write(dev, DE_AXI_OUTSTDCAPB(dev->outstran) |
+			DE_AXI_POUTSTDCAB(poutstdcab) |
+			DE_AXI_BURSTLEN(dev->burstlen - 1),
+			reg->axi_control);
+}
+
+void malidp_de_init_axi_qos(struct malidp_de_device *dev,
+				   u32 low, u32 high,
+				   u32 red_code, u32 green_code)
+{
+	u32 fifo_size = malidp_hw_get_fifo_size(dev->hwdev);
+	u32 qos_reg_val = 0;
+
+	dev_dbg(dev->device,
+		"%s: low: 0x%X, high: 0x%X, red: 0x%X, green: 0x%X\n",
+		__func__, low, high, red_code, green_code);
+
+	/* trim the threshold values */
+	low = low > 0 ? low : DE_DEFAULT_AXI_ARQOS_LOW;
+	high = high > 0 ? high : DE_DEFAULT_AXI_ARQOS_HIGH;
+	high = high < fifo_size ? high : fifo_size;
+	low = low < high ? low : high;
+
+	/* program the qos register */
+	qos_reg_val |= DE_RQOS_LOW(low);
+	qos_reg_val |= DE_RQOS_HIGH(high);
+	qos_reg_val |= DE_RQOS_RED(red_code);
+	qos_reg_val |= DE_RQOS_GREEN(green_code);
+	malidp_de_write(dev, qos_reg_val, dev->de_regmap->qos_control);
+
+	/* save the rqos settings for sysfs */
+	dev->arqos_threshold_low = low;
+	dev->arqos_threshold_high = high;
+	dev->arqos_red = red_code;
+	dev->arqos_green = green_code;
+}
+
+struct malidp_de_device  *malidp_de_hw_init(struct malidp_hw_device *hwdev,
+			     struct platform_device *pdev,
+			     struct malidp_hw_pdata *pdata,
+			     spinlock_t *hw_lock)
+{
+	int res;
+	struct malidp_de_device *dev = devm_kzalloc(&pdev->dev,
+					sizeof(struct malidp_de_device),
+						    GFP_KERNEL);
+	if (!dev)
+		return NULL;
+
+	dev->hw_lock = hw_lock;
+	dev->hwdev = hwdev;
+	dev->regs = pdata->regs + hwdev->hw_regmap->de_base;
+	dev->de_regmap = &hwdev->hw_regmap->de_regmap;
+	dev->scene_changing = false;
+	dev->gamma_enabled = false;
+
+	dev->device = &pdev->dev;
+
+	res = devm_request_threaded_irq(dev->device,
+			pdata->de_irq,
+			hwdev->dp_api->de_api.irq_handler,
+			malidp_de_irq_thread_handler,
+			IRQF_SHARED, "malidp-de", dev);
+	if (res < 0) {
+		dev_err(&pdev->dev, "%s: failed to request 'de' irq\n", __func__);
+		return NULL;
+	}
+
+	dev->ev_queue = malidp_hw_event_queue_create(DE_N_QUEUE_EVENTS);
+	if (!dev->ev_queue)
+		return NULL;
+
+	/* Set identity matrix to coefficients,
+	* no conversion as default.
+	*/
+	dev->color_adjustment_coeffs[0] = 4096;
+	dev->color_adjustment_coeffs[4] = 4096;
+	dev->color_adjustment_coeffs[8] = 4096;
+
+	dev->op_mode = MALIDP_OP_MODE_UNKNOWN;
+
+	dev->outstran = pdata->de_axi_outstran;
+	dev->poutstdcab = pdata->de_axi_poutstdcab;
+	dev->burstlen = pdata->de_axi_burstlen;
+
+	dev->arqos_threshold_low = pdata->de_axi_arqos_low;
+	dev->arqos_threshold_high = pdata->de_axi_arqos_high;
+	dev->arqos_red = pdata->de_axi_arqos_red;
+	dev->arqos_green = pdata->de_axi_arqos_green;
+
+	dev_dbg(dev->device, "%s : success!\n", __func__);
+
+	return dev;
+}
+
+void malidp_de_hw_exit(struct malidp_de_device *dev)
+{
+	malidp_hw_event_queue_destroy(dev->ev_queue);
+	return;
+}
+
+int malidp_de_get_attr(struct malidp_de_device *dev, u32 attr, u32 *val)
+{
+	u32 fifo_size = malidp_hw_get_fifo_size(dev->hwdev);
+
+	switch (attr) {
+	case MALIDP_ATTR_DE_BURSTLEN:
+		*val = dev->burstlen;
+		break;
+	case MALIDP_ATTR_DE_POUTSTDCAB:
+		*val = dev->poutstdcab;
+		break;
+	case MALIDP_ATTR_DE_OUTSTRAN:
+		*val = dev->outstran;
+		break;
+	case MALIDP_ATTR_DE_RQOS_LOW:
+		*val = dev->arqos_threshold_low;
+		break;
+	case MALIDP_ATTR_DE_RQOS_HIGH:
+		*val = dev->arqos_threshold_high;
+		break;
+	case MALIDP_ATTR_DE_RQOS_RED:
+		*val = dev->arqos_red;
+		break;
+	case MALIDP_ATTR_DE_RQOS_GREEN:
+		*val = dev->arqos_green;
+		break;
+	case MALIDP_ATTR_DE_FIFO_SIZE:
+		*val = fifo_size;
+		break;
+	default:
+		dev_err(dev->device, "%s: unkown DE attribute %i\n",
+			__func__, attr);
+		return -EINVAL;
+	}
+
+	dev_dbg(dev->device, "%s: attr: %i, val: %u\n",
+		__func__, attr, *val);
+
+	return 0;
+}
+
+int malidp_de_set_attr(struct malidp_de_device *dev, u32 attr, u32 val)
+{
+	int ret = 0;
+
+	dev_dbg(dev->device, "%s: attr: %i, val: %u\n", __func__, attr, val);
+
+	if (!malidp_de_attr_valid(dev, attr, val)) {
+		dev_dbg(dev->device, "%s: invalid value %u for attr %u\n",
+			__func__, val, attr);
+		return -EINVAL;
+	}
+
+	switch (attr) {
+	case MALIDP_ATTR_DE_BURSTLEN:
+		malidp_de_set_axi_cfg(dev, dev->outstran,
+					dev->poutstdcab, val);
+		break;
+	case MALIDP_ATTR_DE_POUTSTDCAB:
+		malidp_de_set_axi_cfg(dev, dev->outstran, val,
+					dev->burstlen);
+		break;
+	case MALIDP_ATTR_DE_OUTSTRAN:
+		malidp_de_set_axi_cfg(dev, val, dev->poutstdcab,
+					dev->burstlen);
+		break;
+	case MALIDP_ATTR_DE_RQOS_LOW:
+		malidp_de_init_axi_qos(dev, val, dev->arqos_threshold_high,
+				       dev->arqos_red, dev->arqos_green);
+		break;
+	case MALIDP_ATTR_DE_RQOS_HIGH:
+		malidp_de_init_axi_qos(dev, dev->arqos_threshold_low, val,
+				       dev->arqos_red, dev->arqos_green);
+		break;
+	case MALIDP_ATTR_DE_RQOS_RED:
+		malidp_de_init_axi_qos(dev, dev->arqos_threshold_low,
+				       dev->arqos_threshold_high,
+				       val, dev->arqos_green);
+		break;
+	case MALIDP_ATTR_DE_RQOS_GREEN:
+		malidp_de_init_axi_qos(dev, dev->arqos_threshold_low,
+				       dev->arqos_threshold_high,
+				       dev->arqos_red, val);
+		break;
+	default:
+		dev_err(dev->device, "%s: unkown DE attribute %i\n",
+			__func__, attr);
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+int malidp_de_save_attr(struct malidp_de_device *dev, u32 attr, u32 val)
+{
+	int ret = 0;
+
+	dev_dbg(dev->device, "%s: attr: %i, val: %u\n", __func__, attr, val);
+
+	if (!malidp_de_attr_valid(dev, attr, val)) {
+		dev_dbg(dev->device, "%s: invalid value %u for attr %u\n",
+			__func__, val, attr);
+		return -EINVAL;
+	}
+
+	switch (attr) {
+	case MALIDP_ATTR_DE_BURSTLEN:
+		dev->burstlen = val;
+		break;
+	case MALIDP_ATTR_DE_POUTSTDCAB:
+		dev->poutstdcab = val;
+		break;
+	case MALIDP_ATTR_DE_OUTSTRAN:
+		dev->outstran = val;
+		break;
+	case MALIDP_ATTR_DE_RQOS_LOW:
+		dev->arqos_threshold_low = val;
+		break;
+	case MALIDP_ATTR_DE_RQOS_HIGH:
+		dev->arqos_threshold_high = val;
+		break;
+	case MALIDP_ATTR_DE_RQOS_RED:
+		dev->arqos_red = val;
+		break;
+	case MALIDP_ATTR_DE_RQOS_GREEN:
+		dev->arqos_green = val;
+		break;
+	default:
+		dev_err(dev->device, "%s: unkown DE attribute %i\n",
+			__func__, attr);
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+/*
+ * Update the gamma settings
+ *
+ * @enable: enable/disable the gamma correction.
+ * @coeffs: the gamma coeffs table, it is omitted if @enable = false.
+ */
+void malidp_de_update_gamma_settings(struct malidp_de_device *dev,
+			bool enable, u32 *coeffs)
+{
+	dev_dbg(dev->device, "%s: gamma enabled: %d\n", __func__, enable);
+
+	dev->gamma_enabled = enable;
+	if (dev->gamma_enabled) {
+		if (coeffs != NULL) {
+			memcpy(dev->gamma_coeffs, coeffs,
+			       sizeof(u32) * DE_N_COEFTAB_COEFS);
+		} else {
+			dev_warn(dev->device, "%s: the gamma coeffs table is null\n",
+				 __func__);
+		}
+	}
+}
+
+#define MANTISSA	12
+#define FP12_1_0	(1 << MANTISSA)
+
+static s32 fp_div(s32 dividend, s32 divisor)
+{
+	u64 a, b;
+	int sign = 0;
+
+	WARN_ON(divisor == 0);
+
+	if (dividend < 0) {
+		a = -dividend;
+		sign = !sign;
+	} else {
+		a = dividend;
+	}
+
+	if (divisor < 0) {
+		b = -divisor;
+		sign = !sign;
+	} else {
+		b = divisor;
+	}
+
+	a <<= MANTISSA;
+	do_div(a, b);
+	dividend = a;
+
+	return (sign == 0) ? dividend : -dividend;
+}
+
+static s32 fp_mul(s32 faciend, s32 multiplier)
+{
+	s64 t = faciend;
+
+	t *= multiplier;
+	faciend = (t >> MANTISSA);
+	return faciend;
+}
+
+/*
+*	Calculation of the inverse matrix
+*		| a00 a01 a02 |
+*		| a10 a11 a12 |
+*		| a20 a21 a22 |
+*	The result is stored into inverse[3][3]
+*/
+static int matrix_inverse(s32 inverse[3][3],
+		s32 a00, s32 a01, s32 a02,
+		s32 a10, s32 a11, s32 a12,
+		s32 a20, s32 a21, s32 a22)
+{
+	s32 a_1 = fp_mul(a11, a22) - fp_mul(a12, a21);
+	s32 a_2 = fp_mul(a12, a20) - fp_mul(a10, a22);
+	s32 a_3 = fp_mul(a10, a21) - fp_mul(a11, a20);
+
+	s32 determinant = fp_mul(a00, a_1) + fp_mul(a01, a_2) + fp_mul(a02, a_3);
+	if (determinant == 0)
+		return -EINVAL;
+
+	inverse[0][0] = fp_div(a_1, determinant);
+	inverse[1][0] = fp_div(a_2, determinant);
+	inverse[2][0] = fp_div(a_3, determinant);
+
+	a_1 = fp_mul(a02, a21) - fp_mul(a01, a22);
+	a_2 = fp_mul(a00, a22) - fp_mul(a02, a20);
+	a_3 = fp_mul(a01, a20) - fp_mul(a00, a21);
+
+	inverse[0][1] = fp_div(a_1, determinant);
+	inverse[1][1] = fp_div(a_2, determinant);
+	inverse[2][1] = fp_div(a_3, determinant);
+
+	a_1 = fp_mul(a01, a12) - fp_mul(a02, a11);
+	a_2 = fp_mul(a02, a10) - fp_mul(a00, a12);
+	a_3 = fp_mul(a00, a11) - fp_mul(a01, a10);
+
+	inverse[0][2] = fp_div(a_1, determinant);
+	inverse[1][2] = fp_div(a_2, determinant);
+	inverse[2][2] = fp_div(a_3, determinant);
+	return 0;
+}
+
+/* This routing makes the sum of every row in matrix not bigger than 1 */
+static void normalize_matrix(s32 m[3][3])
+{
+	s32 sum_line[3], max_sum;
+	int i, j;
+
+	for (i = 0; i < 3; i++) {
+		sum_line[i] = 0;
+		for (j = 0; j < 3; j++)
+			sum_line[i] += m[i][j];
+	}
+
+	max_sum = sum_line[0];
+	for (i = 1; i < 3; i++) {
+		if (max_sum < sum_line[i])
+			max_sum = sum_line[i];
+	}
+
+	if (max_sum <= FP12_1_0)
+		return;
+	/* If max_sum is larger than 4096, we need get 4096/max_sum,
+	* then, every element in the matrix multiple 4096/max_sum
+	*/
+	max_sum = fp_div(FP12_1_0, max_sum);
+	for (i = 0; i < 3; i++) {
+		for (j = 0; j < 3; j++)
+			m[i][j] = fp_mul(m[i][j], max_sum);
+	}
+}
+
+/*
+* This matrix is used for transforming from Rec. 709 RGB
+* into CIE XYZ.
+*/
+static const s32 matrix709[3][3] = {
+	{1689, 1465,  739},
+	{ 871, 2929,  296},
+	{  79,  488, 3892}
+};
+
+/*
+ * Update color adjustment coefficients
+ *	All the calculation is base on fix point number which format is
+ *	S19.12 (32bit, signed)
+ *	So, integer 4096 is actually for fix pointer number 1.0
+ *	The xy coordinates should be in 10bits representing values
+ *	from 0 to 1023/1024 as reported by the EDID standard.
+ * For result:
+ *	Coefficients are 15bit two's complement code.
+ */
+int malidp_de_update_cadj_coeffs(struct malidp_de_device *dev,
+	u16 red_x, u16 red_y, u16 green_x, u16 green_y,
+	u16 blue_x, u16 blue_y, u16 white_x, u16 white_y)
+{
+	s32 w_x, w_y, w_z;
+	s32 r_x, r_y, r_z;
+	s32 g_x, g_y, g_z;
+	s32 b_x, b_y, b_z;
+	s32 inverse[3][3], coeffs[3][3];
+	s32 r_xyz, g_xyz, b_xyz;
+	unsigned long flags;
+
+	r_x = red_x << 2;
+	r_y = red_y << 2;
+	g_x = green_x << 2;
+	g_y = green_y << 2;
+	b_x = blue_x << 2;
+	b_y = blue_y << 2;
+
+	/*
+	*	Algorithm for calculating M:
+	*	    | r_x  g_x b_x |   |r_xyz   0     0   |
+	*	M = | r_y  g_y b_y | * |  0   g_xyz   0   |
+	*	    | r_z  g_z b_z |   |  0     0   b_xyz |
+	*
+	*	|r_xyz|          | r_x g_x b_x |   | w_x |
+	*	|g_xyz| = inverse| r_y g_y b_y | * | w_y |
+	*	|b_xyz|          | r_z g_z b_z |   | w_z |
+	*
+	*	w_x = white_x/white_y, w_y = 1,
+	*	w_z = (1 - white_x - white_y)/white_y
+	*/
+
+	if (white_y == 0)
+		return -EINVAL;
+
+	w_x = white_x << 2;
+	w_y = white_y << 2;
+	w_z = FP12_1_0 - w_x - w_y;
+
+	w_x = fp_div(w_x, w_y);
+	w_z = fp_div(w_z, w_y);
+	w_y = FP12_1_0;
+
+	r_z = FP12_1_0 - r_x - r_y;
+	g_z = FP12_1_0 - g_x - g_y;
+	b_z = FP12_1_0 - b_x - b_y;
+
+	if (matrix_inverse(inverse,
+		r_x, g_x, b_x, r_y, g_y, b_y, r_z, g_z, b_z) != 0)
+		return -EINVAL;
+
+	r_xyz = fp_mul(inverse[0][0], w_x)
+			+fp_mul(inverse[0][1], w_y)
+			+fp_mul(inverse[0][2], w_z);
+
+	g_xyz = fp_mul(inverse[1][0], w_x)
+			+fp_mul(inverse[1][1], w_y)
+			+fp_mul(inverse[1][2], w_z);
+
+	b_xyz = fp_mul(inverse[2][0], w_x)
+			+fp_mul(inverse[2][1], w_y)
+			+fp_mul(inverse[2][2], w_z);
+
+	if (matrix_inverse(inverse,
+		fp_mul(r_x, r_xyz), fp_mul(g_x, g_xyz), fp_mul(b_x, b_xyz),
+		fp_mul(r_y, r_xyz), fp_mul(g_y, g_xyz), fp_mul(b_y, b_xyz),
+		fp_mul(r_z, r_xyz), fp_mul(g_z, g_xyz), fp_mul(b_z, b_xyz))
+		!= 0)
+		return -EINVAL;
+
+	/* inverse(M) * Matrix 709 */
+	for (r_x = 0; r_x < 3; r_x++) {
+		for (r_y = 0; r_y < 3; r_y++) {
+			coeffs[r_x][r_y] = 0;
+			for (g_x = 0; g_x < 3; g_x++)
+				coeffs[r_x][r_y] +=
+					fp_mul(inverse[r_x][g_x], matrix709[g_x][r_y]);
+		}
+	}
+
+	normalize_matrix(coeffs);
+
+	spin_lock_irqsave(dev->hw_lock, flags);
+
+	for (r_x = 0; r_x < 3; r_x++)
+		for (r_y = 0; r_y < 3; r_y++)
+			dev->color_adjustment_coeffs[r_x * 3 + r_y] =
+				coeffs[r_x][r_y] & 0x7FFF;
+
+	spin_unlock_irqrestore(dev->hw_lock, flags);
+
+	return 0;
+}
+
+static int malidp_de_dbg_dump_cadj(struct seq_file *dump_file,
+		void *v)
+{
+	struct malidp_de_device *dev = dump_file->private;
+	int i, ret;
+
+	for (i = 0; i < DE_N_COLORADJ_COEFS; i++) {
+		ret = seq_printf(dump_file,
+				"K%d = %u (0x%X)\n", i + 1,
+				dev->color_adjustment_coeffs[i],
+				(u32)dev->color_adjustment_coeffs[i]);
+		if (ret != 0)
+			return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int malidp_de_dbg_open(struct inode *inode, struct file *pfile)
+{
+	return single_open(pfile, malidp_de_dbg_dump_cadj,
+				inode->i_private);
+}
+
+static const struct file_operations f_ops_cadj = {
+	.owner = THIS_MODULE,
+	.open = malidp_de_dbg_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+};
+
+void malidp_de_debugfs_init(struct malidp_de_device *dev,
+	struct dentry *folder)
+{
+	struct dentry *dbg_file;
+
+	dbg_file = debugfs_create_file("de_color_adj",
+			S_IROTH, folder, dev, &f_ops_cadj);
+	if (dbg_file == NULL)
+		dev_err(dev->device,
+			"debugfs de_color_adj is not created!\n");
+	/* More dumping */
+}
diff --git a/drivers/video/adf/arm/malidp_de_device.h b/drivers/video/adf/arm/malidp_de_device.h
new file mode 100644
index 0000000..4663d0d
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_de_device.h
@@ -0,0 +1,378 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_DE_DEVICE_H_
+#define _MALIDP_DE_DEVICE_H_
+
+#include <linux/interrupt.h>
+#include <linux/debugfs.h>
+#include <linux/interrupt.h>
+#include <uapi/drm/drm_mode.h>
+#include "malidp_hw_types.h"
+#include "malidp_sysfs.h"
+
+#define DE_H_FRONTPORCH(x)	(((x) & 0xfff) << 0)
+#define DE_H_BACKPORCH(x)	(((x) & 0x3ff) << 16)
+#define DE_V_FRONTPORCH(x)	(((x) & 0xff) << 0)
+#define DE_V_BACKPORCH(x)	(((x) & 0xff) << 16)
+#define DE_H_SYNCWIDTH(x)	(((x) & 0x3ff) << 0)
+#define DE_V_SYNCWIDTH(x)	(((x) & 0xff) << 16)
+#define DE_H_ACTIVE(x)	(((x) & 0x1fff) << 0)
+#define DE_V_ACTIVE(x)	(((x) & 0x1fff) << 16)
+
+#define DE_LINE_INT_1(x)	((x) & 0x3fff)
+#define DE_LINE_INT_2(x)	(((x) & 0x3fff) << 16)
+
+
+#define	DE_AXI_OUTSTDCAPB_MASK	0xff
+#define	DE_AXI_OUTSTDCAPB(x)	(((x) & DE_AXI_OUTSTDCAPB_MASK) << 0)
+#define	DE_AXI_POUTSTDCAB_MASK	0x3f
+#define	DE_AXI_POUTSTDCAB(x)	(((x) & DE_AXI_POUTSTDCAB_MASK) << 8)
+#define	DE_AXI_BURSTLEN_MASK	0xff
+#define	DE_AXI_BURSTLEN(x)	(((x) & DE_AXI_BURSTLEN_MASK) << 16)
+
+#define DE_SET_FLOWCFG_MASK	0x3
+#define DE_SET_FLOWCFG(x)	(((x) & DE_SET_FLOWCFG_MASK) << 16)
+#define DE_GAMMA_EN		0x1
+#define DE_CADJ_EN		(1 << 4)
+#define DE_DITH_EN		(1 << 12)
+
+#define DE_OUT_DEPTH_MASK		0xf
+#define DE_OUT_DEPTH_R_SHIFT		16
+#define DE_OUT_DEPTH_R(x)		(((x) & DE_OUT_DEPTH_MASK) << DE_OUT_DEPTH_R_SHIFT)
+#define DE_OUT_DEPTH_G_SHIFT		8
+#define DE_OUT_DEPTH_G(x)		(((x) & DE_OUT_DEPTH_MASK) << DE_OUT_DEPTH_G_SHIFT)
+#define DE_OUT_DEPTH_B_SHIFT		0
+#define DE_OUT_DEPTH_B(x)		(((x) & DE_OUT_DEPTH_MASK) << DE_OUT_DEPTH_B_SHIFT)
+
+#define DE_REG_COEFTAB_ADDR		0x30
+#define		DE_COEFTAB_ADDR_MASK		0x3f
+#define		DE_COEFTAB_TABLE_MASK		0x7
+#define		DE_COEFTAB_ADDR_SHIFT		0
+#define		DE_COEFTAB_GAMMA_SHIFT		16
+#define		DE_COEFTAB_LV_DEGAMMA_SHIFT	19
+#define		DE_COEFTAB_GAMMA		(DE_COEFTAB_TABLE_MASK << DE_COEFTAB_GAMMA_SHIFT)
+#define		DE_COEFTAB_LV_DEGAMMA		(DE_COEFTAB_TABLE_MASK << DE_COEFTAB_LV_DEGAMMA_SHIFT)
+#define		DE_COEFTAB_INTAB_ADDR(x)	(((x) & DE_COEFTAB_ADDR_MASK) << DE_COEFTAB_ADDR_SHIFT)
+#define DE_REG_COEFTAB_DATA		0x34
+#define		DE_COEFTAB_DATA(a, b)		((((a) & 0xfff) << 16) | (((b) & 0xfff) << 0))
+#define DE_N_COEFTAB_COEFS		64
+#define DE_N_COLORADJ_COEFS		12
+
+/* Layer Common Registers */
+#define DE_REG_L_FORMAT			0x0
+#define		DE_L_FMT_MASK			0x3f
+#define		DE_L_SET_FMT(x)			(((x) & DE_L_FMT_MASK) << 0)
+#define DE_REG_L_CONTROL		0x4
+#define		DE_L_EN				(1 << 0)
+#define		DE_L_FCFG_MASK		0x7
+#define		DE_L_FCFG(x)			(((x) & DE_L_FCFG_MASK) << 1)
+#define		DE_GET_L_FCFG(x)		((x >> 1) & DE_L_FCFG_MASK)
+#define		DE_L_IGEN			(1 << 4)
+#define		DE_L_VALID			(1 << 5)
+#define		DE_L_IGSEL_MASK			(0x3 << 6)
+#define		DE_L_IGSEL_IG			(0 << 6)
+#define		DE_L_IGSEL_SRGB			(1 << 6)
+#define		DE_L_IGSEL_LINEAR		(2 << 6)
+#define		DE_L_ROT_90			(1 << 8)
+#define		DE_L_ROT_180			(2 << 8)
+#define		DE_L_HFLIP			(1 << 10)
+#define		DE_L_VFLIP			(1 << 11)
+#define		DE_L_TRANS_MASK			(DE_L_ROT_90 | DE_L_ROT_180 | DE_L_HFLIP | DE_L_VFLIP)
+#define		DE_L_SET_TRANS(x)		(((x) << 8) & DE_L_TRANS_MASK)
+#define		DE_L_COMPOSE_PIXEL		(1 << 12)
+#define		DE_L_COMPOSE_BG			(2 << 12)
+#define		DE_L_PREMULT			(1 << 14)
+#define		DE_L_ALPHA(x)			(((x) & 0xff) << 16)
+#define DE_REG_L_COMPOSE		0x8
+#define		DE_L_ALPHA0(x)			((x) & 0xff)
+#define		DE_L_ALPHA1(x)			(((x) & 0xff) << 8)
+#define		DE_L_ALPHA2(x)			(((x) & 0xff) << 16)
+#define		DE_L_ALPHA3(x)			(((x) & 0xff) << 24)
+#define DE_REG_L_SIZE			0xC
+#define DE_REG_L_SIZE_CMP		0x10
+#define		DE_L_SIZE_H(x)			(((x) & 0x1fff) << 0)
+#define		DE_L_SIZE_V(x)			(((x) & 0x1fff) << 16)
+#define DE_REG_L_OFFSET			0x14
+#define		DE_L_OFFSET_H(x)		(((x) & 0x1fff) << 0)
+#define		DE_L_OFFSET_V(x)		(((x) & 0x1fff) << 16)
+
+/* Video Layer Specific Registers */
+#define DE_REG_LV1_STRIDE		0x18
+#define DE_REG_LV2_STRIDE		0x1C
+#define DE_REG_LV3_STRIDE		0x20
+#define DE_REG_LV1_PTR0_LOW		0x24
+#define DE_REG_LV1_PTR0_HIGH		0x28
+#define DE_REG_LV1_PTR1_LOW		0x2C
+#define DE_REG_LV1_PTR1_HIGH		0x30
+#define DE_REG_LV2_PTR0_LOW		0x34
+#define DE_REG_LV2_PTR0_HIGH		0x38
+#define DE_REG_LV2_PTR1_LOW		0x3C
+#define DE_REG_LV2_PTR1_HIGH		0x40
+#define DE_REG_LV3_PTR0_LOW		0x44
+#define DE_REG_LV3_PTR0_HIGH		0x48
+#define DE_REG_LV3_PTR1_LOW		0x4C
+#define DE_REG_LV3_PTR1_HIGH		0x50
+#define DE_REG_LV1I_PTR0_LOW		0x54
+#define DE_REG_LV1I_PTR0_HIGH		0x58
+#define DE_REG_LV1I_PTR1_LOW		0x5C
+#define DE_REG_LV1I_PTR1_HIGH		0x60
+#define DE_REG_LV2I_PTR0_LOW		0x64
+#define DE_REG_LV2I_PTR0_HIGH		0x68
+#define DE_REG_LV2I_PTR1_LOW		0x6C
+#define DE_REG_LV2I_PTR1_HIGH		0x70
+#define DE_REG_LV3I_PTR0_LOW		0x74
+#define DE_REG_LV3I_PTR0_HIGH		0x78
+#define DE_REG_LV3I_PTR1_LOW		0x7C
+#define DE_REG_LV3I_PTR1_HIGH		0x80
+#define DE_REG_LV1_PTR0_R_LOW		0x84
+#define DE_REG_LV1_PTR0_R_HIGH		0x88
+#define DE_REG_LV1_PTR1_R_LOW		0x8C
+#define DE_REG_LV1_PTR1_R_HIGH		0x90
+#define DE_REG_LV2_PTR0_R_LOW		0x94
+#define DE_REG_LV2_PTR0_R_HIGH		0x98
+#define DE_REG_LV2_PTR1_R_LOW		0x9C
+#define DE_REG_LV2_PTR1_R_HIGH		0xA0
+#define DE_REG_LV3_PTR0_R_LOW		0xA4
+#define DE_REG_LV3_PTR0_R_HIGH		0xA8
+#define DE_REG_LV3_PTR1_R_LOW		0xAC
+#define DE_REG_LV3_PTR1_R_HIGH		0xB0
+
+/* Graphics Layer Specific Registers */
+#define DE_REG_LG_STRIDE		0x18
+#define DE_REG_LG_PTR0_LOW		0x1C
+#define DE_REG_LG_PTR0_HIGH		0x20
+#define DE_REG_LG_PTR1_LOW		0x24
+#define DE_REG_LG_PTR1_HIGH		0x28
+
+/* Smart Layer Specific Registers */
+#define DE_REG_LS_BBOX_ARGB		0x18
+#define DE_REG_LS_ENABLE		0x1C
+#define		DE_LS_EN_NUM(x)		(((x) & 0x7) << 0)
+#define DE_REG_LS_R1_IN_SIZE		0x20
+#define DE_REG_LS_R1_OFFSET		0x24
+#define DE_REG_LS_R1_STRIDE		0x28
+#define DE_REG_LS_R1_PTR_LOW		0x2C
+#define DE_REG_LS_R1_PTR_HIGH		0x30
+
+#define DE_REG_LS_R2_IN_SIZE		0x34
+
+#define DE_REG_LS_Rn_ADDR_DELTA	(DE_REG_LS_R2_IN_SIZE - DE_REG_LS_R1_IN_SIZE)
+
+/* AFBC Decoder Registers */
+#define DE_AD_EN			(1 << 0)
+#define DE_AD_YTR			(1 << 4)
+#define DE_AD_BS			(1 << 8)
+#define DE_AD_CROP_LEFT(x)		(((x) & 0x1FFF) << 0)
+#define DE_AD_CROP_RIGHT(x)		(((x) & 0x1FFF) << 16)
+#define DE_AD_CROP_TOP(x)		(((x) & 0x1FFF) << 0)
+#define DE_AD_CROP_BOTTOM(x)		(((x) & 0x1FFF) << 16)
+
+/* RQOS Register */
+#define		DE_RQOS_LOW(x)		(((x) & 0xFFF) << 0)
+#define		DE_RQOS_RED(x)		(((x) & 0xF) << 12)
+#define		DE_RQOS_HIGH(x)		(((x) & 0xFFF) << 16)
+#define		DE_RQOS_GREEN(x)	(((x) & 0xF) << 28)
+
+#define DE_DEFAULT_AXI_OUTSTRAN		16
+#define DE_DEFAULT_AXI_POUTSTDCAB	16
+#define DE_DEFAULT_AXI_BURSTLEN		16
+#define DE_DEFAULT_AXI_ARQOS_LOW	112
+#define DE_DEFAULT_AXI_ARQOS_HIGH	128
+#define DE_DEFAULT_AXI_ARQOS_RED	1
+#define DE_DEFAULT_AXI_ARQOS_GREEN	0
+
+/* Background is always set to black color */
+#define DE_FIXED_BG_R   0
+#define DE_FIXED_BG_G   0
+#define DE_FIXED_BG_B   0
+
+#define DE_DEFAULT_PREFETCH_LINE	5
+
+enum malidp_de_flow_cmp_cfg {
+	MALIDP_DE_CMP_FLOW_INTERNAL,
+	MALIDP_DE_CMP_FLOW_SE0,
+	/* Other configurations are currently reserved */
+};
+
+enum malidp_de_flow_layer_cfg {
+	MALIDP_DE_LAYER_FLOW_LOCAL = 0,
+	MALIDP_DE_LAYER_FLOW_SIMULT_SE0 = 1,
+	MALIDP_DE_LAYER_FLOW_SCALE_SE0 = 3,
+	/* Other values are currently reserved */
+};
+
+/*
+ * This structure contains all the relevant HW parameters we need to change
+ * the mode in the DE:
+ * - clock: frequency of the pixclk in Hz
+ * Horizontal sync parameters:
+ * - h_active: size of the horizontal active area in pixels
+ * - hbp: horizontal backporch in pixels
+ * - hfp: horizontal front porch in pixels
+ * - hsw: horizontal sync pulse width
+ * - hsync_pol_pos: horizontal sync polarity (true=positive, false=negative)
+ * Vertical sync parameters:
+ * - v_active: size of the vertical active area in pixels
+ * - vbp: vertical backporch in pixels
+ * - vfp: vertical front porch in pixels
+ * - vsw: vertical sync pulse width
+ * - vsync_pol_pos: vertical sync polarity (true=positive, false=negative)
+ */
+struct malidp_de_hwmode {
+	u32 clock;
+	u32 h_active, hbp, hfp, hsw;
+	bool hsync_pol_pos;
+	u32 v_active, vbp, vfp, vsw;
+	bool vsync_pol_pos;
+};
+
+struct malidp_de_device {
+	void __iomem *regs;
+	enum malidp_op_mode op_mode;
+	struct drm_mode_modeinfo current_mode;
+	struct device *device;
+	struct malidp_hw_device *hwdev;
+	void (*flip_callback)(struct device *, void *, struct malidp_hw_event_queue *);
+	void *callback_opaque;
+	const s32 *yuv2rgb_coeffs[MALIDP_MAX_LAYERS];
+	/*
+	 * Used to indicate that the next PTR_UPDATE IRQ is due to a
+	 * content change as opposed to a mode change or disabling the memory
+	 * interface. Access must be protected by the hwdev hw_lock.
+	 */
+	bool scene_changing;
+	struct malidp_hw_event_queue *ev_queue;
+	/*
+	 * This spinlock protects accesses to registers and clocks.
+	 * Also protects the shared variables in this structure:
+	 * "event", "op_mode" and "flip_callback".
+	 */
+	spinlock_t *hw_lock;
+
+	/*
+	 * Gamma-related settings
+	 */
+	bool gamma_enabled;
+	u32 gamma_coeffs[DE_N_COEFTAB_COEFS];
+
+	/* Color adjustment settings */
+	u16 color_adjustment_coeffs[DE_N_COLORADJ_COEFS];
+
+	/* Output depth for dithering */
+	u8 red_bits, green_bits, blue_bits;
+
+	/* Attributes accessible through sysfs */
+	u16 burstlen;
+	u8 outstran;
+	u8 poutstdcab;
+
+	u16 arqos_threshold_low;
+	u16 arqos_threshold_high;
+	u8 arqos_red;
+	u8 arqos_green;
+
+	const struct malidp_de_regmap *de_regmap;
+	/* Stored after entering PSM to handle any residual IRQs */
+	u32 pending_status;
+};
+
+int malidp_dt_parse_de(struct platform_device *pdev,
+			       struct device_node *nproot,
+			       struct malidp_hw_pdata *pdata);
+
+int malidp_de_fmt_drm2hw(struct malidp_de_device *dev,
+	struct malidp_hw_buffer *buf);
+
+struct malidp_de_device *malidp_de_hw_init(struct malidp_hw_device *hwdev,
+			     struct platform_device *pdev,
+			     struct malidp_hw_pdata *pdata,
+			     spinlock_t *hw_lock);
+
+void malidp_de_set_axi_cfg(struct malidp_de_device *dev, u32 outstran,
+				u32 poutstdcab, u32 burstlen);
+bool malidp_de_attr_valid(struct malidp_de_device *dev,
+		u32 attr, u32 val);
+void malidp_de_init_axi_qos(struct malidp_de_device *dev,
+		u32 low, u32 high, u32 red_code, u32 green_code);
+void malidp_de_write_alpha_lookup(struct malidp_de_device *dev);
+void malidp_de_hw_exit(struct malidp_de_device *dev);
+
+void malidp_de_write(struct malidp_de_device *dev,
+				u32 value, u32 reg);
+u32 malidp_de_read(struct malidp_de_device *dev, u32 reg);
+void malidp_de_setbits(struct malidp_de_device *dev, u32 mask,
+		u32 reg);
+void malidp_de_clearbits(struct malidp_de_device *dev,
+		u32 mask, u32 reg);
+irqreturn_t malidp_de_irq_thread_handler(int irq, void *data);
+
+int malidp_de_modeset(struct malidp_de_device *dev,
+		struct drm_mode_modeinfo *mode);
+
+void malidp_de_set_coeftab(struct malidp_de_device *dev,
+	u32 table, const u32 *coeffs);
+/*
+ * The following functions need to be called while holding the HW spinlock
+ * unless they are used at initialization or exit time.
+ *
+ */
+void malidp_de_cfg_cmp_flow(struct malidp_de_device *dev,
+			enum malidp_de_flow_cmp_cfg);
+
+void malidp_de_cfg_layer_flow(struct malidp_de_device *dev,
+			const struct malidp_layer_hw_info *hw_layer,
+			enum malidp_de_flow_layer_cfg cfg);
+
+enum malidp_de_flow_layer_cfg malidp_de_get_layer_flow(struct malidp_de_device *dev,
+			const struct malidp_layer_hw_info *hw_layer);
+
+void malidp_de_cfg_smart_state(struct malidp_de_device *dev,
+			const struct malidp_hw_smart_layer_state *ls_state);
+
+int malidp_de_cfg_layer(struct malidp_de_device *dev,
+			struct malidp_hw_buffer *buf);
+
+void malidp_de_disable_all_layers(struct malidp_de_device *dev);
+
+void malidp_de_set_flip_callback(struct malidp_de_device *dev,
+		void (*callback)(struct device *, void *, struct malidp_hw_event_queue *),
+		void *opaque);
+
+void malidp_de_modeget(struct malidp_de_device *dev,
+		       struct drm_mode_modeinfo *mode);
+
+enum malidp_op_mode malidp_de_get_op_mode(struct malidp_de_device *dev);
+
+int malidp_de_get_attr(struct malidp_de_device *dev, u32 attr, u32 *val);
+int malidp_de_set_attr(struct malidp_de_device *dev, u32 attr, u32 val);
+int malidp_de_save_attr(struct malidp_de_device *dev, u32 attr, u32 val);
+
+void malidp_de_update_gamma_settings(struct malidp_de_device *dev,
+			bool enable, u32 *coeffs);
+void malidp_de_store_output_depth(struct malidp_de_device *dev,
+		u8 red, u8 green, u8 blue);
+
+int malidp_de_update_cadj_coeffs(struct malidp_de_device *dev,
+	u16 red_x, u16 red_y, u16 green_x, u16 green_y,
+	u16 blue_x, u16 blue_y, u16 white_x, u16 white_y);
+
+void malidp_de_debugfs_init(struct malidp_de_device *dev,
+		struct dentry *folder);
+
+void malidp_de_cleanup_yuv2rgb_coeffs(struct malidp_de_device *dev);
+#endif /* _MALIDP_DE_DEVICE_H_ */
diff --git a/drivers/video/adf/arm/malidp_drv.c b/drivers/video/adf/arm/malidp_drv.c
new file mode 100644
index 0000000..f1c3cce
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_drv.c
@@ -0,0 +1,396 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <video/video_tx.h>
+#include <linux/pm.h>
+#include <linux/pm_runtime.h>
+#include <linux/suspend.h>
+
+#include "malidp_adf.h"
+#include "malidp_drv.h"
+#include "malidp_hw.h"
+#include "malidp_hw_types.h"
+#include "malidp_iommu.h"
+#include "malidp_sysfs.h"
+#include "malidp_of_graph.h"
+#define MALIDP_NAME "mali-dp"
+/* Epoch should be limited to 8 bits, and major and minor to 12 bits */
+#define VERSION_EPOCH 1
+#define VERSION_MAJOR 1
+#define VERSION_MINOR 0
+
+struct malidp_devtype {
+	enum malidp_hw_product product;
+};
+
+static const struct malidp_devtype malidp_devdata[] = {
+	[MALI_DP500] = {
+		.product = MALI_DP500,
+	},
+	[MALI_DP550] = {
+		.product = MALI_DP550,
+	},
+};
+
+static const struct of_device_id malidp_dt_ids[] = {
+	{ .compatible = "arm,mali-dp500", .data = &malidp_devdata[MALI_DP500], },
+	{ .compatible = "arm,mali-dp550", .data = &malidp_devdata[MALI_DP550], },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, malidp_dt_ids);
+
+struct video_tx_device *malidp_find_video_tx(struct malidp_device *dev,
+		struct device_node *nproot)
+{
+	struct device_node *local_endpoint;
+	struct device_node *tx_node;
+	struct video_tx_device *tx = NULL;
+
+	local_endpoint = of_graph_get_next_endpoint(nproot, NULL);
+	if (!local_endpoint) {
+		dev_err(dev->device, "Couldn't find local endpoint\n");
+		return NULL;
+	}
+
+	tx_node = of_graph_get_remote_port_parent(local_endpoint);
+	if (tx_node) {
+		tx = of_find_video_tx_by_node(tx_node);
+		of_node_put(tx_node);
+	} else {
+		dev_err(dev->device, "Couldn't find transmitter by endpoint\n");
+	}
+	of_node_put(local_endpoint);
+
+	return tx;
+}
+
+#if defined(CONFIG_PM_SLEEP) || defined(CONFIG_PM_RUNTIME)
+static struct malidp_device *to_malidp_dev(struct device *dev)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+
+	return platform_get_drvdata(pdev);
+}
+#endif /* CONFIG_PM_SLEEP | CONFIG_PM_RUNTIME */
+
+#ifdef CONFIG_PM_SLEEP
+static int malidp_sys_pm_suspend(struct device *dev)
+{
+	struct malidp_device *dp_dev = to_malidp_dev(dev);
+
+	dev_info(dev, "%s\n", __func__);
+
+	if (dp_dev->current_dpms == DRM_MODE_DPMS_ON)
+		malidp_hw_display_switch(dp_dev->hw_dev, false);
+
+	return 0;
+}
+
+static int malidp_sys_pm_suspend_late(struct device *dev)
+{
+	struct malidp_device *dp_dev = to_malidp_dev(dev);
+
+	dev_info(dev, "%s\n", __func__);
+	if (!pm_runtime_status_suspended(dev)) {
+		malidp_hw_runtime_suspend(dp_dev->hw_dev);
+		pm_runtime_set_suspended(dev);
+	}
+	return 0;
+}
+
+static int malidp_sys_pm_resume_early(struct device *dev)
+{
+	struct malidp_device *dp_dev = to_malidp_dev(dev);
+
+	dev_info(dev, "%s\n", __func__);
+	malidp_hw_runtime_resume(dp_dev->hw_dev);
+	pm_runtime_set_active(dev);
+	return 0;
+}
+
+static void malidp_sys_pm_complete(struct device *dev)
+{
+	struct malidp_device *dp_dev = to_malidp_dev(dev);
+
+	dev_info(dev, "%s\n", __func__);
+
+	if (dp_dev->current_dpms == DRM_MODE_DPMS_ON) {
+		if (dp_dev->adf_dev.onscreen != NULL) {
+			struct malidp_driver_state *state =
+				dp_dev->adf_dev.onscreen->state;
+			malidp_adf_cleanup_signaled_mw(state);
+			malidp_hw_commit(dp_dev->hw_dev, &state->hw_state);
+		}
+		malidp_hw_display_switch(dp_dev->hw_dev, true);
+	}
+	atomic_set(&dp_dev->suspending, 0);
+}
+
+static int malidp_pm_notifier(struct notifier_block *notifier,
+		unsigned long event, void *data)
+{
+	struct malidp_device *dev = container_of(notifier,
+						struct malidp_device,
+						dp_pm_nb);
+	struct malidp_driver_state *state;
+
+	switch (event) {
+	case PM_SUSPEND_PREPARE:
+		dev_info(dev->device, "%s:PM_SUSPEND_PREPARE\n", __func__);
+
+		atomic_set(&dev->suspending, 1);
+
+		mutex_lock(&dev->adf_dev.client_lock);
+		flush_kthread_worker(&dev->adf_dev.post_worker);
+		if (dev->adf_dev.onscreen != NULL) {
+			state = dev->adf_dev.onscreen->state;
+			malidp_adf_waiting_for_mw(state);
+		}
+		mutex_unlock(&dev->adf_dev.client_lock);
+
+		break;
+	case PM_POST_SUSPEND:
+		dev_info(dev->device, "%s:PM_POST_SUSPEND\n", __func__);
+		atomic_set(&dev->suspending, 0);
+		break;
+	default:
+		break;
+	}
+	return NOTIFY_OK;
+}
+#endif /* CONFIG_PM_SLEEP */
+
+static int malidp_remove(struct platform_device *pdev)
+{
+	struct malidp_device *dev = platform_get_drvdata(pdev);
+
+	dev_dbg(&pdev->dev, "removing module");
+
+#ifdef CONFIG_PM_SLEEP
+	unregister_pm_notifier(&dev->dp_pm_nb);
+#endif /* CONFIG_PM_SLEEP */
+
+	pm_runtime_disable(&pdev->dev);
+
+	debugfs_remove_recursive(dev->dbg_folder);
+
+	malidp_sysfs_destroy(dev);
+	malidp_adf_destroy(dev);
+	if (dev->iommu_domain)
+		malidp_iommu_exit(dev->iommu_domain);
+	if (!pm_runtime_status_suspended(&pdev->dev)) {
+		malidp_hw_runtime_suspend(dev->hw_dev);
+		pm_runtime_set_suspended(&pdev->dev);
+	}
+
+	malidp_hw_exit(dev->hw_dev);
+
+	return 0;
+}
+
+static int malidp_debugfs_init(struct malidp_device *dev)
+{
+	char dbg_folder_name[32];
+
+	if (!debugfs_initialized())
+		return 0;
+
+	snprintf(dbg_folder_name, 32, "%s%d", dev->name, dev->id);
+	dev->dbg_folder = debugfs_create_dir(dbg_folder_name, NULL);
+	if (IS_ERR_OR_NULL(dev->dbg_folder))
+		return -EINVAL;
+	return malidp_hw_debugfs_init(dev->hw_dev, dev->dbg_folder);
+}
+
+static int malidp_probe(struct platform_device *pdev)
+{
+	const struct of_device_id *of_id =
+		of_match_device(of_match_ptr(malidp_dt_ids), &pdev->dev);
+	struct device_node *np = pdev->dev.of_node;
+	struct malidp_device *dev;
+	struct malidp_hw_description hw_desc;
+	struct malidp_hw_pdata pdata;
+	struct video_tx_device *tx;
+	const struct malidp_devtype *malidp_dev;
+	int ret;
+
+	if (!of_id || !np) {
+		dev_err(&pdev->dev, "only device tree set up supported\n");
+		return -ENODEV;
+	}
+	malidp_dev = of_id->data;
+
+	dev = devm_kzalloc(&pdev->dev,
+			     sizeof(struct malidp_device),
+			     GFP_KERNEL);
+	if (!dev)
+		return -ENOMEM;
+
+	dev->device = &pdev->dev;
+
+	dev_dbg(&pdev->dev, "name: %s\n", of_id->name);
+	memset(&pdata, 0, sizeof(struct malidp_hw_pdata));
+	ret = malidp_hw_get_resources(pdev, np, &pdata);
+	if (ret < 0)
+		return ret;
+
+	dev->id = pdata.dp_id;
+
+	malidp_hw_enumerate(&hw_desc, malidp_dev->product, &pdata);
+
+	dev->hw_dev = malidp_hw_init(pdev, &hw_desc);
+	if (IS_ERR(dev->hw_dev)) {
+		dev_err(&pdev->dev, "failed to initialize the HW");
+		return PTR_ERR(dev->hw_dev);
+	}
+
+	dev->core_id = malidp_hw_get_core_id(dev->hw_dev);
+
+	snprintf(dev->name, ADF_NAME_LEN, "malidp");
+
+	dev->iommu_domain = malidp_iommu_init(&pdev->dev, pdev->dev.bus);
+	if (!dev->iommu_domain)
+		dev_info(&pdev->dev, "Continuing without IOMMU support\n");
+
+	tx = malidp_find_video_tx(dev, np);
+	if (!tx) {
+		dev_err(&pdev->dev, "deferring probe: failed to find video tx\n");
+		ret = -EPROBE_DEFER;
+		goto err_hw;
+	}
+
+	ret = malidp_adf_init(dev, &hw_desc, tx);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to initialize ADF device");
+		goto err_hw;
+	}
+
+	ret = malidp_sysfs_init(dev);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to initialize sysfs interface");
+		goto err_adf;
+	}
+
+	ret = malidp_debugfs_init(dev);
+	if (ret) {
+		dev_err(&pdev->dev, "failed initializing debugfs\n");
+		goto err_sysfs;
+	}
+
+	pm_runtime_set_suspended(&pdev->dev);
+	pm_runtime_enable(&pdev->dev);
+	if (!pm_runtime_enabled(&pdev->dev)) {
+		dev_info(&pdev->dev, "Continuing without Runtime PM support\n");
+		malidp_hw_runtime_resume(dev->hw_dev);
+		pm_runtime_set_active(&pdev->dev);
+	}
+
+#ifdef CONFIG_PM_SLEEP
+	dev->dp_pm_nb.notifier_call = malidp_pm_notifier;
+	ret = register_pm_notifier(&dev->dp_pm_nb);
+	if (ret) {
+		dev_err(&pdev->dev, "could not register pm notifier\n");
+		goto err_late;
+	}
+#endif
+
+	platform_set_drvdata(pdev, dev);
+
+	return 0;
+
+#ifdef CONFIG_PM_SLEEP
+err_late:
+	pm_runtime_disable(&pdev->dev);
+	if (!pm_runtime_status_suspended(&pdev->dev)) {
+		malidp_hw_runtime_suspend(dev->hw_dev);
+		pm_runtime_set_suspended(&pdev->dev);
+	}
+
+	debugfs_remove_recursive(dev->dbg_folder);
+#endif
+err_sysfs:
+	malidp_sysfs_destroy(dev);
+err_adf:
+	malidp_adf_destroy(dev);
+err_hw:
+	if (dev->iommu_domain)
+		malidp_iommu_exit(dev->iommu_domain);
+	malidp_hw_exit(dev->hw_dev);
+	return ret;
+}
+
+#ifdef CONFIG_PM_RUNTIME
+static int malidp_rt_pm_suspend(struct device *dev)
+{
+	struct malidp_device *dp_dev = to_malidp_dev(dev);
+
+	dev_info(dev, "%s\n", __func__);
+
+	malidp_hw_runtime_suspend(dp_dev->hw_dev);
+	return 0;
+}
+
+static int malidp_rt_pm_resume(struct device *dev)
+{
+	struct malidp_device *dp_dev = to_malidp_dev(dev);
+
+	dev_info(dev, "%s\n", __func__);
+	malidp_hw_runtime_resume(dp_dev->hw_dev);
+	malidp_adf_runtime_resume(dp_dev);
+	return 0;
+}
+#endif /* ! CONFIG_PM_RUNTIME */
+
+static const struct dev_pm_ops malidp_pm_ops = {
+	SET_RUNTIME_PM_OPS(malidp_rt_pm_suspend,
+			   malidp_rt_pm_resume,
+			   NULL)
+#ifdef CONFIG_PM_SLEEP
+	.suspend = malidp_sys_pm_suspend,
+	.suspend_late = malidp_sys_pm_suspend_late,
+	.resume_early = malidp_sys_pm_resume_early,
+	.complete = malidp_sys_pm_complete,
+#endif
+};
+
+static struct platform_driver malidp_driver = {
+	.probe  = malidp_probe,
+	.remove = malidp_remove,
+	.driver = {
+		.name   = MALIDP_NAME,
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(malidp_dt_ids),
+		.pm = &malidp_pm_ops,
+	},
+};
+
+module_platform_driver(malidp_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Mali-DP product driver");
+MODULE_VERSION(__stringify(VERSION_EPOCH) ":"
+	       __stringify(VERSION_MAJOR) "."
+	       __stringify(VERSION_MINOR)
+#ifdef DEBUG
+	       "-debug"
+#endif
+);
diff --git a/drivers/video/adf/arm/malidp_drv.h b/drivers/video/adf/arm/malidp_drv.h
new file mode 100644
index 0000000..02068fa
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_drv.h
@@ -0,0 +1,45 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_DRV_H_
+#define _MALIDP_DRV_H_
+
+#include <linux/clk.h>
+#include <video/adf.h>
+#include <linux/debugfs.h>
+
+struct malidp_hw_device;
+struct malidp_iommu_domain;
+
+struct malidp_device {
+	struct malidp_iommu_domain *iommu_domain;
+	struct malidp_hw_device *hw_dev;
+	struct device *device;
+	struct adf_device adf_dev;
+	char name[ADF_NAME_LEN];
+	u32 id;
+	u32 core_id;
+	u8 current_dpms;
+
+#ifdef CONFIG_PM_SLEEP
+	atomic_t suspending;
+	struct notifier_block dp_pm_nb;
+#endif
+	struct dentry *dbg_folder;
+};
+
+#endif /* _MALIDP_DRV_H_ */
diff --git a/drivers/video/adf/arm/malidp_hw.c b/drivers/video/adf/arm/malidp_hw.c
new file mode 100644
index 0000000..c700403
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_hw.c
@@ -0,0 +1,2161 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/slab.h>
+#include <asm/uaccess.h>
+#include <linux/pm_runtime.h>
+
+#include <uapi/drm/drm_fourcc.h>
+#include <uapi/video/malidp_adf.h>
+
+#include "malidp_product_api.h"
+#include "malidp_de_device.h"
+#include "malidp_se_device.h"
+#include "malidp_sysfs.h"
+
+#define MALIDP_AFBC_ALIGN_MASK 0xf
+
+#define MALIDP_MAX_EVENT_STRING 100
+
+/* Global register offset definitions */
+#define MALIDP_REG_DP500_CORE_ID	0x18
+#define MALIDP_REG_CORE_ID		0xC018
+#define		MALIDP_CFG_VALID		0x1
+#define MALIDP_REG_PER_ID_4	0x00
+#define MALIDP_REG_CONFIG_0 0x04
+#define		MALIDP_CONFIG_0_GET_DISP(x)	(((x) >> 0) & 0x1)
+#define		MALIDP_CONFIG_0_GET_LS(x)	(((x) >> 4) & 0x3)
+
+#define MALIDP_DEFAULT_ROTMEM_SIZE 0
+
+struct rotmem_partition {
+	int dividers[3];
+};
+
+struct malidp_hw_event_queue {
+	spinlock_t lock;
+	size_t n_events;
+	struct malidp_hw_event *queue;
+	/*
+	 * head == NULL when the queue is empty
+	 * head == tail when the queue is full
+	 */
+	struct malidp_hw_event *head;
+	struct malidp_hw_event *tail;
+};
+
+struct rotmem_partition fixed_partition_table[] = {
+	/* 1 layer */
+	{
+		.dividers = { 1, 0, 0 }
+	},
+	/* 2 layers */
+	{
+		.dividers = { 2, 2, 0 }
+	},
+	/* 3 layers */
+	{
+		.dividers = { 2, 4, 4 }
+	},
+};
+
+/* Start of HW description */
+
+const struct malidp_intf_hw_info dp_interfaces[] = {
+	{
+		.name = "Panel",
+		.type = MALIDP_HW_INTF_PRIMARY,
+		.idx = 0,
+	},
+	{
+		.name = "Memory",
+		.type = MALIDP_HW_INTF_MEMORY,
+		.idx = 0,
+	}
+};
+
+bool malidp_hw_format_is_yuv(u32 format)
+{
+	switch (format) {
+	case DRM_FORMAT_ARGB2101010:
+	case DRM_FORMAT_ABGR2101010:
+	case DRM_FORMAT_RGBA1010102:
+	case DRM_FORMAT_BGRA1010102:
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_BGRA8888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBX8888:
+	case DRM_FORMAT_BGRX8888:
+	case DRM_FORMAT_RGB888:
+	case DRM_FORMAT_BGR888:
+	case DRM_FORMAT_RGBA5551:
+	case DRM_FORMAT_ABGR1555:
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_BGR565:
+		return false;
+	case DRM_FORMAT_UYVY:
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_YUV420:
+	case MALIDP_FORMAT_XYUV:
+	case MALIDP_FORMAT_VYU30:
+	case MALIDP_FORMAT_YUV10_420AFBC:
+	case MALIDP_FORMAT_NV12AFBC:
+	case MALIDP_FORMAT_NV16AFBC:
+	case MALIDP_FORMAT_Y0L2:
+	case MALIDP_FORMAT_P010:
+		return true;
+	default:
+		BUG();
+	}
+}
+
+bool malidp_hw_format_has_alpha(u32 format)
+{
+	switch (format) {
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBX8888:
+	case DRM_FORMAT_BGRX8888:
+	case DRM_FORMAT_RGB888:
+	case DRM_FORMAT_BGR888:
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_BGR565:
+	case DRM_FORMAT_UYVY:
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_YUV420:
+	case MALIDP_FORMAT_XYUV:
+	case MALIDP_FORMAT_VYU30:
+	case MALIDP_FORMAT_YUV10_420AFBC:
+	case MALIDP_FORMAT_NV12AFBC:
+	case MALIDP_FORMAT_NV16AFBC:
+	case MALIDP_FORMAT_P010:
+	/* Y0L2 does have alpha, but Mali-DP will ignore it */
+	case MALIDP_FORMAT_Y0L2:
+		return false;
+	case DRM_FORMAT_ARGB2101010:
+	case DRM_FORMAT_ABGR2101010:
+	case DRM_FORMAT_RGBA1010102:
+	case DRM_FORMAT_BGRA1010102:
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_BGRA8888:
+	case DRM_FORMAT_RGBA5551:
+	case DRM_FORMAT_ABGR1555:
+		return true;
+	default:
+		BUG();
+	}
+}
+
+u32 malidp_hw_format_bpp(u32 format)
+{
+	switch (format)	{
+	case DRM_FORMAT_ARGB2101010:
+	case DRM_FORMAT_ABGR2101010:
+	case DRM_FORMAT_RGBA1010102:
+	case DRM_FORMAT_BGRA1010102:
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_BGRA8888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBX8888:
+	case DRM_FORMAT_BGRX8888:
+	case MALIDP_FORMAT_VYU30:
+	case MALIDP_FORMAT_XYUV:
+	case MALIDP_FORMAT_Y0L2:
+	case MALIDP_FORMAT_P010:
+		return 32;
+
+	case DRM_FORMAT_RGB888:
+	case DRM_FORMAT_BGR888:
+		return 24;
+
+	case DRM_FORMAT_RGBA5551:
+	case DRM_FORMAT_ABGR1555:
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_BGR565:
+	case DRM_FORMAT_UYVY:
+	case DRM_FORMAT_YUYV:
+	case MALIDP_FORMAT_NV16AFBC:
+		return 16;
+
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_YUV420:
+	case MALIDP_FORMAT_NV12AFBC:
+		return 12;
+
+	case MALIDP_FORMAT_YUV10_420AFBC:
+		return 15;
+
+	default:
+		BUG();
+	}
+}
+
+static void malidp_dump_hw_buf(struct malidp_hw_device *hwdev,
+		struct malidp_hw_buffer *buf)
+{
+	int i;
+	struct device *dev = hwdev->device;
+
+	dev_dbg(dev, "hw_buffer:\n");
+	if (buf->hw_layer) {
+		dev_dbg(dev, "  layer: %s\n", buf->hw_layer->name);
+	}
+	dev_dbg(dev, "  natural size: %ix%i\n", buf->natural_w, buf->natural_h);
+	dev_dbg(dev, "  cmp_scaling_enable = %s\n",
+		buf->cmp_scaling_enable ? "true" : "false");
+	dev_dbg(dev, "    cmp_rect src: %ix%i\n", buf->cmp_rect.src_w,
+			buf->cmp_rect.src_h);
+	dev_dbg(dev, "    cmp_rect dest: %ix%i\n", buf->cmp_rect.dest_w,
+			buf->cmp_rect.dest_h);
+	dev_dbg(dev, "  mw_scaling_enable = %s\n",
+		buf->mw_scaling_enable ? "true" : "false");
+	dev_dbg(dev, "    mw_rect src: %ix%i\n", buf->mw_rect.src_w,
+			buf->mw_rect.src_h);
+	dev_dbg(dev, "    mw_rect dest: %ix%i\n", buf->mw_rect.dest_w,
+			buf->mw_rect.dest_h);
+	dev_dbg(dev, "  offset: %ix%i\n",
+			buf->h_offset, buf->v_offset);
+	dev_dbg(dev, "  format: 0x%08x\n", buf->fmt);
+	dev_dbg(dev, "  HW format: 0x%x\n", buf->hw_fmt);
+
+	dev_dbg(dev, "  n_planes: %i\n", buf->n_planes);
+	dev_dbg(dev, "  address: ");
+	for (i = 0; i < buf->n_planes; i++) {
+		dev_dbg(dev, "    0x%llx", (unsigned long long)buf->addr[i]);
+	}
+	dev_dbg(dev, "  pitch: ");
+	for (i = 0; i < buf->n_planes; i++) {
+		dev_dbg(dev, "    %i", buf->pitch[i]);
+	}
+	dev_dbg(dev, "  flags: 0x%08x\n", buf->flags);
+	dev_dbg(dev, "  transform: 0x%08x\n", buf->transform);
+	dev_dbg(dev, "  alpha_mode: %i\n", buf->alpha_mode);
+	dev_dbg(dev, "  layer_alpha: %i\n", buf->layer_alpha);
+	dev_dbg(dev, "  write_out: %s\n", buf->write_out_enable ? "True" : "False");
+}
+
+struct malidp_hw_state_priv {
+	struct malidp_se_mw_conf mw;
+	enum malidp_de_flow_cmp_cfg cmp_flow;
+	/* LEOSW-409: layer_flow is product specific */
+	enum malidp_de_flow_layer_cfg layer_flow[MALIDP_MAX_LAYERS];
+	struct malidp_se_scaler_conf s0;
+};
+
+u32 malidp_hw_read(struct malidp_hw_device *hwdev, u32 reg)
+{
+	return readl(hwdev->regs + reg);
+}
+
+static const struct malidp_line_size_hw_info *malidp_hw_get_ls_info(
+		struct malidp_hw_device *hwdev,
+		struct malidp_hw_description *hw_desc)
+{
+	u32 config_raw;
+	u32 ls_config_id;
+
+	config_raw = malidp_hw_read(hwdev,
+		hwdev->hw_regmap->id_registers + MALIDP_REG_CONFIG_0);
+
+	ls_config_id = MALIDP_CONFIG_0_GET_LS(config_raw);
+
+	/* The HW can't report a line size config we don't understand */
+	if (ls_config_id >= hw_desc->config->n_configs) {
+		return NULL;
+	}
+
+	return &hw_desc->config->ls_configs[ls_config_id];
+}
+
+void malidp_hw_enumerate(struct malidp_hw_description *hw_desc,
+		enum malidp_hw_product product,
+		struct malidp_hw_pdata *pdata)
+{
+	switch (product) {
+	case MALI_DP500:
+		malidp_dp500_get_hw_description(hw_desc);
+		break;
+	case MALI_DP550:
+		malidp_dp550_get_hw_description(hw_desc);
+		break;
+	default:
+		BUG();
+	}
+
+	hw_desc->pdata = pdata;
+}
+
+void malidp_hw_write(struct malidp_hw_device *hwdev,
+					  u32 value, u32 reg)
+{
+	writel(value, hwdev->regs + reg);
+}
+
+void malidp_hw_setbits(struct malidp_hw_device *hwdev, u32 mask,
+			u32 reg)
+{
+	u32 data = malidp_hw_read(hwdev, reg);
+	data |= mask;
+	malidp_hw_write(hwdev, data, reg);
+}
+
+void malidp_hw_clearbits(struct malidp_hw_device *hwdev, u32 mask,
+			u32 reg)
+{
+	u32 data = malidp_hw_read(hwdev, reg);
+	data &= ~mask;
+	malidp_hw_write(hwdev, data, reg);
+}
+
+void malidp_hw_commit_scene_atomic(struct malidp_hw_device *hwdev, bool set)
+{
+	u32 val = 0;
+
+	dev_dbg(hwdev->device, "%s: start: set = %d\n", __func__, set);
+
+	if (set)
+		val = MALIDP_CFG_VALID;
+	malidp_hw_write(hwdev, val, hwdev->hw_regmap->config_valid);
+
+	dev_dbg(hwdev->device, "%s: end: set = %d\n", __func__, set);
+}
+
+static bool malidp_hw_validate_rotmem_fixed(struct malidp_hw_device *hwdev,
+				struct malidp_hw_state *state)
+{
+	struct rotmem_partition *table;
+	u32 rotmem_idx = 0;
+	u32 rotmem_count = 0;
+	int i, j, k;
+	struct malidp_hw_buffer *valid_hw_bufs[ARRAY_SIZE(fixed_partition_table)];
+
+	memset(valid_hw_bufs, 0, sizeof(valid_hw_bufs));
+
+	/*
+	 * First pass:
+	 * Find out the total number of buffers using rotation memory
+	 * and sort them.
+	 */
+	for (i = 0; i < state->n_bufs; i++) {
+		struct malidp_hw_buffer *hw_buf = &state->bufs[i];
+
+		/* Only AFBC and 90/270 rotations use rotation memory */
+		if ((hw_buf->flags & MALIDP_FLAG_AFBC) ||
+		   (hw_buf->transform & MALIDP_TRANSFORM_R90) ||
+		   (hw_buf->transform & MALIDP_TRANSFORM_R270)) {
+			rotmem_count++;
+			if (rotmem_count > ARRAY_SIZE(fixed_partition_table)) {
+				dev_err(hwdev->device, "Too many hw buffers using rotation memory\n");
+				return false;
+			}
+			for (j = 0; j < rotmem_count; j++) {
+				if (valid_hw_bufs[j] == NULL)
+					valid_hw_bufs[j] = hw_buf;
+				else if (valid_hw_bufs[j]->hw_layer->index >
+					    hw_buf->hw_layer->index) {
+					k = rotmem_count - 1;
+					valid_hw_bufs[k] = hw_buf;
+					while (k-- > j) {
+						struct malidp_hw_buffer *tmp;
+						tmp = valid_hw_bufs[k];
+						valid_hw_bufs[k] = valid_hw_bufs[k + 1];
+						valid_hw_bufs[k + 1] = tmp;
+					}
+					break;
+				}
+			}
+		}
+	}
+
+	/*
+	 * If no buffers use rotation memory
+	 * then there's nothing to validate
+	 */
+	if (!rotmem_count)
+		return true;
+
+	/* Get the correct set of dividers */
+	table = &fixed_partition_table[rotmem_count - 1];
+
+	/*
+	 * Second pass:
+	 * Validate each individual buffer that uses the memory
+	 */
+	for (i = 0; i < rotmem_count; i++) {
+		struct malidp_hw_buffer *hw_buf = valid_hw_bufs[i];
+		u32 layer_divider = table->dividers[rotmem_idx];
+		u32 layer_size = hwdev->dp_api->rotmem_size_required(
+							hw_buf);
+
+		/* Does the layer fit in it's parition? */
+		if (layer_size > (hwdev->rotmem_size / layer_divider)) {
+			dev_err(hwdev->device, "hwbuf(%d) uses too much rotation memory\n"
+				"\tAvailable: %d bytes\n"
+				"\tNeeded: %d bytes\n"
+				"\tCount: %d, Index: %d\n"
+				"\tWidth: %d, Format: %d bpp %d\n",
+				i, (hwdev->rotmem_size / layer_divider), layer_size,
+				rotmem_count, rotmem_idx, hw_buf->cmp_rect.src_w,
+				hw_buf->fmt,
+				malidp_hw_format_bpp(hw_buf->fmt));
+			return false;
+		}
+		rotmem_idx++;
+	}
+	return true;
+}
+
+static bool malidp_hw_validate_rotmem(struct malidp_hw_device *hwdev,
+				struct malidp_hw_state *state)
+{
+	switch (hwdev->partition_type) {
+	case MALIDP_HW_PARTITION_FIXED:
+		return malidp_hw_validate_rotmem_fixed(hwdev, state);
+	default:
+		BUG();
+	}
+}
+
+static int scale_f(u16 in, u16 out)
+{
+	int ret = 0;
+
+	if (in < out)
+		ret = 1; /* upscaling */
+	else if (in > out)
+		ret = -1; /* downscaling */
+
+	return ret;	/* -1: downscaling, 0: no scaling, 1: upscaing */
+}
+
+/* Check limition for scaler, if no limitaion found return true, or return false */
+static bool limitation_check(struct malidp_hw_device *hwdev,
+				struct malidp_hw_state_priv *hw_priv)
+{
+	bool scaling_to_dp = false, scaling_layer_to_mw = false;
+	int i;
+
+	if (hw_priv->s0.scaling_enable == false)
+		return true;
+
+	for (i = 0; i < hwdev->topology->n_layers; i++) {
+		if (hw_priv->layer_flow[i] == MALIDP_DE_LAYER_FLOW_SCALE_SE0)
+			scaling_to_dp = true;
+		else if (hw_priv->layer_flow[i] == MALIDP_DE_LAYER_FLOW_SIMULT_SE0)
+			scaling_layer_to_mw = true;
+	}
+
+	if (scaling_to_dp == true) {
+		if ((scale_f(hw_priv->s0.input_w, hw_priv->s0.output_w)) == -1 ||
+			(scale_f(hw_priv->s0.input_h, hw_priv->s0.output_h) == -1)) {
+			bool supported = hwdev->dp_api->se_api.limitation_check(hwdev->se_dev,
+										&hw_priv->s0);
+			if (!supported) {
+				return false;
+			}
+		}
+	}
+
+	if (scaling_layer_to_mw ||
+			((hw_priv->cmp_flow == MALIDP_DE_CMP_FLOW_SE0) && (hw_priv->mw.mode == MALIDP_SE_MW_L0))) {
+		if ((scale_f(hw_priv->s0.input_w, hw_priv->s0.output_w)) == 1 ||
+			(scale_f(hw_priv->s0.input_h, hw_priv->s0.output_h) == 1)) {
+			dev_err(hwdev->device,
+			"%s: Upscaling the layer or composition to mw only is not supported.",
+			__func__);
+			return false;
+		}
+	}
+
+	return true;
+}
+
+int malidp_hw_buffer_set_hw_fmt(struct malidp_hw_device *hwdev,
+	struct malidp_hw_buffer *hw_buf)
+{
+	const struct malidp_hw_topology *topo = hwdev->topology;
+	int res = -1;
+	unsigned int i;
+	bool afbc_support = false;
+
+	if (hw_buf->flags & MALIDP_FLAG_AFBC) {
+		for (i = 0; i < topo->n_supported_afbc_formats; i++) {
+			if (topo->supported_afbc_formats[i] == hw_buf->fmt) {
+				afbc_support = true;
+				if ((hw_buf->flags & MALIDP_FLAG_AFBC_SPLITBLK) &&
+				    !((1 << i) & topo->supported_afbc_splitblk))
+						afbc_support = false;
+				break;
+			}
+		}
+
+		if (!afbc_support) {
+			dev_err(hwdev->device, "Format 0x%08x unsupported for AFBC flags 0x%08x\n",
+				hw_buf->fmt, hw_buf->flags);
+			return -1;
+		}
+	} else if (hw_buf->transform) {
+		/*
+		 * This needs to be in an "else" branch because the limitations
+		 * don't apply for AFBC
+		 */
+		for (i = 0; i < topo->n_xform_invalid_formats; i++) {
+			if (topo->xform_invalid_formats[i] == hw_buf->fmt) {
+				dev_err(hwdev->device, "Transform not supported for format 0x%08x\n",
+					hw_buf->fmt);
+				return -1;
+			}
+		}
+	}
+
+	if (hw_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT) {
+		res = malidp_se_fmt_drm2mw(hwdev->se_dev, hw_buf->fmt);
+		if (res < 0) {
+			dev_err(hwdev->device, "Format 0x%08x unsupported for MW\n",
+				hw_buf->fmt);
+			return -1;
+		}
+		hw_buf->hw_fmt = res;
+	} else {
+		res = malidp_de_fmt_drm2hw(hwdev->de_dev, hw_buf);
+		if (res < 0) {
+			dev_err(hwdev->device, "Format 0x%08x unsupported\n",
+				hw_buf->fmt);
+			return -1;
+		}
+		hw_buf->hw_fmt = res;
+	}
+	return 0;
+}
+
+static void malidp_dump_all_hw_bufs(struct malidp_hw_device *hwdev,
+			struct malidp_hw_buffer *hw_bufs, int nbuf)
+{
+	int i;
+
+	for (i = 0; i < nbuf; i++)
+		malidp_dump_hw_buf(hwdev, &hw_bufs[i]);
+}
+
+bool malidp_hw_buf_support_srgb(struct malidp_hw_buffer *hw_buf)
+{
+	const struct malidp_layer_hw_info *layer = hw_buf->hw_layer;
+
+	if (layer->features & MALIDP_LAYER_FEATURE_SRGB)
+		return true;
+
+	return false;
+}
+
+static int malidp_hw_validate_srgb(struct malidp_hw_device *hwdev,
+	struct malidp_hw_buffer *hw_buf)
+{
+	if (!(hw_buf->flags & MALIDP_FLAG_SRGB))
+		return 0;
+
+	if (hw_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT) {
+		dev_err(hwdev->device,
+			"%s: buffer is sRGB but it is output buffer.\n",
+			__func__);
+		return -EINVAL;
+	}
+
+	if (malidp_hw_buf_support_srgb(hw_buf) == false) {
+		dev_err(hwdev->device,
+			"%s: buffer is sRGB but layer doesn't support.\n",
+			__func__);
+		return -EINVAL;
+	}
+
+	if (hw_buf->flags & MALIDP_FLAG_FORCE_NO_IGAMMA) {
+		dev_err(hwdev->device,
+			"%s: buffer is sRGB but IG block is disabled.\n",
+			__func__);
+		return -EINVAL;
+	}
+
+	if (malidp_hw_format_is_yuv(hw_buf->fmt) == true) {
+		dev_err(hwdev->device,
+			"%s: buffer is sRGB but its format (%u) is not supported\n",
+			__func__, hw_buf->fmt);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static bool malidp_hw_check_buf_overlap(const struct malidp_hw_buffer *buf_a,
+					const struct malidp_hw_buffer *buf_b) {
+	u16 top_a    = buf_a->v_offset;
+	u16 bottom_a = buf_a->v_offset + buf_a->natural_h;
+	u16 left_a   = buf_a->h_offset;
+	u16 right_a  = buf_a->h_offset + buf_a->natural_w;
+	u16 top_b    = buf_b->v_offset;
+	u16 bottom_b = buf_b->v_offset + buf_b->natural_h;
+	u16 left_b   = buf_b->h_offset;
+	u16 right_b  = buf_b->h_offset + buf_b->natural_w;
+
+	if (min(bottom_a, bottom_b) > max(top_a, top_b) &&
+	    min(right_a, right_b) > max(left_a, left_b)) {
+		return true;
+	}
+
+	return false;
+}
+
+static int malidp_hw_validate_smart_layer(struct malidp_hw_device *hwdev,
+					  struct malidp_hw_state *state,
+					  struct malidp_hw_buffer *ls_buf)
+{
+	u32 i;
+	struct malidp_hw_buffer *hw_bufs = state->bufs;
+	struct malidp_hw_smart_layer_state *ls_state = &state->ls_state;
+	struct malidp_hw_buffer *buf = &hw_bufs[ls_state->ls_hw_buf_idx[0]];
+
+	/* Check the "same format and same alpha" restriction and
+	 * suppose same buffer flags
+	 */
+	if (ls_buf->fmt != buf->fmt ||
+	    ls_buf->layer_alpha != buf->layer_alpha ||
+	    ls_buf->alpha_mode != buf->alpha_mode ||
+	    ls_buf->flags != buf->flags) {
+		dev_err(hwdev->device, "%s : The smart layers have different format or alpha settings or flags\n",
+				__func__);
+		return -EINVAL;
+	}
+
+	/* Check the "no overlap" restriction */
+	for (i = 0; i < ls_buf->ls_rect_idx; i++) {
+		buf = &hw_bufs[ls_state->ls_hw_buf_idx[i]];
+		if (malidp_hw_check_buf_overlap(ls_buf, buf)) {
+			dev_err(hwdev->device, "%s : The smart layer overlapped with an existing smart layer\n",
+					__func__);
+			return -EINVAL;
+		}
+	}
+
+	/* Check the "First sort on x offset, and then on y offset" restriction */
+	i = ls_state->ls_hw_buf_idx[ls_buf->ls_rect_idx-1];
+	buf = &hw_bufs[i];
+	if (buf->h_offset > ls_buf->h_offset ||
+	    (buf->h_offset == ls_buf->h_offset &&
+	     buf->v_offset > ls_buf->v_offset)) {
+		dev_err(hwdev->device, "%s : The smart layer x/y offset sort check failed\n",
+					__func__);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static bool malidp_hw_is_active_rect_in_bbox(struct malidp_hw_smart_layer_state *ls_state,
+					     struct malidp_hw_buffer *ls_buf)
+{
+	u16 bbox_w = ls_state->ls_bbox_right - ls_state->ls_bbox_left;
+	u16 bbox_h = ls_state->ls_bbox_bottom - ls_state->ls_bbox_top;
+
+	if ((ls_buf->v_offset + ls_buf->natural_h) > bbox_h ||
+	    (ls_buf->h_offset + ls_buf->natural_w) > bbox_w) {
+		return false;
+	}
+
+	return true;
+}
+
+int malidp_hw_validate(struct malidp_hw_device *hwdev,
+		struct malidp_hw_state *state)
+{
+	struct drm_mode_modeinfo mode;
+	struct malidp_hw_buffer *de_buffer_to_mw = NULL;
+	struct malidp_hw_buffer *out_buffer = NULL;
+	int n_write_out_buffers = 0, n_scaling_on_mw = 0;
+	u32 n_hw_layers = hwdev->topology->n_layers;
+	u32 *n_bufs_per_layer;
+	unsigned long flags;
+	u32 min_size = hwdev->ls_info->min_line_size;
+	u32 max_size = hwdev->ls_info->max_line_size;
+	u32 smart_layer_idx = 0;
+	int i, ret = -EINVAL;
+
+	struct malidp_hw_state_priv *hw_priv =
+		kzalloc(sizeof(*hw_priv), GFP_KERNEL);
+	if (!hw_priv)
+		return -ENOMEM;
+
+	n_bufs_per_layer = kzalloc(sizeof(*n_bufs_per_layer) * n_hw_layers,
+				   GFP_KERNEL);
+	if (!n_bufs_per_layer) {
+		ret = -ENOMEM;
+		goto error;
+	}
+
+	for (i = 0; i < n_hw_layers; i++)
+		hw_priv->layer_flow[i] = MALIDP_DE_LAYER_FLOW_LOCAL;
+
+	malidp_dump_all_hw_bufs(hwdev, state->bufs, state->n_bufs);
+
+	for (i = 0; i < state->n_bufs; i++) {
+		struct malidp_hw_buffer *hw_buf = &state->bufs[i];
+
+		if (hw_buf->hw_layer &&
+		    hw_buf->hw_layer->type == MALIDP_HW_LAYER_SMART) {
+			struct malidp_hw_smart_layer_state *ls_state = &state->ls_state;
+
+			BUG_ON(smart_layer_idx != hw_buf->ls_rect_idx);
+			/* We don't need check the first smart layer */
+			if (smart_layer_idx > 0) {
+				if (malidp_hw_validate_smart_layer(hwdev, state, hw_buf)) {
+					dev_err(hwdev->device, "%s : smart layer validation failed\n",
+						__func__);
+					goto error;
+				}
+			}
+
+			if (ls_state->ls_bbox_from_user &&
+			    !(malidp_hw_is_active_rect_in_bbox(ls_state, hw_buf))) {
+				dev_err(hwdev->device, "%s : smart layer active rect %d is out of the bounding box\n",
+					__func__, smart_layer_idx);
+				goto error;
+			}
+
+			smart_layer_idx++;
+		}
+
+		if (malidp_hw_validate_srgb(hwdev, hw_buf) != 0)
+			goto error;
+
+		switch (hw_buf->n_planes) {
+		case 3:
+			/*
+			 * The hardware behaviour is as follows:
+			 * "For 3 planes the last bits of the cropping are
+			 * determined by LV2PTR[2:0] and LV1PTR[2:0]/LV3PTR[2:0]
+			 * are ignored."
+			 *
+			 * Compatibility with these constraints is enforced by
+			 * the following checks:
+			 * The plane 0 pointer must be even, as the hardware
+			 * will ignore the least significant bit.
+			 * The plane 2 pointer least-significant bits must match
+			 * the plane 1 pointer, as the hardware will ignore the
+			 * plane 2 value and use the plane 1 value directly
+			 */
+			if ((hw_buf->addr[0] & 0x1) ||
+			    ((hw_buf->addr[1] & 0x7) != (hw_buf->addr[2] & 0x7))) {
+				dev_err(hwdev->device, "%s : buffer %i does not meet alignment constraints\n",
+					__func__, i);
+				goto error;
+			}
+
+			/*
+			 * The 3rd stride will be ignored on some hardware,
+			 * so the 2nd and 3rd pitches of the buffer must be same.
+			 */
+			if ((hw_buf->pitch[2] != hw_buf->pitch[1]) &&
+			    (!hw_buf->hw_layer->p3_stride_offset)) {
+				dev_err(hwdev->device, "%s : the second and third strides are not same\n",
+					__func__);
+				goto error;
+			}
+			break;
+		case 2:
+			/*
+			 * The hardware behaviour is as follows:
+			 * "For 2 plane the last bits of the cropping are
+			 *  determined by bits [2:0] of the LV1PTR register and
+			 *  the [2:0] bits in LV2PTR are ignored."
+			 *
+			 * Compatibility with these constraints is enforced by
+			 * the following checks:
+			 * The plane 0 pointer must be even, as the hardware
+			 * will ignore the least significant bit.
+			 * The plane 1 pointer least-significant bits must match
+			 * the plane 0 pointer, as the hardware will ignore the
+			 * plane 1 value and use the plane 0 value directly
+			 */
+			if ((hw_buf->addr[0] & 0x1) ||
+			    ((hw_buf->addr[0] & 0x7) != (hw_buf->addr[1] & 0x7))) {
+				dev_err(hwdev->device, "%s : buffer %i does not meet alignment constraints\n",
+					__func__, i);
+				goto error;
+			}
+			break;
+		case 1:
+			/* AFBC buffers have to be 128-bit aligned */
+			if ((hw_buf->flags & MALIDP_FLAG_AFBC) &&
+				(hw_buf->addr[0] & MALIDP_AFBC_ALIGN_MASK)) {
+				dev_err(hwdev->device, "%s : AFBC buffers must be aligned to %u bytes (including offset)\n",
+					__func__, MALIDP_AFBC_ALIGN_MASK + 1);
+				goto error;
+			}
+			break;
+		default:
+			/* Nothing to do */
+			break;
+		}
+
+		if ((hw_buf->cmp_rect.src_w < min_size) || (hw_buf->cmp_rect.src_h < min_size) ||
+		    (hw_buf->cmp_rect.dest_w < min_size) || (hw_buf->cmp_rect.dest_h < min_size)) {
+			dev_err(hwdev->device, "%s : buffer dimensions too small. src: %ix%i, dest: %ix%i\n", __func__,
+				hw_buf->cmp_rect.src_w, hw_buf->cmp_rect.src_h,
+				hw_buf->cmp_rect.dest_w, hw_buf->cmp_rect.dest_h);
+			goto error;
+		}
+
+		if ((hw_buf->mw_rect.src_w < min_size) || (hw_buf->mw_rect.src_h < min_size) ||
+		    (hw_buf->mw_rect.dest_w < min_size) || (hw_buf->mw_rect.dest_h < min_size)) {
+			dev_err(hwdev->device, "%s : buffer dimensions too small. src: %ix%i, dest: %ix%i\n", __func__,
+				hw_buf->mw_rect.src_w, hw_buf->mw_rect.src_h,
+				hw_buf->mw_rect.dest_w, hw_buf->mw_rect.dest_h);
+			goto error;
+		}
+
+		if ((hw_buf->cmp_rect.src_w > max_size) || (hw_buf->cmp_rect.src_h > max_size) ||
+		    (hw_buf->cmp_rect.dest_w > max_size) || (hw_buf->cmp_rect.dest_h > max_size)) {
+			dev_err(hwdev->device, "%s : buffer dimensions too big. src: %ix%i, dest: %ix%i\n", __func__,
+				hw_buf->cmp_rect.src_w, hw_buf->cmp_rect.src_h,
+				hw_buf->cmp_rect.dest_w, hw_buf->cmp_rect.dest_h);
+			goto error;
+		}
+
+		if ((hw_buf->mw_rect.src_w > max_size) || (hw_buf->mw_rect.src_h > max_size) ||
+		    (hw_buf->mw_rect.dest_w > max_size) || (hw_buf->mw_rect.dest_h > max_size)) {
+			dev_err(hwdev->device, "%s : buffer dimensions too big. src: %ix%i, dest: %ix%i\n", __func__,
+				hw_buf->mw_rect.src_w, hw_buf->mw_rect.src_h,
+				hw_buf->mw_rect.dest_w, hw_buf->mw_rect.dest_h);
+			goto error;
+		}
+
+		if ((hw_buf->alpha_mode & MALIDP_ALPHA_MODE_PREMULT) &&
+		    !(hw_buf->alpha_mode & MALIDP_ALPHA_MODE_PIXEL)) {
+			dev_err(hwdev->device, "hwbuf(%d) pre-multiplied alpha "
+				"only supported with pixel alpha blending\n", i);
+			goto error;
+		}
+
+		if ((hw_buf->alpha_mode & MALIDP_ALPHA_MODE_PIXEL) &&
+		    !malidp_hw_format_has_alpha(hw_buf->fmt)) {
+			dev_err(hwdev->device, "hwbuf(%d) alpha pixel mode set "
+				"for a pixel format without alpha\n", i);
+			goto error;
+		}
+
+		if (malidp_hw_buffer_set_hw_fmt(hwdev, hw_buf)) {
+			dev_err(hwdev->device,
+				"Couldn't get HW pixel format for buffer %i\n",
+				i);
+			goto error;
+		} else {
+			dev_dbg(hwdev->device, "Set buffer %i hw_fmt: 0x%08x -> 0x%x\n",
+				i, hw_buf->fmt, hw_buf->hw_fmt);
+		}
+
+		if (hw_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT) {
+			if (out_buffer != NULL) {
+				dev_err(hwdev->device, "found more than one output buffer\n");
+				goto error;
+			}
+			out_buffer = &state->bufs[i];
+
+			/* The output buffer cannot be transformed */
+			if (out_buffer->requirements & MALIDP_LAYER_FEATURE_TRANSFORM) {
+				dev_err(hwdev->device, "output buffer cannot be transformed");
+				goto error;
+			}
+
+			/* The output buffer cannot AFBC */
+			if (out_buffer->requirements & MALIDP_LAYER_FEATURE_AFBC) {
+				dev_err(hwdev->device, "output buffer cannot be compressed");
+				goto error;
+			}
+
+			/* cmp_scaling_enable of output buffer should not be 'true' */
+			if (out_buffer->cmp_scaling_enable == true) {
+				dev_err(hwdev->device, "output buffer should not have cmp_scaling_enable set");
+				goto error;
+			}
+		} else {
+			if ((hw_buf->requirements & hw_buf->hw_layer->features) !=
+			    hw_buf->requirements) {
+				dev_err(hwdev->device,
+					"%s: buffer requirements %08x not compatible with layer features %08x\n",
+					__func__, hw_buf->requirements, hw_buf->hw_layer->features);
+				goto error;
+			}
+			if (hw_buf->write_out_enable) {
+				n_write_out_buffers++;
+				de_buffer_to_mw = &state->bufs[i];
+			}
+		}
+
+		if (hw_buf->cmp_scaling_enable) {
+
+			if (hw_buf->mw_scaling_enable == false) {
+				dev_err(hwdev->device, "Input buffer cannot be scaled to composition and not be scaled to MW interface");
+				goto error;
+			} else if (((hw_buf->cmp_rect.dest_w != hw_buf->mw_rect.dest_w) ||
+							(hw_buf->cmp_rect.dest_h != hw_buf->mw_rect.dest_h)) && hw_buf->mw_scaling_enable == true) {
+				dev_err(hwdev->device, "Input buffer cannot be scaled different to composition and MW interface");
+				goto error;
+			}
+
+			if (hw_priv->s0.scaling_enable == true) {
+				dev_err(hwdev->device, "%s: more than 1 input layer to be scaled is not support", __func__);
+				goto error;
+			}
+
+			hw_priv->layer_flow[hw_buf->hw_layer->index] = MALIDP_DE_LAYER_FLOW_SCALE_SE0;
+			hw_priv->s0.scaling_enable = true;
+			hw_priv->s0.input_h = hw_buf->cmp_rect.src_h;
+			hw_priv->s0.input_w = hw_buf->cmp_rect.src_w;
+			hw_priv->s0.output_h = hw_buf->cmp_rect.dest_h;
+			hw_priv->s0.output_w = hw_buf->cmp_rect.dest_w;
+			hw_priv->s0.rgbo_enable = true;
+			hw_priv->s0.scale_alpha = malidp_hw_format_has_alpha(hw_buf->fmt);
+		} else if (!(hw_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT) && hw_buf->mw_scaling_enable) {
+			dev_dbg(hwdev->device, "MW Scaling is detected\n");
+
+			hw_priv->layer_flow[hw_buf->hw_layer->index] = MALIDP_DE_LAYER_FLOW_SIMULT_SE0;
+			hw_priv->s0.input_h = hw_buf->mw_rect.src_h;
+			hw_priv->s0.input_w = hw_buf->mw_rect.src_w;
+			hw_priv->s0.output_h = hw_buf->mw_rect.dest_h;
+			hw_priv->s0.output_w = hw_buf->mw_rect.dest_w;
+			hw_priv->s0.scale_alpha = malidp_hw_format_has_alpha(hw_buf->fmt);
+			hw_priv->s0.rgbo_enable = false;
+			hw_priv->s0.scaling_enable = true;
+			n_scaling_on_mw++;
+		}
+
+		if (hw_buf->hw_layer) {
+			if (n_bufs_per_layer[hw_buf->hw_layer->index] >=
+					hw_buf->hw_layer->n_supported_layers) {
+				dev_err(hwdev->device, "%s: more than max %d buffers for layer %i\n",
+					__func__, hw_buf->hw_layer->n_supported_layers,
+					hw_buf->hw_layer->index);
+				goto error;
+			}
+			n_bufs_per_layer[hw_buf->hw_layer->index]++;
+		}
+
+	}
+
+	/* If all input layers are scaled to mw, then just scale composition */
+	if ((n_scaling_on_mw == state->n_bufs -1) && (out_buffer != NULL && out_buffer->mw_scaling_enable == true)) {
+		/* Disable it, then scaler will be configured to scale composition */
+		hw_priv->s0.scaling_enable = false;
+		/* All the layers will not be sent to SE */
+		for (i = 0; i < n_hw_layers; i++)
+			hw_priv->layer_flow[i] = MALIDP_DE_LAYER_FLOW_LOCAL;
+	} else if (n_scaling_on_mw > 0 && out_buffer == NULL) {
+		dev_err(hwdev->device, "%s: Output buffer is not found", __func__);
+		goto error;
+	} else if (n_scaling_on_mw >= 2) {
+		dev_err(hwdev->device, "%s: More than one but not all layers are scaled to memory", __func__);
+		goto error;
+	}
+
+	/*
+	 * Validate that the scene uses rotation memory appropriately
+	 */
+	if (!malidp_hw_validate_rotmem(hwdev, state))
+		goto error;
+
+	/* Find flow for memory write-out, set scaler configuration for scaling composition to mw */
+	hw_priv->cmp_flow = MALIDP_DE_CMP_FLOW_INTERNAL;
+	if ((n_write_out_buffers == 0) && (!out_buffer)) {
+		/* Do not use the memory write-out interface */
+		hw_priv->mw.mode = MALIDP_SE_MW_DISABLE;
+		hw_priv->mw.buf = NULL;
+	} else if ((n_write_out_buffers == (state->n_bufs - 1)) &&
+		    out_buffer && out_buffer->write_out_enable) {
+		/* Write out the result of the composition.*/
+		spin_lock_irqsave(&hwdev->hw_lock, flags);
+		malidp_de_modeget(hwdev->de_dev, &mode);
+		spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+
+		if ((out_buffer->mw_rect.src_w != mode.hdisplay) ||
+				(out_buffer->mw_rect.src_h != mode.vdisplay)) {
+			dev_err(hwdev->device, "output buffer src size did not match the mode");
+			goto error;
+		}
+		/* check whether output buffer need be scaled */
+		if (out_buffer->mw_scaling_enable == true) {
+			if (hw_priv->s0.scaling_enable == true) {
+				dev_err(hwdev->device, "no scaler for MW");
+				goto error;
+			}
+			hw_priv->mw.mode = MALIDP_SE_MW_L0;
+
+			/* Scale the composition to memory */
+			hw_priv->s0.input_h = out_buffer->mw_rect.src_h;
+			hw_priv->s0.input_w = out_buffer->mw_rect.src_w;
+			hw_priv->s0.output_h = out_buffer->mw_rect.dest_h;
+			hw_priv->s0.output_w = out_buffer->mw_rect.dest_w;
+			hw_priv->s0.scale_alpha = malidp_hw_format_has_alpha(out_buffer->fmt);
+			hw_priv->s0.rgbo_enable = false;
+			hw_priv->s0.scaling_enable = true;
+		} else {
+			hw_priv->mw.mode = (hw_priv->s0.scaling_enable == true) ? MALIDP_SE_MW_L1 : MALIDP_SE_MW_L0;
+
+			/* for L1, no alpha compoment */
+			if (hw_priv->mw.mode == MALIDP_SE_MW_L1 && malidp_hw_format_has_alpha(out_buffer->fmt)) {
+				dev_err(hwdev->device,
+					"hwbuf(%d) alpha not supported when writing-out "
+					"the result of the composition\n", i);
+				goto error;
+			}
+		}
+
+		hw_priv->mw.buf = out_buffer;
+		hw_priv->cmp_flow = MALIDP_DE_CMP_FLOW_SE0;
+	} else if ((n_write_out_buffers == 1) && out_buffer &&
+		    !out_buffer->write_out_enable) {
+		/* Write out the layer indicated by "de_buffer_to_mw" */
+
+		if (!(de_buffer_to_mw->hw_layer->features & MALIDP_LAYER_FEATURE_SCALING)) {
+			dev_err(hwdev->device, "writing layer %s to memory is not supported",
+				de_buffer_to_mw->hw_layer->name);
+			goto error;
+		}
+
+		hw_priv->mw.mode = MALIDP_SE_MW_L0;
+		hw_priv->mw.buf = out_buffer;
+		/* if the layer will be scaled, the size of cmp_rect.dest, should be same as the size of output */
+		if (de_buffer_to_mw->cmp_scaling_enable) {
+			if ((de_buffer_to_mw->cmp_rect.dest_w != out_buffer->mw_rect.dest_w) ||
+				(de_buffer_to_mw->cmp_rect.dest_h != out_buffer->mw_rect.dest_h)) {
+				dev_err(hwdev->device, "scaled input buffer size does not match output size");
+				goto error;
+			}
+		}
+
+		if (hw_priv->layer_flow[de_buffer_to_mw->hw_layer->index] == MALIDP_DE_LAYER_FLOW_LOCAL) {
+			hw_priv->layer_flow[de_buffer_to_mw->hw_layer->index] = MALIDP_DE_LAYER_FLOW_SIMULT_SE0;
+		}
+
+	} else {
+		/* Error condition */
+		dev_err(hwdev->device, "couldn't determine memory write-out configuration");
+		goto error;
+	}
+
+	if (!limitation_check(hwdev, hw_priv))
+		goto error;
+
+	malidp_se_set_scaling_dependent_state(hwdev->se_dev, &hw_priv->s0);
+	state->hw_priv = hw_priv;
+	kfree(n_bufs_per_layer);
+
+	return 0;
+
+error:
+	kfree(n_bufs_per_layer);
+	kfree(hw_priv);
+
+	return ret;
+};
+
+void malidp_hw_state_free(struct malidp_hw_device *hwdev,
+		struct malidp_hw_state *state)
+{
+	kfree(state->hw_priv);
+};
+
+int malidp_hw_commit(struct malidp_hw_device *hwdev,
+		struct malidp_hw_state *state)
+{
+	int i, res = 0;
+	unsigned long flags;
+	struct malidp_hw_state_priv *hw_priv = state->hw_priv;
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+
+	dev_dbg(hwdev->device, "%s: start\n", __func__);
+
+	malidp_hw_commit_scene_atomic(hwdev, false);
+
+	malidp_de_disable_all_layers(hwdev->de_dev);
+
+	for (i = 0; i < state->n_bufs; i++) {
+		struct malidp_hw_buffer *hw_buf = &state->bufs[i];
+
+		if (!(hw_buf->flags & MALIDP_FLAG_BUFFER_OUTPUT)) {
+			res = malidp_de_cfg_layer(hwdev->de_dev, hw_buf);
+			if (res)
+				dev_err(hwdev->device, "%s : cfg layer returned %i",
+						__func__, res);
+		}
+	}
+
+	if (state->ls_state.ls_hw_layer) {
+		dev_dbg(hwdev->device, "%s, smart layer state: bounding box (%d, %d, %d, %d), active smart layers (%d)\n",
+			__func__,
+			state->ls_state.ls_bbox_top,
+			state->ls_state.ls_bbox_left,
+			state->ls_state.ls_bbox_bottom,
+			state->ls_state.ls_bbox_right,
+			state->ls_state.n_smart_layers);
+		malidp_de_cfg_smart_state(hwdev->de_dev, &state->ls_state);
+	}
+
+	/* Set flows for the different layers and composition result */
+	malidp_de_cfg_cmp_flow(hwdev->de_dev, hw_priv->cmp_flow);
+	for (i = 0; i < hwdev->topology->n_layers; i++) {
+		malidp_de_cfg_layer_flow(hwdev->de_dev,
+				 &hwdev->topology->layers[i],
+				 hw_priv->layer_flow[i]);
+	}
+
+	malidp_se_cfg_processing(hwdev->se_dev, &hw_priv->mw, &hw_priv->s0);
+
+	malidp_hw_commit_scene_atomic(hwdev, true);
+
+	dev_dbg(hwdev->device, "%s: end\n", __func__);
+
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+	return res;
+}
+
+static void malidp_hw_pdata_dump(struct platform_device *pdev,
+				struct malidp_hw_pdata *pdata)
+{
+	dev_dbg(&pdev->dev, "%s:\n", __func__);
+	dev_dbg(&pdev->dev, "pxclk: %p, mclk: %p, aclk: %p, pclk: %p\n",
+		pdata->pxclk, pdata->mclk, pdata->aclk, pdata->pclk);
+	dev_dbg(&pdev->dev, "de axi burst length = %d\n", pdata->de_axi_burstlen);
+	dev_dbg(&pdev->dev, "de axi outstanding transactions = %d\n",
+		pdata->de_axi_outstran);
+	dev_dbg(&pdev->dev, "de axi arqos threshold low = 0x%X\n",
+		pdata->de_axi_arqos_low);
+	dev_dbg(&pdev->dev, "de axi arqos threshold high = 0x%X\n",
+		pdata->de_axi_arqos_high);
+	dev_dbg(&pdev->dev, "de axi arqos red = 0x%X\n",
+		pdata->de_axi_arqos_red);
+	dev_dbg(&pdev->dev, "de axi arqos green = 0x%X\n",
+		pdata->de_axi_arqos_green);
+	dev_dbg(&pdev->dev, "se axi burst length = %d\n", pdata->se_axi_burstlen);
+	dev_dbg(&pdev->dev, "se axi outstanding transactions = %d\n",
+		pdata->se_axi_outstran);
+	dev_dbg(&pdev->dev, "se axi awcache  %d\n", pdata->se_axi_awcache);
+	dev_dbg(&pdev->dev, "se axi qos = %d\n", pdata->se_axi_awqos);
+	dev_dbg(&pdev->dev, "rotmem size = %d\n", pdata->rotmem_size);
+}
+
+char *malidp_hw_get_event_string(char *string, int max, struct malidp_hw_event *event)
+{
+	int i = 0;
+
+	if (!string)
+		return NULL;
+
+	if (event->type == MALIDP_HW_EVENT_NONE) {
+		if (max <= 4)
+			return NULL;
+		sprintf(string, "NONE");
+	} else {
+		if (event->type & MALIDP_HW_EVENT_FLIP) {
+			if (max <= i + 6)
+				return NULL;
+			i += sprintf(string + i, "FLIP |");
+		}
+		if (event->type & MALIDP_HW_EVENT_ERROR) {
+			if (max <= i + 7)
+				return NULL;
+			i += sprintf(string + i, "ERROR |");
+			if (event->type & MALIDP_HW_ERROR_URUN) {
+				if (max <= i + 10)
+					return NULL;
+				i += sprintf(string + i, "UNDERRUN |");
+			}
+			if (event->type & MALIDP_HW_ERROR_ORUN) {
+				if (max <= i + 9)
+					return NULL;
+				i += sprintf(string + i, "OVERRUN |");
+			}
+			if (event->type & MALIDP_HW_ERROR_AXI) {
+				if (max <= i + 8)
+					return NULL;
+				i += sprintf(string + i, "AXIERR |");
+			}
+			if (event->type & MALIDP_HW_ERROR_QFULL) {
+				if (max <= i + 7)
+					return NULL;
+				i += sprintf(string + i, "QFULL |");
+			}
+			if (event->type & MALIDP_HW_ERROR_IBUSY) {
+				if (max <= i + 7)
+					return NULL;
+				i += sprintf(string + i, "IBUSY |");
+			}
+		}
+		if (event->type & MALIDP_HW_EVENT_VSYNC) {
+			if (max <= i + 7)
+				return NULL;
+			i += sprintf(string + i, "VSYNC |");
+		}
+		if (event->type & MALIDP_HW_EVENT_START) {
+			if (max <= i + 7)
+				return NULL;
+			i += sprintf(string + i, "START |");
+		}
+		if (event->type & MALIDP_HW_EVENT_NEWCFG) {
+			if (max <= i + 8)
+				return NULL;
+			i += sprintf(string + i, "NEWCFG |");
+		}
+		if (event->type & MALIDP_HW_EVENT_STOP) {
+			if (max <= i + 6)
+				return NULL;
+			i += sprintf(string + i, "STOP |");
+		}
+	}
+
+	return string;
+}
+
+/* Populate pdata structure using device tree description */
+int malidp_hw_get_resources(struct platform_device *pdev,
+			       struct device_node *nproot,
+			       struct malidp_hw_pdata *pdata)
+{
+	struct resource *res;
+	u32 props;
+	int i, ret;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(&pdev->dev, "Could not get registers resource\n");
+		return -ENOMEM;
+	}
+
+	pdata->regs = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(pdata->regs))
+		return -ENOMEM;
+
+	pdata->de_irq = -1;
+	pdata->se_irq = -1;
+	for (i = 0; i < 2; i++) {
+		res = platform_get_resource(pdev, IORESOURCE_IRQ, i);
+		if (!res) {
+			dev_err(&pdev->dev, "Could not get irq %d\n", i);
+			return -EINVAL;
+		}
+		if (!strcmp("DE", res->name)) {
+			if (pdata->de_irq < 0) {
+				pdata->de_irq = res->start;
+			} else {
+				dev_err(&pdev->dev, "IRQ '%s' already assigned\n", res->name);
+				return -EINVAL;
+			}
+		} else if (!strcmp("SE", res->name)) {
+			if (pdata->se_irq < 0) {
+				pdata->se_irq = res->start;
+			} else {
+				dev_err(&pdev->dev, "IRQ '%s' already assigned\n", res->name);
+				return -EINVAL;
+			}
+		} else {
+			dev_err(&pdev->dev, "Wrong name (%s) for irq %d\n",
+				res->name, i);
+			return -EINVAL;
+		}
+	}
+
+	pdata->pxclk = devm_clk_get(&pdev->dev, "pxclk");
+	if (!pdata->pxclk) {
+		dev_err(&pdev->dev, "Could not get pxclk");
+		return -EINVAL;
+	}
+
+	pdata->mclk = devm_clk_get(&pdev->dev, "mclk");
+	if (!pdata->mclk) {
+		dev_err(&pdev->dev, "Could not get mclk");
+		return -EINVAL;
+	}
+
+	pdata->aclk = devm_clk_get(&pdev->dev, "aclk");
+	if (!pdata->aclk) {
+		dev_err(&pdev->dev, "Could not get aclk");
+		return -EINVAL;
+	}
+
+	pdata->pclk = devm_clk_get(&pdev->dev, "pclk");
+	if (!pdata->pclk) {
+		dev_err(&pdev->dev, "Could not get pclk");
+		return -EINVAL;
+	}
+
+	/*
+	 * Optional, non-standard properties are retrieved parsing
+	 * the device-tree description directly. If we wanted to add support
+	 * for initializing using board files we would need to use a custom
+	 * pdata structure in <linux/platform_data/malidp.h>.
+	 */
+	ret = of_property_read_u32(nproot, "de-axi-burst-length", &props);
+	if (ret == 0)
+		pdata->de_axi_burstlen = props;
+	else
+		pdata->de_axi_burstlen = DE_DEFAULT_AXI_BURSTLEN;
+
+	ret = of_property_read_u32(nproot, "de-axi-poutstdcab", &props);
+	if (ret == 0)
+		pdata->de_axi_poutstdcab = props;
+	else
+		pdata->de_axi_poutstdcab = DE_DEFAULT_AXI_POUTSTDCAB;
+
+	ret = of_property_read_u32(nproot,
+				   "de-axi-outstanding-transactions", &props);
+	if (ret == 0)
+		pdata->de_axi_outstran = props;
+	else
+		pdata->de_axi_outstran = DE_DEFAULT_AXI_OUTSTRAN;
+
+	ret = of_property_read_u32(nproot,
+				   "de-axi-arqos-threshold-low", &props);
+	if (ret == 0)
+		pdata->de_axi_arqos_low = props;
+	else
+		pdata->de_axi_arqos_low = DE_DEFAULT_AXI_ARQOS_LOW;
+
+	ret = of_property_read_u32(nproot,
+				   "de-axi-arqos-threshold-high", &props);
+	if (ret == 0)
+		pdata->de_axi_arqos_high = props;
+	else
+		pdata->de_axi_arqos_high = DE_DEFAULT_AXI_ARQOS_HIGH;
+
+	ret = of_property_read_u32(nproot, "de-axi-arqos-red", &props);
+	if (ret == 0)
+		pdata->de_axi_arqos_red = props;
+	else
+		pdata->de_axi_arqos_red = DE_DEFAULT_AXI_ARQOS_RED;
+
+	ret = of_property_read_u32(nproot, "de-axi-arqos-green", &props);
+	if (ret == 0)
+		pdata->de_axi_arqos_green = props;
+	else
+		pdata->de_axi_arqos_green = DE_DEFAULT_AXI_ARQOS_GREEN;
+
+	ret = of_property_read_u32(nproot, "se-axi-burst-length", &props);
+	if (ret == 0)
+		pdata->se_axi_burstlen = props;
+	else
+		pdata->se_axi_burstlen = SE_DEFAULT_AXI_BURSTLEN;
+
+	ret = of_property_read_u32(nproot,
+				   "se-axi-outstanding-transactions", &props);
+	if (ret == 0)
+		pdata->se_axi_outstran = props;
+	else
+		pdata->se_axi_outstran = SE_DEFAULT_AXI_OUTSTRAN;
+
+	ret = of_property_read_u32(nproot, "se-axi-awcache", &props);
+	if (ret == 0)
+		pdata->se_axi_awcache = props;
+	else
+		pdata->se_axi_awcache = SE_DEFAULT_AXI_AWCACHE;
+
+	ret = of_property_read_u32(nproot, "se-axi-awqos", &props);
+	if (ret == 0)
+		pdata->se_axi_awqos = props;
+	else
+		pdata->se_axi_awqos = SE_DEFAULT_AXI_AWQOS;
+
+	ret = of_property_read_u32(nproot, "rotmem", &props);
+	if (ret == 0)
+		pdata->rotmem_size = props * SZ_1K;
+	else
+		pdata->rotmem_size = MALIDP_DEFAULT_ROTMEM_SIZE;
+
+	ret = of_alias_get_id(nproot, "malidp");
+	if (ret < 0) {
+		dev_err(&pdev->dev, "Could not get alias id\n");
+
+		/* Fallback to use the node phandle */
+		pdata->dp_id = nproot->phandle;
+	} else {
+		pdata->dp_id = ret;
+	}
+
+	malidp_hw_pdata_dump(pdev, pdata);
+
+	return 0;
+}
+
+static void malidp_hw_enable_clocks(struct malidp_hw_device *hwdev)
+{
+	clk_prepare_enable(hwdev->pclk);
+	clk_prepare_enable(hwdev->aclk);
+	clk_prepare_enable(hwdev->mclk);
+	clk_prepare_enable(hwdev->pxclk);
+}
+
+static void malidp_hw_disable_clocks(struct malidp_hw_device *hwdev)
+{
+	clk_disable_unprepare(hwdev->aclk);
+	clk_disable_unprepare(hwdev->pxclk);
+	clk_disable_unprepare(hwdev->mclk);
+	clk_disable_unprepare(hwdev->pclk);
+
+}
+
+/* Must be called with the power_mutex held */
+static enum malidp_op_mode malidp_hw_change_op_mode(struct malidp_hw_device *hwdev,
+		enum malidp_op_mode mode)
+{
+	enum malidp_op_mode old_mode_de;
+
+	BUG_ON(mode == MALIDP_OP_MODE_UNKNOWN);
+
+	/* We're protected by the power mutex, so just read the mode */
+	old_mode_de = malidp_de_get_op_mode(hwdev->de_dev);
+	if (old_mode_de == mode)
+		return old_mode_de;
+
+	old_mode_de = hwdev->dp_api->change_op_mode(hwdev, mode);
+
+	return old_mode_de;
+}
+
+void malidp_hw_cfg_de_disable_mw_flows_atomic(struct malidp_hw_device *hwdev)
+{
+	enum malidp_de_flow_layer_cfg layer_flow;
+	int i;
+
+	for (i = 0; i < hwdev->topology->n_layers; i++) {
+		layer_flow = malidp_de_get_layer_flow(hwdev->de_dev,
+				&hwdev->topology->layers[i]);
+
+		if (layer_flow == MALIDP_DE_LAYER_FLOW_SIMULT_SE0)
+			malidp_de_cfg_layer_flow(hwdev->de_dev,
+					&hwdev->topology->layers[i],
+					MALIDP_DE_LAYER_FLOW_LOCAL);
+	}
+
+	malidp_de_cfg_cmp_flow(hwdev->de_dev, MALIDP_DE_CMP_FLOW_INTERNAL);
+}
+
+static void malidp_hw_update_downscaling_threshold(
+	struct malidp_hw_device *hwdev,
+	struct drm_mode_modeinfo *mode)
+{
+	u32 pxlclk;
+	u32 mclk;
+
+	mclk = clk_get_rate(hwdev->mclk) / 1000;
+	pxlclk = clk_get_rate(hwdev->pxclk) / 1000;
+
+	hwdev->downscaling_threshold =
+			hwdev->dp_api->se_api.calc_downscaling_threshold(mclk,
+					pxlclk, mode);
+}
+
+bool malidp_hw_pxclk_ok(struct malidp_hw_device *dev, long rate)
+{
+	long rounded_rate = clk_round_rate(dev->pxclk, rate);
+	if (abs(rate - rounded_rate) >= 1000)
+		return false;
+
+	return true;
+}
+
+int malidp_hw_modeset(struct malidp_hw_device *dev, struct drm_mode_modeinfo *mode)
+{
+	struct malidp_se_mw_conf mw_conf;
+	enum malidp_op_mode old_mode;
+	unsigned long flags;
+	long rate = mode->clock * 1000;
+	int ret = 0;
+
+	mutex_lock(&dev->power_mutex);
+
+	/* Check if we can achieve the pixel clock before we try */
+	if (!malidp_hw_pxclk_ok(dev, rate)) {
+		dev_err(dev->device, "%s: pxclk rate couldn't be matched\n",
+			__func__);
+		ret = -ERANGE;
+		goto unlock;
+	}
+
+	old_mode = malidp_de_get_op_mode(dev->de_dev);
+	/* Skip the call if the hardware is suspended */
+	if (old_mode == MALIDP_OP_MODE_POWERSAVE) {
+		goto unlock;
+	}
+
+	old_mode = malidp_hw_change_op_mode(dev, MALIDP_OP_MODE_CONFIG);
+
+	clk_set_rate(dev->pxclk, rate);
+	ret = malidp_hw_set_mclk(dev, rate);
+	if (ret < 0)
+		goto exit;
+	dev->clock_ratio = malidp_hw_clock_ratio_get(dev);
+	dev_dbg(dev->device, "%s: New clock ratio: 0x%04x.%04x\n", __func__,
+		(dev->clock_ratio & 0xFFFF0000) >> 16,
+		dev->clock_ratio & 0xFFFF);
+
+	/* Ratio must be >= 1 */
+	if (dev->clock_ratio < (1 << 16)) {
+		dev_dbg(dev->device, "%s: mclk rate must exceed pxclk rate\n",
+			__func__);
+		ret = -ERANGE;
+		goto exit;
+	}
+
+	spin_lock_irqsave(&dev->hw_lock, flags);
+	/*
+	 * Modeset disables all the layers and memory interface in the system
+	 * to avoid displaying an old configuration that doesn't match the same
+	 * resultion.
+	 */
+	mw_conf.mode = MALIDP_SE_MW_DISABLE;
+	malidp_se_cfg_processing(dev->se_dev, &mw_conf, NULL);
+	ret = malidp_de_modeset(dev->de_dev, mode);
+	if (ret == 0)
+		malidp_hw_update_downscaling_threshold(dev, mode);
+	spin_unlock_irqrestore(&dev->hw_lock, flags);
+
+exit:
+	malidp_hw_change_op_mode(dev, old_mode);
+unlock:
+	mutex_unlock(&dev->power_mutex);
+
+	return ret;
+}
+
+int malidp_hw_set_callback(struct malidp_hw_device *dev,
+		const struct malidp_intf_hw_info *hw_intf,
+		void (*callback)(struct device *, void *, struct malidp_hw_event_queue *),
+		void *opaque)
+{
+	unsigned long flags;
+	int ret = 0;
+
+	spin_lock_irqsave(&dev->hw_lock, flags);
+	if (hw_intf->type == MALIDP_HW_INTF_PRIMARY)
+		malidp_de_set_flip_callback(dev->de_dev, callback, opaque);
+	else if (MALIDP_HW_INTF_MEMORY)
+		malidp_se_set_flip_callback(dev->se_dev, callback, opaque);
+	else
+		ret = -EINVAL;
+	spin_unlock_irqrestore(&dev->hw_lock, flags);
+
+	return ret;
+}
+
+inline u32 malidp_hw_get_core_id(struct malidp_hw_device *hwdev)
+{
+	BUG_ON(!hwdev->core_id);
+	return hwdev->core_id;
+}
+
+static inline u32 malidp_hw_identify(struct malidp_hw_device *hwdev)
+{
+	u32 product_id = hwdev->topology->product_id;
+	u32 core_id;
+
+	/*
+	 * If the old register identifies as DP500, then we can be sure that
+	 * the *hardware* is DP500 (this requires that bits [27:24] of register
+	 * MALIDP_REG_DP500_CORE_ID are reserved for all other hardware
+	 * versions).
+	 */
+	core_id = malidp_hw_read(hwdev, MALIDP_REG_DP500_CORE_ID);
+	switch (MALIDP_CORE_ID_PRODUCT_ID(core_id)) {
+	case MALIDP_DP500_PRODUCT_ID:
+		if (product_id == MALIDP_DP500_PRODUCT_ID)
+			return core_id;
+		else
+			goto mismatch;
+	default:
+		if (product_id == MALIDP_DP500_PRODUCT_ID)
+			goto mismatch;
+	}
+
+	/* For all other hardware version, use MALIDP_REG_CORE_ID */
+	core_id = malidp_hw_read(hwdev, MALIDP_REG_CORE_ID);
+	if (MALIDP_CORE_ID_PRODUCT_ID(core_id) == product_id)
+		return core_id;
+
+mismatch:
+	dev_err(hwdev->device, "%s : device-tree expected hwver 0x%X but register suggested 0x%X\n",
+		__func__, product_id, MALIDP_CORE_ID_PRODUCT_ID(core_id));
+
+	return 0;
+}
+
+struct malidp_hw_device *malidp_hw_init(struct platform_device *pdev,
+			       struct malidp_hw_description *hw_desc)
+{
+	struct malidp_hw_device *hwdev = devm_kzalloc(&pdev->dev,
+			sizeof(struct malidp_hw_device),
+			GFP_KERNEL);
+	if (!hwdev)
+		return hwdev;
+
+	spin_lock_init(&hwdev->hw_lock);
+	mutex_init(&hwdev->power_mutex);
+
+	hwdev->device = &pdev->dev;
+	hwdev->pclk = hw_desc->pdata->pclk;
+	hwdev->mclk = hw_desc->pdata->mclk;
+	hwdev->pxclk = hw_desc->pdata->pxclk;
+	hwdev->aclk = hw_desc->pdata->aclk;
+	hwdev->regs = hw_desc->pdata->regs;
+	hwdev->topology = hw_desc->topology;
+	hwdev->partition_type = hw_desc->config->partition_type;
+	hwdev->clock_ratio = 0x10000;
+	hwdev->dp_api = hw_desc->topology->dp_api;
+	hwdev->hw_regmap = hw_desc->topology->regmap;
+
+	/* We need the APB clock for register accesses */
+	clk_prepare_enable(hwdev->pclk);
+
+	hwdev->core_id = malidp_hw_identify(hwdev);
+	if (!hwdev->core_id) {
+		dev_err(hwdev->device, "%s : couldn't determine hardware version\n",
+			__func__);
+		goto fail_clk;
+	}
+	dev_info(hwdev->device, "Probed product ID: 0x%04x",
+		 MALIDP_CORE_ID_PRODUCT_ID(hwdev->core_id));
+	dev_info(hwdev->device, "  Major: %d, minor: %d, status: %d\n",
+		 MALIDP_CORE_ID_MAJOR(hwdev->core_id),
+		 MALIDP_CORE_ID_MINOR(hwdev->core_id),
+		 MALIDP_CORE_ID_STATUS(hwdev->core_id));
+
+	hwdev->ls_info = malidp_hw_get_ls_info(hwdev, hw_desc);
+	if (!hwdev->ls_info) {
+		dev_err(hwdev->device, "%s : couldn't determine linesize config\n",
+			__func__);
+		goto fail_clk;
+	}
+
+	/* Look for rotmem in order of priority: platform then HW config */
+	if (hw_desc->pdata->rotmem_size)
+		hwdev->rotmem_size = hw_desc->pdata->rotmem_size;
+	else
+		hwdev->rotmem_size = hwdev->ls_info->default_rotmem_size;
+
+	hwdev->dp_api->disable_irq(hwdev);
+
+	/* Set up the SE device structure */
+	hwdev->se_dev = malidp_se_hw_init(hwdev, pdev,
+			hw_desc->pdata, &hwdev->hw_lock);
+	if (!hwdev->se_dev)
+		goto fail_clk;
+
+	/* Set up the DE device structure */
+	hwdev->de_dev = malidp_de_hw_init(hwdev, pdev,
+			hw_desc->pdata, &hwdev->hw_lock);
+	if (!hwdev->de_dev)
+		goto fail_clk;
+
+	/* Enter config mode and do configuration reset */
+	malidp_hw_runtime_resume(hwdev);
+
+	/* Enter lowpower mode */
+	malidp_hw_runtime_suspend(hwdev);
+	/*
+	 * Drop our reference on the APB clock.
+	 */
+	clk_disable_unprepare(hwdev->pclk);
+
+	dev_dbg(&pdev->dev, "%s: success\n", __func__);
+
+	return hwdev;
+
+fail_clk:
+	clk_disable_unprepare(hwdev->pclk);
+	return ERR_PTR(-ENODEV);
+}
+
+void malidp_hw_exit(struct malidp_hw_device *hwdev)
+{
+	/* We need the APB clock for register accesses */
+	clk_prepare_enable(hwdev->pclk);
+
+	malidp_hw_change_op_mode(hwdev, MALIDP_OP_MODE_CONFIG);
+
+	hwdev->dp_api->disable_irq(hwdev);
+
+	malidp_se_hw_exit(hwdev->se_dev);
+	malidp_de_hw_exit(hwdev->de_dev);
+
+	malidp_hw_change_op_mode(hwdev, MALIDP_OP_MODE_POWERSAVE);
+
+	clk_disable_unprepare(hwdev->pclk);
+}
+
+u32 malidp_hw_rotmem_size_get(struct malidp_hw_device *hwdev)
+{
+	return hwdev->rotmem_size;
+}
+
+u32 malidp_hw_get_fifo_size(struct malidp_hw_device *hwdev)
+{
+	return hwdev->ls_info->input_fifo_size;
+}
+
+void malidp_hw_supported_dimensions_get(struct malidp_hw_device *hwdev,
+					u32 *min_width, u32 *min_height,
+					u32 *max_width, u32 *max_height)
+{
+	if (min_width)
+		*min_width = hwdev->ls_info->min_line_size;
+	if (min_height)
+		*min_height = hwdev->ls_info->min_line_size;
+	if (max_width)
+		*max_width = hwdev->ls_info->max_line_size;
+	if (max_height)
+		*max_height = hwdev->ls_info->max_line_size;
+}
+
+u32 malidp_hw_clock_ratio_get(struct malidp_hw_device *hwdev)
+{
+	u64 current_mclk;
+	u32 clock_r;
+
+	if (hwdev->mclk == hwdev->pxclk)
+		return 1 << 16;
+
+	current_mclk = clk_get_rate(hwdev->mclk) / 1000;
+	clock_r = clk_get_rate(hwdev->pxclk) / 1000;
+
+	current_mclk <<= 16;
+	do_div(current_mclk, clock_r);
+	clock_r = current_mclk;
+	return clock_r;
+}
+
+int malidp_hw_clock_ratio_set(struct malidp_hw_device *hwdev,
+		u32 new_clock_ratio)
+{
+	unsigned long flags;
+
+	if (new_clock_ratio < 0x10000) {
+		dev_err(hwdev->device, "clock ratio is less than 1.");
+		return -EINVAL;
+	}
+
+	if ((hwdev->mclk == hwdev->pxclk) && new_clock_ratio != 0x10000) {
+		dev_err(hwdev->device, "mclk and pxclk are shared. Ratio must be 1.\n");
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+	hwdev->clock_ratio = new_clock_ratio;
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+	return 0;
+}
+
+int malidp_hw_set_mclk(struct malidp_hw_device *hwdev, u32 pxclk)
+{
+	u32 mclk;
+	u64 tmp64 = pxclk;
+
+	if (pxclk == 0)
+		return -EINVAL;
+
+	if (hwdev->pxclk == hwdev->mclk)
+		return 0;
+
+	tmp64 *= hwdev->clock_ratio;
+	tmp64 >>= 16;
+	mclk = tmp64;
+
+	/*
+	 * This can fail if mclk is fixed, but we will check the actual
+	 * rate later
+	 */
+	clk_set_rate(hwdev->mclk, mclk);
+
+	return 0;
+}
+
+enum malidp_hw_partition_type malidp_hw_rotmem_type_get(struct malidp_hw_device *hwdev)
+{
+	return hwdev->partition_type;
+}
+
+const struct malidp_hw_topology *malidp_hw_get_topology(struct malidp_hw_device *hwdev)
+{
+	return hwdev->topology;
+}
+
+int malidp_hw_get_attr(struct malidp_hw_device *hwdev, u32 attr, u32 *val)
+{
+	int ret;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+
+	switch (attr & (MALIDP_ATTR_FLAG_DE | MALIDP_ATTR_FLAG_SE)) {
+	case MALIDP_ATTR_FLAG_DE:
+		ret = malidp_de_get_attr(hwdev->de_dev, attr, val);
+		break;
+	case MALIDP_ATTR_FLAG_SE:
+		ret = malidp_se_get_attr(hwdev->se_dev, attr, val);
+		break;
+	default:
+		ret = -EINVAL;
+		break;
+	}
+
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+
+	return ret;
+}
+
+static int malidp_hw_save_attr(struct malidp_hw_device *hwdev, u32 attr, u32 val)
+{
+	int ret;
+
+	switch (attr & (MALIDP_ATTR_FLAG_DE | MALIDP_ATTR_FLAG_SE)) {
+	case MALIDP_ATTR_FLAG_DE:
+		ret = malidp_de_save_attr(hwdev->de_dev, attr, val);
+		break;
+	case MALIDP_ATTR_FLAG_SE:
+		ret = malidp_se_save_attr(hwdev->se_dev, attr, val);
+		break;
+	default:
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+int malidp_hw_set_attr(struct malidp_hw_device *hwdev, u32 attr, u32 val)
+{
+	int ret;
+	unsigned long flags;
+	enum malidp_op_mode de_mode;
+
+	mutex_lock(&hwdev->power_mutex);
+	de_mode = malidp_de_get_op_mode(hwdev->de_dev);
+
+	if (de_mode == MALIDP_OP_MODE_POWERSAVE) {
+		/*
+		 * If PM runtime is enabled, we just save the attributes
+		 * to device for PSM, they will be reset when the device
+		 * is resumed.
+		 */
+		ret = malidp_hw_save_attr(hwdev, attr, val);
+		goto exit;
+	}
+
+	if (de_mode == MALIDP_OP_MODE_NORMAL) {
+		if ((attr & MALIDP_ATTR_FLAG_CM)) {
+			dev_err(hwdev->device, "%s: can't set attr %u with display on\n", __func__, attr);
+			ret = -EBUSY;
+			goto exit;
+		}
+		/* If attr doesn't need CFM, then we don't need to change */
+	} else {
+		/*
+		 * We need to make sure we aren't in PSM so we can access
+		 * registers, even if the attr doesn't specifically need CFM.
+		 */
+		malidp_hw_change_op_mode(hwdev, MALIDP_OP_MODE_CONFIG);
+	}
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+
+	switch (attr & (MALIDP_ATTR_FLAG_DE | MALIDP_ATTR_FLAG_SE)) {
+	case MALIDP_ATTR_FLAG_DE:
+		ret = malidp_de_set_attr(hwdev->de_dev, attr, val);
+		break;
+	case MALIDP_ATTR_FLAG_SE:
+		ret = malidp_se_set_attr(hwdev->se_dev, attr, val);
+		break;
+	default:
+		ret = -EINVAL;
+		break;
+	}
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+
+	malidp_hw_change_op_mode(hwdev, de_mode);
+
+exit:
+	mutex_unlock(&hwdev->power_mutex);
+	return ret;
+}
+
+/*
+ * Pass-through the gamma settings to DE dev
+ */
+void malidp_hw_update_gamma_settings(struct malidp_hw_device *hwdev,
+				     bool enable,
+				     u32 *coeffs)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+	malidp_de_update_gamma_settings(hwdev->de_dev, enable, coeffs);
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+}
+
+void malidp_hw_set_de_output_depth(struct malidp_hw_device *hwdev, u8 red,
+		u8 green, u8 blue)
+{
+	unsigned long flags;
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+	malidp_de_store_output_depth(hwdev->de_dev, red, green, blue);
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+}
+
+/*
+ * The xy CIE coordinates should be in 10bits representing values
+ * from 0 to 1023/1024 as reported by the EDID standard.
+ */
+int malidp_hw_update_color_adjustment(struct malidp_hw_device *hwdev,
+	u16 red_x, u16 red_y, u16 green_x, u16 green_y,
+	u16 blue_x, u16 blue_y, u16 white_x, u16 white_y)
+{
+	return malidp_de_update_cadj_coeffs(hwdev->de_dev, red_x, red_y,
+		green_x, green_y, blue_x, blue_y, white_x, white_y);
+}
+
+u32 malidp_hw_downscaling_threshold(struct malidp_hw_device *hwdev)
+{
+	return hwdev->downscaling_threshold;
+}
+
+static int malidp_hw_dbg_dump_clock(struct seq_file *dump_file,
+		void *x)
+{
+	struct malidp_hw_device *hwdev = dump_file->private;
+
+	return seq_printf(dump_file, "mclk=%luHz pxclk=%luHz\n",
+				clk_get_rate(hwdev->mclk),
+				clk_get_rate(hwdev->pxclk));
+}
+
+static int malidp_hw_dbg_open(struct inode *inode, struct file *pfile)
+{
+	return single_open(pfile, malidp_hw_dbg_dump_clock,
+			inode->i_private);
+}
+
+static const struct file_operations f_ops_clock = {
+	.owner = THIS_MODULE,
+	.open = malidp_hw_dbg_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+};
+
+int malidp_hw_debugfs_init(struct malidp_hw_device *hwdev,
+	struct dentry *parent)
+{
+	struct dentry *dbg_file;
+
+	if (hwdev->dbg_folder != NULL)
+		return 0;
+
+	hwdev->dbg_folder = debugfs_create_dir("hardware", parent);
+	if (hwdev->dbg_folder == NULL)
+		return -EINVAL;
+
+	malidp_de_debugfs_init(hwdev->de_dev, hwdev->dbg_folder);
+
+	dbg_file = debugfs_create_file("clock", S_IROTH,
+			hwdev->dbg_folder, hwdev, &f_ops_clock);
+	if (dbg_file == NULL)
+		dev_err(hwdev->device, "debugfs clock is created error!\n");
+
+	dbg_file = debugfs_create_u32("rotmem", S_IRUSR | S_IWUSR,
+			hwdev->dbg_folder, &hwdev->rotmem_size);
+	if (dbg_file == NULL)
+		dev_err(hwdev->device, "couldn't create rotmem debugfs file\n");
+
+	dbg_file = debugfs_create_u32("maxline", S_IRUSR | S_IRGRP | S_IROTH,
+			hwdev->dbg_folder, (u32 *)&hwdev->ls_info->max_line_size);
+	if (dbg_file == NULL)
+		dev_err(hwdev->device, "couldn't create maxline debugfs file\n");
+
+	if (hwdev->dp_api->debugfs_func != NULL)
+		hwdev->dp_api->debugfs_func(hwdev);
+
+	return 0;
+}
+
+struct malidp_hw_event_queue *malidp_hw_event_queue_create(size_t n_events)
+{
+	struct malidp_hw_event_queue *queue;
+	size_t size = sizeof(*queue) +
+		(sizeof(struct malidp_hw_event) * n_events);
+
+	queue = kzalloc(size, GFP_KERNEL);
+	if (!queue)
+		return NULL;
+
+	spin_lock_init(&queue->lock);
+	queue->n_events = n_events;
+	queue->queue = (struct malidp_hw_event *)((char *)queue + sizeof(*queue));
+	queue->head = NULL;
+	queue->tail = queue->queue;
+	return queue;
+}
+
+void malidp_hw_event_queue_destroy(struct malidp_hw_event_queue *queue)
+{
+	kfree(queue);
+}
+
+void malidp_hw_event_queue_enqueue(struct malidp_hw_event_queue *queue,
+		struct malidp_hw_event *event)
+{
+	unsigned long flags;
+	spin_lock_irqsave(&queue->lock, flags);
+
+	*queue->tail = *event;
+
+	/* If the queue gets full, log an error */
+	if (queue->tail == queue->head)
+		(*queue->tail).type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_QFULL;
+
+	if (!queue->head)
+		queue->head = queue->tail;
+
+	queue->tail--;
+	if (queue->tail < queue->queue)
+		queue->tail = &queue->queue[queue->n_events - 1];
+
+	spin_unlock_irqrestore(&queue->lock, flags);
+}
+
+void malidp_hw_event_queue_dequeue(struct malidp_hw_event_queue *queue,
+		struct malidp_hw_event *event)
+{
+	unsigned long flags;
+	spin_lock_irqsave(&queue->lock, flags);
+
+	if (!queue->head) {
+		event->type = MALIDP_HW_EVENT_NONE;
+	} else {
+		*event = *queue->head;
+
+		queue->head--;
+		if (queue->head < queue->queue)
+			queue->head = &queue->queue[queue->n_events - 1];
+
+		/* Are we empty? */
+		if (queue->head == queue->tail)
+			queue->head = NULL;
+	}
+
+	spin_unlock_irqrestore(&queue->lock, flags);
+}
+
+void malidp_hw_disable_all_layers_and_mw(struct malidp_hw_device *hwdev)
+{
+	struct malidp_se_mw_conf mw_conf = {
+		.mode = MALIDP_SE_MW_DISABLE,
+	};
+	unsigned long flags;
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+	malidp_se_cfg_processing(hwdev->se_dev, &mw_conf, NULL);
+	malidp_de_disable_all_layers(hwdev->de_dev);
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+}
+
+attr_visible_t malidp_hw_get_attr_visible_func(struct malidp_hw_device *hwdev)
+{
+	return hwdev->dp_api->attr_visible;
+}
+
+int malidp_hw_runtime_suspend(struct malidp_hw_device *hwdev)
+{
+	mutex_lock(&hwdev->power_mutex);
+	malidp_hw_change_op_mode(hwdev, MALIDP_OP_MODE_POWERSAVE);
+	mutex_unlock(&hwdev->power_mutex);
+
+	malidp_hw_disable_clocks(hwdev);
+	return 0;
+}
+
+int malidp_hw_runtime_resume(struct malidp_hw_device *hwdev)
+{
+	int res;
+
+	malidp_hw_enable_clocks(hwdev);
+
+	mutex_lock(&hwdev->power_mutex);
+	malidp_hw_change_op_mode(hwdev, MALIDP_OP_MODE_CONFIG);
+	mutex_unlock(&hwdev->power_mutex);
+
+	res = hwdev->dp_api->se_api.hw_cfg(hwdev->se_dev);
+	WARN_ON(res != 0);
+
+	res = hwdev->dp_api->de_api.hw_cfg(hwdev->de_dev);
+	WARN_ON(res != 0);
+
+	return 0;
+}
+
+int malidp_hw_display_switch(struct malidp_hw_device *hwdev, bool power_on)
+{
+
+	if (power_on == true) {
+		pm_runtime_get_sync(hwdev->device);
+
+		mutex_lock(&hwdev->power_mutex);
+		malidp_hw_change_op_mode(hwdev, MALIDP_OP_MODE_NORMAL);
+		mutex_unlock(&hwdev->power_mutex);
+	} else {
+		malidp_hw_disable_all_layers_and_mw(hwdev);
+
+		mutex_lock(&hwdev->power_mutex);
+		malidp_hw_change_op_mode(hwdev, MALIDP_OP_MODE_CONFIG);
+		mutex_unlock(&hwdev->power_mutex);
+
+		pm_runtime_put(hwdev->device);
+	}
+
+	return 0;
+}
+
+void malidp_hw_clear_mw(struct malidp_hw_state *hw_state)
+{
+	struct malidp_hw_state_priv *hw_priv = hw_state->hw_priv;
+	int i;
+
+	hw_priv->mw.mode = MALIDP_SE_MW_DISABLE;
+	hw_priv->mw.buf = NULL;
+
+	hw_priv->cmp_flow = MALIDP_DE_CMP_FLOW_INTERNAL;
+
+	for (i = 0; i < MALIDP_MAX_LAYERS; i++) {
+		if (hw_priv->layer_flow[i] == MALIDP_DE_LAYER_FLOW_SIMULT_SE0)
+			hw_priv->layer_flow[i] = MALIDP_DE_LAYER_FLOW_LOCAL;
+	}
+}
diff --git a/drivers/video/adf/arm/malidp_hw.h b/drivers/video/adf/arm/malidp_hw.h
new file mode 100644
index 0000000..6220c6f
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_hw.h
@@ -0,0 +1,315 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_HW_H_
+#define _MALIDP_HW_H_
+
+#include <linux/platform_device.h>
+#include <linux/debugfs.h>
+#include <uapi/drm/drm_mode.h>
+#include "malidp_hw_types.h"
+#include "malidp_sysfs.h"
+
+#define MALIDP_MAX_EVENT_STRING 100
+#define MALIDP_MAX_LAYERS 4
+#define MALIDP_MAX_SMART_LAYERS 4
+
+enum malidp_hw_product {
+	MALI_DP500 = 0,
+	MALI_DP550
+};
+
+enum malidp_op_mode {
+	MALIDP_OP_MODE_NORMAL = 0,
+	MALIDP_OP_MODE_CONFIG,
+	MALIDP_OP_MODE_POWERSAVE,
+	MALIDP_OP_MODE_TEST,
+	/* Must only be used at driver init */
+	MALIDP_OP_MODE_UNKNOWN,
+};
+
+enum malidp_hw_intf_type {
+	MALIDP_HW_INTF_PRIMARY,
+	MALIDP_HW_INTF_MEMORY,
+};
+
+struct malidp_intf_hw_info {
+	char name[MALIDP_NAME_LEN];
+	enum malidp_hw_intf_type type;
+	u32 idx;
+};
+
+enum malidp_hw_layer_type {
+	MALIDP_HW_LAYER_VIDEO,
+	MALIDP_HW_LAYER_GRAPHICS,
+	MALIDP_HW_LAYER_SMART,
+};
+
+struct malidp_layer_hw_info {
+	int index;
+	char name[MALIDP_NAME_LEN];
+	enum malidp_hw_layer_type type;
+	/* Bitwise-OR of MALIDP_LAYER_FEATURE_xxx supported by this layer */
+	u32 features;
+	unsigned int n_supported_formats;
+	int n_max_planes;
+	const u32 *supported_formats;
+	/* The HW id of the format at the same index in the supported_formats list
+	 * Can be null if the index itself should be used (e.g. in DP550)
+	 */
+	const u32 *format_ids;
+	const u32 n_supported_layers;
+	const u32 regs_base;
+	const u32 ad_ctrl_reg;
+	const u32 ad_crop_h_reg;
+	const u32 ad_crop_v_reg;
+	union {
+		struct {
+			const u32 stride_offset;
+			const u32 ptr0_low_offset;
+			const u32 ptr0_high_offset;
+			const u32 p3_stride_offset;
+		};
+
+		struct {
+			const u32 ls_r1_in_size;
+			const u32 ls_r1_offset;
+			const u32 ls_r1_stride;
+			const u32 ls_r1_ptr_low;
+			const u32 ls_r1_ptr_high;
+		};
+	};
+	const u32 yuv2rgb_reg_offset;
+};
+
+struct malidp_hw_regmap;
+struct malidp_product_api;
+
+struct malidp_hw_topology {
+	u32 product_id;
+	const struct malidp_intf_hw_info *interfaces;
+	int n_interfaces;
+	const struct malidp_layer_hw_info *layers;
+	int n_layers;
+	u32 n_scalers;
+	u32 n_supported_afbc_formats;
+	const u32 *supported_afbc_formats;
+	u64 supported_afbc_splitblk;
+	u32 n_mw_formats;
+	const u32 *mw_formats;
+	const u32 *mw_format_ids;
+	u32 n_xform_invalid_formats;
+	const u32 *xform_invalid_formats;
+	const struct malidp_product_api *dp_api;
+	const struct malidp_hw_regmap *regmap;
+};
+
+struct malidp_line_size_hw_info {
+	u32 max_line_size;
+	u32 min_line_size;
+	u32 input_fifo_size;
+	u32 default_rotmem_size;
+};
+
+struct malidp_hw_device {
+	void __iomem *regs;
+	const struct malidp_hw_topology *topology;
+	const struct malidp_line_size_hw_info *ls_info;
+	/*
+	 * Protects access to the HW features, needs to be taken by the DE and
+	 * SE IRQ handlers to avoid races.
+	 */
+	spinlock_t hw_lock;
+	/*
+	 * Must be held when calling malidp_hw_change_op_mode() to
+	 * serialise operating mode changes and ensure the reported operating
+	 * mode is consistent.
+	 */
+	struct mutex power_mutex;
+	struct device *device;
+	struct malidp_de_device *de_dev;
+	struct malidp_se_device *se_dev;
+	struct clk *pxclk, *mclk, *aclk, *pclk;
+	u32 rotmem_size;
+	/* clock_ratio=mclk/pclk, it is fix point data (16.16)*/
+	u32 clock_ratio;
+	/* Threshold for downscaling. Fix point data (16.16) */
+	u32 downscaling_threshold;
+
+	char hw_event_mask[MALIDP_MAX_EVENT_STRING];
+	enum malidp_hw_partition_type partition_type;
+
+	const struct malidp_product_api *dp_api;
+	const struct malidp_hw_regmap *hw_regmap;
+
+	struct dentry *dbg_folder;
+	u32 core_id;
+	/* Only used in debugfs and not available for dp500 */
+	bool cproc_en;
+};
+
+struct malidp_hw_configuration {
+	const struct malidp_line_size_hw_info *ls_configs;
+	int n_configs;
+	enum malidp_hw_partition_type partition_type;
+};
+
+/* Description of the hardware, in order of increasing specificity */
+struct malidp_hw_description {
+	/* Things defined by the HW version */
+	const struct malidp_hw_topology *topology;
+	/* Things defined by this configuration of the HW version */
+	struct malidp_hw_configuration *config;
+	/* Things defined by this platform */
+	struct malidp_hw_pdata *pdata;
+};
+
+struct malidp_hw_smart_layer_state {
+	const struct malidp_layer_hw_info *ls_hw_layer;
+	/* The size of smart layer bounding box */
+	u16 ls_bbox_top;
+	u16 ls_bbox_left;
+	u16 ls_bbox_bottom;
+	u16 ls_bbox_right;
+	/* The smart layer bounding box background color in ARGB8888 format */
+	u32 ls_bbox_argb;
+	/* The number of active smart layers */
+	u8 n_smart_layers;
+	/* The array of indexes of the smart layer HW buffers */
+	u8 ls_hw_buf_idx[MALIDP_MAX_SMART_LAYERS];
+	/* Indicate the bbox is from user space */
+	bool ls_bbox_from_user;
+};
+
+struct malidp_hw_state_priv;
+
+struct malidp_hw_state {
+	u32 n_bufs;
+	struct malidp_hw_buffer *bufs;
+	struct malidp_hw_state_priv *hw_priv;
+	struct malidp_hw_smart_layer_state ls_state;
+};
+
+/*
+ * This function should find out what hardware is available and populate
+ * hw_desc appropriately.
+ *
+ * @hw_desc[out] The hardware description
+ * @product[in] The product code for this device.
+ * @pdata[in] The platform-specific information for this device.
+ */
+void malidp_hw_enumerate(struct malidp_hw_description *hw_desc,
+		enum malidp_hw_product product, struct malidp_hw_pdata *pdata);
+
+int malidp_hw_validate(struct malidp_hw_device *hwdev,
+		struct malidp_hw_state *hw_state);
+
+void malidp_hw_state_free(struct malidp_hw_device *hwdev,
+		struct malidp_hw_state *hw_state);
+
+int malidp_hw_commit(struct malidp_hw_device *hwdev,
+		struct malidp_hw_state *hw_state);
+
+int malidp_hw_set_callback(struct malidp_hw_device *dev,
+		const struct malidp_intf_hw_info *hw_intf,
+		void (*callback)(struct device *, void *, struct malidp_hw_event_queue *),
+		void *opaque);
+
+int malidp_hw_modeset(struct malidp_hw_device *dev, struct drm_mode_modeinfo *mode);
+
+char *malidp_hw_get_event_string(char *string, int max, struct malidp_hw_event *event);
+
+struct malidp_hw_device *malidp_hw_init(struct platform_device *pdev,
+			       struct malidp_hw_description *hw_desc);
+
+void malidp_hw_exit(struct malidp_hw_device *hwdev);
+
+u32 malidp_hw_get_core_id(struct malidp_hw_device *hwdev);
+
+int malidp_hw_get_resources(struct platform_device *pdev,
+			       struct device_node *nproot,
+			       struct malidp_hw_pdata *pdata);
+
+void malidp_hw_update_gamma_settings(struct malidp_hw_device *hwdev,
+				     bool enable,
+				     u32 *coeffs);
+
+bool malidp_hw_format_is_yuv(u32 format);
+bool malidp_hw_format_has_alpha(u32 format);
+u32 malidp_hw_format_bpp(u32 format);
+
+uint32_t malidp_hw_rotmem_size_get(struct malidp_hw_device *hwdev);
+void malidp_hw_supported_dimensions_get(struct malidp_hw_device *hwdev,
+					u32 *min_width, u32 *min_height,
+					u32 *max_width, u32 *max_height);
+enum malidp_hw_partition_type
+		malidp_hw_rotmem_type_get(struct malidp_hw_device *hwdev);
+const struct malidp_hw_topology
+		*malidp_hw_get_topology(struct malidp_hw_device *hwdev);
+u32 malidp_hw_clock_ratio_get(struct malidp_hw_device *hwdev);
+int malidp_hw_clock_ratio_set(struct malidp_hw_device *hwdev,
+		u32 new_clock_ratio);
+u32 malidp_hw_downscaling_threshold(struct malidp_hw_device *hwdev);
+u32 malidp_hw_get_fifo_size(struct malidp_hw_device *hwdev);
+int malidp_hw_set_mclk(struct malidp_hw_device *hwdev, u32 pxclk);
+
+int malidp_hw_get_attr(struct malidp_hw_device *hwdev, u32 attr, u32 *val);
+int malidp_hw_set_attr(struct malidp_hw_device *hwdev, u32 attr, u32 val);
+
+void malidp_hw_set_de_output_depth(struct malidp_hw_device *hwdev, u8 red,
+		u8 green, u8 blue);
+
+int malidp_hw_update_color_adjustment(struct malidp_hw_device *hwdev,
+	u16 red_x, u16 red_y, u16 green_x, u16 green_y, u16 blue_x, u16 blue_y,
+	u16 white_x, u16 white_y);
+
+int malidp_hw_debugfs_init(struct malidp_hw_device *hwdev,
+	struct dentry *parent);
+
+struct malidp_hw_event_queue *malidp_hw_event_queue_create(size_t n_events);
+void malidp_hw_event_queue_destroy(struct malidp_hw_event_queue *queue);
+void malidp_hw_event_queue_enqueue(struct malidp_hw_event_queue *queue,
+		struct malidp_hw_event *event);
+void malidp_hw_event_queue_dequeue(struct malidp_hw_event_queue *queue,
+		struct malidp_hw_event *event);
+
+void malidp_hw_disable_all_layers_and_mw(struct malidp_hw_device *hwdev);
+void malidp_hw_clear_mw(struct malidp_hw_state *hw_state);
+
+u32 malidp_hw_read(struct malidp_hw_device *hwdev, u32 reg);
+void malidp_hw_write(struct malidp_hw_device *hwdev, u32 value, u32 reg);
+void malidp_hw_setbits(struct malidp_hw_device *dev, u32 mask,
+			u32 reg);
+void malidp_hw_clearbits(struct malidp_hw_device *dev, u32 mask,
+			u32 reg);
+bool malidp_hw_buf_support_srgb(struct malidp_hw_buffer *hw_buf);
+bool malidp_hw_pxclk_ok(struct malidp_hw_device *dev, long rate);
+attr_visible_t malidp_hw_get_attr_visible_func(struct malidp_hw_device *hwdev);
+
+int malidp_hw_runtime_resume(struct malidp_hw_device *hwdev);
+int malidp_hw_runtime_suspend(struct malidp_hw_device *hwdev);
+int malidp_hw_display_switch(struct malidp_hw_device *hwdev, bool power_on);
+/*
+ * To be used only by the DE/SE HW code. As indicated by the "atomic" suffix
+ * these calls are not thread safe, hence they need to be called with the
+ * HW spinlock taken.
+ *
+ */
+void malidp_hw_commit_scene_atomic(struct malidp_hw_device *hwdev, bool set);
+void malidp_hw_cfg_de_disable_mw_flows_atomic(struct malidp_hw_device *hwdev);
+
+#endif /* _MALIDP_HW_H_ */
diff --git a/drivers/video/adf/arm/malidp_hw_types.h b/drivers/video/adf/arm/malidp_hw_types.h
new file mode 100644
index 0000000..ba7262a
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_hw_types.h
@@ -0,0 +1,171 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_HW_TYPES_H_
+#define _MALIDP_HW_TYPES_H_
+
+#include <linux/ktime.h>
+#include <linux/ioport.h>
+
+#define MALIDP_NAME_LEN 30
+
+
+#define MALIDP_HW_EVENT_NONE	0
+#define MALIDP_HW_EVENT_FLIP	(1 << 0)
+#define MALIDP_HW_EVENT_ERROR	(1 << 1)
+#define		MALIDP_HW_ERROR_URUN	(1 << 6)
+#define		MALIDP_HW_ERROR_ORUN	(1 << 7)
+#define		MALIDP_HW_ERROR_AXI	(1 << 8)
+#define		MALIDP_HW_ERROR_QFULL	(1 << 9)
+#define		MALIDP_HW_ERROR_IBUSY	(1 << 10)
+#define MALIDP_HW_EVENT_VSYNC	(1 << 2)
+#define MALIDP_HW_EVENT_START	(1 << 3)
+#define MALIDP_HW_EVENT_NEWCFG	(1 << 4)
+#define MALIDP_HW_EVENT_STOP	(1 << 5)
+
+/* Attributes which are exposed via sysfs */
+#define MALIDP_ATTR_FLAG_CM	(1 << 0)
+#define MALIDP_ATTR_FLAG_DE	(1 << 1)
+#define MALIDP_ATTR_FLAG_SE	(1 << 2)
+#define MALIDP_ATTR_BURSTLEN	((1 << 3) | MALIDP_ATTR_FLAG_CM)
+#define MALIDP_ATTR_OUTSTRAN	((2 << 3) | MALIDP_ATTR_FLAG_CM)
+#define MALIDP_ATTR_CACHE	((3 << 3) | MALIDP_ATTR_FLAG_CM)
+#define MALIDP_ATTR_QOS		((4 << 3) | MALIDP_ATTR_FLAG_CM)
+#define MALIDP_ATTR_RQOS_LOW	(5 << 3)
+#define MALIDP_ATTR_RQOS_HIGH	(6 << 3)
+#define MALIDP_ATTR_RQOS_RED	(7 << 3)
+#define MALIDP_ATTR_RQOS_GREEN	(8 << 3)
+#define MALIDP_ATTR_FIFO_SIZE	(9 << 3)
+#define MALIDP_ATTR_POUTSTDCAB  ((10 << 3) | MALIDP_ATTR_FLAG_CM)
+#define MALIDP_ATTR_DE_BURSTLEN	(MALIDP_ATTR_BURSTLEN | MALIDP_ATTR_FLAG_DE)
+#define MALIDP_ATTR_DE_POUTSTDCAB (MALIDP_ATTR_POUTSTDCAB | MALIDP_ATTR_FLAG_DE)
+#define MALIDP_ATTR_DE_OUTSTRAN	(MALIDP_ATTR_OUTSTRAN | MALIDP_ATTR_FLAG_DE)
+#define MALIDP_ATTR_DE_RQOS_LOW	(MALIDP_ATTR_RQOS_LOW | MALIDP_ATTR_FLAG_DE)
+#define MALIDP_ATTR_DE_RQOS_HIGH (MALIDP_ATTR_RQOS_HIGH | MALIDP_ATTR_FLAG_DE)
+#define MALIDP_ATTR_DE_RQOS_RED	(MALIDP_ATTR_RQOS_RED | MALIDP_ATTR_FLAG_DE)
+#define MALIDP_ATTR_DE_RQOS_GREEN (MALIDP_ATTR_RQOS_GREEN | MALIDP_ATTR_FLAG_DE)
+#define MALIDP_ATTR_DE_FIFO_SIZE (MALIDP_ATTR_FIFO_SIZE | MALIDP_ATTR_FLAG_DE)
+#define MALIDP_ATTR_SE_BURSTLEN	(MALIDP_ATTR_BURSTLEN | MALIDP_ATTR_FLAG_SE)
+#define MALIDP_ATTR_SE_OUTSTRAN	(MALIDP_ATTR_OUTSTRAN | MALIDP_ATTR_FLAG_SE)
+#define MALIDP_ATTR_SE_WQOS	(MALIDP_ATTR_QOS | MALIDP_ATTR_FLAG_SE)
+#define MALIDP_ATTR_SE_WCACHE	(MALIDP_ATTR_CACHE | MALIDP_ATTR_FLAG_SE)
+
+enum malidp_hw_partition_type {
+	MALIDP_HW_PARTITION_FIXED,
+};
+
+struct malidp_hw_event {
+	u32 type;
+	ktime_t timestamp;
+};
+
+struct malidp_hw_event_queue;
+
+struct malidp_hw_scale_rect {
+	u16 src_w, src_h;
+	u16 dest_w, dest_h;
+};
+
+/** struct malidp_hw_buffer - HW specific buffer structure
+  *
+  * The following parameters allow to specify source cropping
+  * when the target is the Display Engine. For the Scaling Engine
+  * only "w" and "h" are used as the output size for the memory
+  * write-out interface:
+  * @natural_w:	active width of the buffer in pixels, as it is in memory
+  * @natural_h:	active height of the buffer in pixels, as it is in memory
+  * @h_offset:	horizontal offset of the buffer in pixels
+  * @v_offset:	vertical offset of the buffer in pixels
+  *
+  * @fmt:	fourcc pixel format of the buffer
+  * @hw_fmt:	hardware-specific pixel format of the buffer
+  * @addr[3]:	DMA enabled address for each plane in the buffer
+  * @pitch[3]:	stride of the DMA transfer in bytes for every plane
+  * @n_planes:	number of planes used for this buffer
+  * @flags:	malidp specific flags
+  * @mw_scaling_enable: this buffer will be scaled, and the scaling result
+  * will be used in memory write-out.
+  * @mw_rect:	source and destination sizes for memory-write buffer
+  * @cmp_scaling_enable: this buffer will be scaled, and the scaling result
+  * will be used in the composition.
+  * @cmp_rect:	source and destination sizes for composition, after any
+  * rotation has been applied. For an output buffer, src and dest must be the
+  * same, which will also match the "natural" dimensions.
+  * @write_out_enable:	this buffer will be written-out to memory,
+  * if all the DE (input) buffers have this set and the output buffer too
+  * this means we want to write-out the result of the composition.
+  *
+  * The following parameters are specific to the DE only:
+  * @alpha_mode: MALIDP_ALPHA_MODE_xxx flags to set the kind of blending
+  * @layer_alpha: this is the alpha value that will be used if layer level
+  * blending is selected.
+  * @afbc_crop_l: left AFBC cropping.
+  * @afbc_crop_r: right AFBC cropping.
+  * @afbc_crop_t: top AFBC cropping.
+  * @afbc_crop_b: bottom AFBC cropping.
+  * @ls_rect_idx: smart layer rectangle register index.
+  * @hw_layer: HW specific layer information that provides information on
+  * what DE layer this buffer is aiming for. This will be NULL for buffers
+  * aiming the SE write-out interface.
+  * @requirements: the hardware features required for this buffer
+  * Bitwise OR of MALIDP_LAYER_FEATURE_xxx
+  */
+struct malidp_hw_buffer {
+	u16 natural_w, natural_h;
+	u16 h_offset, v_offset;
+	u32 fmt;
+	u32 hw_fmt;
+	dma_addr_t addr[3];
+	u32 pitch[3];
+	u32 n_planes;
+	u32 flags;
+	u32 transform;
+	bool mw_scaling_enable;
+	struct malidp_hw_scale_rect mw_rect;
+	bool cmp_scaling_enable;
+	struct malidp_hw_scale_rect cmp_rect;
+	/* DE specific */
+	bool write_out_enable;
+	u32 alpha_mode;
+	u8 layer_alpha;
+	u16 afbc_crop_l, afbc_crop_r;
+	u16 afbc_crop_t, afbc_crop_b;
+	u8 ls_rect_idx;
+	const struct malidp_layer_hw_info *hw_layer;
+	u32 requirements;
+};
+
+struct malidp_hw_pdata {
+	void __iomem *regs;
+	int se_irq, de_irq;
+	struct clk *pxclk, *mclk, *aclk, *pclk;
+	u32 de_axi_burstlen;
+	u32 de_axi_poutstdcab;
+	u32 de_axi_outstran;
+	u32 de_axi_arqos_low;
+	u32 de_axi_arqos_high;
+	u32 de_axi_arqos_red;
+	u32 de_axi_arqos_green;
+	u32 se_axi_burstlen;
+	u32 se_axi_outstran;
+	u32 se_axi_awcache;
+	u32 se_axi_awqos;
+	u32 rotmem_size;
+	u32 dp_id;
+};
+
+#endif /* _MALIDP_HW_TYPES_H_ */
diff --git a/drivers/video/adf/arm/malidp_iommu.c b/drivers/video/adf/arm/malidp_iommu.c
new file mode 100644
index 0000000..452f9ff
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_iommu.c
@@ -0,0 +1,451 @@
+/*
+ *
+ * (C) COPYRIGHT 2014-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/device.h>
+#include <linux/iommu.h>
+#include <linux/list.h>
+#include <linux/slab.h>
+#include <linux/types.h>
+#include <linux/dma-mapping.h>
+
+#include "malidp_iommu.h"
+
+#define MALIDP_DEV_ADDR_START   0x20000000 /* Start address of the VA space */
+#define MALIDP_DEV_ADDR_SIZE    0x40000000 /* Size of the addres space */
+#define MALIDP_DEV_ADDR_ORDER   0x0        /* Order of the VA allocations */
+
+struct malidp_iommu_domain {
+	struct iommu_domain *domain;
+	struct device *dev;
+	void *bitmap;
+	size_t bits;
+	unsigned int order;
+	dma_addr_t base;
+	spinlock_t lock;
+};
+
+struct malidp_iommu_mapping {
+	struct sg_table *sgt;
+	enum dma_data_direction dir;
+};
+
+#ifdef CONFIG_IOMMU_API
+
+static void dump_sg_table(struct device *dev, struct sg_table *sgt)
+{
+	struct scatterlist *aux_sgl;
+	int i;
+
+	dev_dbg(dev, "sgt = %p:\n", sgt);
+	dev_dbg(dev, "\t sgl = %p\n", sgt->sgl);
+	dev_dbg(dev, "\t nents = %d\n", sgt->nents);
+	dev_dbg(dev, "\t orig_nents = %d\n", sgt->orig_nents);
+	for_each_sg(sgt->sgl, aux_sgl, sgt->nents, i) {
+		dev_dbg(dev, "\t sgl(%d) = %p\n", i, aux_sgl);
+		dev_dbg(dev, "\t\t dma_addr = 0x%llx\n",
+			(unsigned long long)sg_dma_address(aux_sgl));
+		dev_dbg(dev, "\t\t virt_addr = %p\n", sg_virt(aux_sgl));
+		dev_dbg(dev, "\t\t phys_addr = 0x%llx\n",
+			(unsigned long long)sg_phys(aux_sgl));
+		dev_dbg(dev, "\t\t len = %u\n", aux_sgl->length);
+	}
+}
+
+/*
+ * Code taken from arch/arm/mm/dma-mapping.c to handle iova allocations.
+ *
+ * It has been slightly simplified:
+ * - Do not support an extra MMU alignment (CONFIG_ARM_DMA_IOMMU_ALIGNMENT)
+ * - Do not perform any cache maintenance (should already be done by the
+ * exporter of the memory).
+ * - Do not impose a maximum size to each sgl entry in an sgt.
+ */
+static inline dma_addr_t __alloc_iova(struct malidp_iommu_domain *dp_domain,
+				      size_t size)
+{
+	unsigned int align = 0;
+	unsigned int count, start;
+	unsigned long flags;
+
+	count = ((PAGE_ALIGN(size) >> PAGE_SHIFT) +
+		 (1 << dp_domain->order) - 1) >> dp_domain->order;
+
+	spin_lock_irqsave(&dp_domain->lock, flags);
+	start = bitmap_find_next_zero_area(dp_domain->bitmap, dp_domain->bits, 0,
+					   count, align);
+	if (start > dp_domain->bits) {
+		spin_unlock_irqrestore(&dp_domain->lock, flags);
+		return DMA_ERROR_CODE;
+	}
+
+	bitmap_set(dp_domain->bitmap, start, count);
+	spin_unlock_irqrestore(&dp_domain->lock, flags);
+
+	return dp_domain->base + (start << (dp_domain->order + PAGE_SHIFT));
+}
+
+static inline void __free_iova(struct malidp_iommu_domain *dp_domain,
+			       dma_addr_t addr, size_t size)
+{
+	unsigned int start = (addr - dp_domain->base) >>
+			     (dp_domain->order + PAGE_SHIFT);
+	unsigned int count = ((size >> PAGE_SHIFT) +
+			      (1 << dp_domain->order) - 1) >> dp_domain->order;
+	unsigned long flags;
+
+	spin_lock_irqsave(&dp_domain->lock, flags);
+	bitmap_clear(dp_domain->bitmap, start, count);
+	spin_unlock_irqrestore(&dp_domain->lock, flags);
+}
+
+static int __map_sg_chunk(struct malidp_iommu_domain *dp_domain, struct scatterlist *sg,
+			  size_t size, dma_addr_t *handle,
+			  enum dma_data_direction dir, struct dma_attrs *attrs)
+{
+	dma_addr_t iova, iova_base;
+	int ret = 0;
+	unsigned int count;
+	struct scatterlist *s;
+
+	size = PAGE_ALIGN(size);
+	*handle = DMA_ERROR_CODE;
+
+	iova_base = iova = __alloc_iova(dp_domain, size);
+	if (iova == DMA_ERROR_CODE)
+		return -ENOMEM;
+
+	for (count = 0, s = sg; count < (size >> PAGE_SHIFT); s = sg_next(s)) {
+		phys_addr_t phys = page_to_phys(sg_page(s));
+		unsigned int len = PAGE_ALIGN(s->offset + s->length);
+		int prot = 0;
+
+		dev_dbg(dp_domain->dev,
+			"%s: s->offset = %u, s->length = %u, len = %u\n",
+		       __func__, s->offset, s->length, len);
+
+		if (dir == DMA_BIDIRECTIONAL)
+			prot = IOMMU_READ | IOMMU_WRITE;
+		else if (dir == DMA_TO_DEVICE)
+			prot = IOMMU_READ;
+		else if (dir == DMA_FROM_DEVICE)
+			prot = IOMMU_WRITE;
+
+		ret = iommu_map(dp_domain->domain, iova, phys, len, prot);
+		if (ret < 0)
+			goto fail;
+		count += len >> PAGE_SHIFT;
+		iova += len;
+	}
+	*handle = iova_base;
+
+	return 0;
+fail:
+	__free_iova(dp_domain, iova_base, size);
+	return ret;
+}
+
+static int __iommu_remove_mapping(struct malidp_iommu_domain *dp_domain,
+				  dma_addr_t iova, size_t size)
+{
+	/*
+	 * add optional in-page offset from iova to size and align
+	 * result to page size
+	 */
+	size = PAGE_ALIGN((iova & ~PAGE_MASK) + size);
+	iova &= PAGE_MASK;
+
+	iommu_unmap(dp_domain->domain, iova, size);
+	__free_iova(dp_domain, iova, size);
+	return 0;
+}
+
+static int iommu_map_sg(struct malidp_iommu_domain *dp_domain,
+		     struct scatterlist *sg, int nents,
+		     enum dma_data_direction dir, struct dma_attrs *attrs)
+{
+	struct scatterlist *s = sg, *dma = sg, *start = sg;
+	int i, count = 0;
+	unsigned int offset = s->offset;
+	unsigned int size = s->offset + s->length;
+
+	dev_dbg(dp_domain->dev,
+		"%s: s->offset = %u, s->length = %u, size = %u\n",
+	       __func__, s->offset, s->length, size);
+
+	for (i = 1; i < nents; i++) {
+		s = sg_next(s);
+
+		s->dma_address = DMA_ERROR_CODE;
+		s->dma_length = 0;
+
+		if (s->offset || (size & ~PAGE_MASK)) {
+			if (__map_sg_chunk(dp_domain, start, size, &dma->dma_address,
+			    dir, attrs) < 0)
+				goto bad_mapping;
+
+			dma->dma_address += offset;
+			dma->dma_length = size - offset;
+
+			size = offset = s->offset;
+			start = s;
+			dma = sg_next(dma);
+			count += 1;
+		}
+		size += s->length;
+	}
+	if (__map_sg_chunk(dp_domain, start, size, &dma->dma_address, dir, attrs) < 0)
+		goto bad_mapping;
+
+	dma->dma_address += offset;
+	dma->dma_length = size - offset;
+
+	return count+1;
+
+bad_mapping:
+	for_each_sg(sg, s, count, i)
+		__iommu_remove_mapping(dp_domain, sg_dma_address(s), sg_dma_len(s));
+	return 0;
+}
+
+static void iommu_unmap_sg(struct malidp_iommu_domain *dp_domain,
+			   struct scatterlist *sg, int nents,
+			   enum dma_data_direction dir,
+			   struct dma_attrs *attrs)
+{
+	struct scatterlist *s;
+	int i;
+
+	dev_dbg(dp_domain->dev,
+		"%s: sg->offset = %u, sg->length = %u\n",
+	       __func__, sg->offset, sg->length);
+
+	for_each_sg(sg, s, nents, i) {
+		if (sg_dma_len(s))
+			__iommu_remove_mapping(dp_domain, sg_dma_address(s),
+					       sg_dma_len(s));
+	}
+}
+/* End of code from arch/arm/mm/dma-mapping.c*/
+
+static struct sg_table *clone_sgt(struct sg_table *sgt_src)
+{
+	struct sg_table *sgt = NULL;
+	struct scatterlist *s, *s_out;
+	unsigned int i;
+	int ret;
+
+	sgt = kzalloc(sizeof(*sgt), GFP_KERNEL);
+	if (!sgt)
+		return NULL;
+
+	ret = sg_alloc_table(sgt, sgt_src->orig_nents, GFP_KERNEL);
+	if (ret < 0 || !sgt) {
+		kfree(sgt);
+		return NULL;
+	}
+
+	s_out = sgt->sgl;
+	for_each_sg(sgt_src->sgl, s, sgt_src->orig_nents, i) {
+		sg_set_page(s_out, sg_page(s), s->length, s->offset);
+		s_out = sg_next(s_out);
+	}
+
+	return sgt;
+}
+
+static void destroy_sgt(struct sg_table *sgt)
+{
+	sg_free_table(sgt);
+	kfree(sgt);
+}
+
+struct malidp_iommu_mapping *malidp_iommu_map_sgt(struct malidp_iommu_domain *dp_domain,
+			   struct sg_table *sgt,
+			   enum dma_data_direction dir)
+{
+	struct malidp_iommu_mapping *map;
+	int ret;
+
+	map = kzalloc(sizeof(struct malidp_iommu_mapping), GFP_KERNEL);
+	if (!map)
+		return NULL;
+
+	map->sgt = clone_sgt(sgt);
+	if (!map->sgt)
+		goto err_clone;
+
+	map->dir = dir;
+
+	dump_sg_table(dp_domain->dev, map->sgt);
+
+	ret = iommu_map_sg(dp_domain, map->sgt->sgl, map->sgt->nents,
+			       dir, NULL);
+	dump_sg_table(dp_domain->dev, map->sgt);
+	if (ret != 1) {
+		/*
+		 * If ret > 1 it means that we couldn't find contiguous VA
+		 * space to fit the whole buffer. Since Mali DP don't have
+		 * scatter gather DMA this cannot be handled by the HW.
+		 */
+		dev_err(dp_domain->dev, "could only map SG table as %d entries\n",
+			ret);
+		goto err_map_sg;
+	}
+
+	return map;
+
+err_map_sg:
+	destroy_sgt(map->sgt);
+err_clone:
+	kfree(map);
+	return NULL;
+}
+
+void malidp_iommu_unmap_sgt(struct malidp_iommu_domain *dp_domain,
+			    struct malidp_iommu_mapping *map)
+{
+	if (!map)
+		return;
+
+	dev_dbg(dp_domain->dev, "%s: sgt = %p\n", __func__, map->sgt);
+
+	iommu_unmap_sg(dp_domain, map->sgt->sgl, map->sgt->nents,
+				       map->dir, NULL);
+	destroy_sgt(map->sgt);
+	kfree(map);
+}
+
+dma_addr_t malidp_iommu_dma_addr(struct malidp_iommu_domain *dp_domain,
+				 struct malidp_iommu_mapping *map)
+{
+	return sg_dma_address(map->sgt->sgl);
+}
+
+static int malidp_iommu_fault_handler(struct iommu_domain *domain,
+		struct device *dev, unsigned long iova, int flags, void *data)
+{
+	struct device *dpdev = data;
+
+	dev_err_ratelimited(dpdev, "iommu fault in %s access (iova = 0x%lx)\n",
+			    (flags & IOMMU_FAULT_WRITE) ? "write" : "read",
+			    iova);
+
+	/*
+	 * We cannot really do anything if we get a page fault. The memory
+	 * should have been already mapped.
+	 */
+	return -EFAULT;
+}
+
+struct malidp_iommu_domain *malidp_iommu_init(struct device *dev,
+				       struct bus_type *bus)
+{
+	unsigned int count = MALIDP_DEV_ADDR_SIZE >> (PAGE_SHIFT + MALIDP_DEV_ADDR_ORDER);
+	unsigned int bitmap_size = BITS_TO_LONGS(count) * sizeof(long);
+	struct malidp_iommu_domain *dp_domain;
+	int ret;
+
+	dp_domain = kzalloc(sizeof(struct malidp_iommu_domain), GFP_KERNEL);
+	if (!dp_domain) {
+		dev_err(dev, "could not alloc malidp iommu domain\n");
+		return NULL;
+	}
+
+	dp_domain->domain = iommu_domain_alloc(bus);
+	if (!dp_domain->domain) {
+		dev_dbg(dev, "could not alloc iommu domain\n");
+		goto err_alloc;
+	}
+
+	ret = iommu_attach_device(dp_domain->domain, dev);
+	if (ret < 0) {
+		dev_dbg(dev, "could not attach device to domain %p\n",
+			dp_domain->domain);
+		goto err_attach;
+	}
+
+	iommu_set_fault_handler(dp_domain->domain, malidp_iommu_fault_handler,
+				dev);
+
+	dp_domain->dev = dev;
+	dp_domain->order = MALIDP_DEV_ADDR_ORDER;
+	dp_domain->base = MALIDP_DEV_ADDR_START;
+	spin_lock_init(&dp_domain->lock);
+
+	dp_domain->bits = BITS_PER_BYTE * bitmap_size;
+
+	dp_domain->bitmap = kzalloc(bitmap_size, GFP_KERNEL);
+	if (!dp_domain->bitmap) {
+		dev_err(dev, "could not alloc iommu bitmap\n");
+		goto err_bitmap;
+	}
+
+	dev_info(dev, "attached to iommu domain %p", dp_domain->domain);
+
+	return dp_domain;
+
+err_bitmap:
+	iommu_detach_device(dp_domain->domain, dp_domain->dev);
+err_attach:
+	iommu_domain_free(dp_domain->domain);
+err_alloc:
+	kfree(dp_domain);
+
+	return NULL;
+}
+
+void malidp_iommu_exit(struct malidp_iommu_domain *dp_domain)
+{
+	iommu_detach_device(dp_domain->domain, dp_domain->dev);
+	iommu_domain_free(dp_domain->domain);
+	kfree(dp_domain);
+}
+
+#else /* CONFIG_IOMMU_API=n */
+
+struct malidp_iommu_mapping *malidp_iommu_map_sgt(struct malidp_iommu_domain *dp_domain,
+			   struct sg_table *sgt,
+			   enum dma_data_direction dir)
+{
+	return NULL;
+}
+
+void malidp_iommu_unmap_sgt(struct malidp_iommu_domain *dp_domain,
+			    struct malidp_iommu_mapping *map)
+{
+	return;
+}
+
+dma_addr_t malidp_iommu_dma_addr(struct malidp_iommu_domain *dp_domain,
+				 struct malidp_iommu_mapping *map)
+{
+	return 0;
+}
+
+struct malidp_iommu_domain *malidp_iommu_init(struct device *dev,
+				       struct bus_type *bus)
+{
+	return NULL;
+}
+
+void malidp_iommu_exit(struct malidp_iommu_domain *dp_domain)
+{
+	return;
+}
+
+#endif /* CONFIG_IOMMU_API */
+
diff --git a/drivers/video/adf/arm/malidp_iommu.h b/drivers/video/adf/arm/malidp_iommu.h
new file mode 100644
index 0000000..10d76c1
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_iommu.h
@@ -0,0 +1,41 @@
+/*
+ *
+ * (C) COPYRIGHT 2014 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef __MALIDP_IOMMU_H__
+#define __MALIDP_IOMMU_H__
+
+#include <linux/iommu.h>
+
+struct malidp_iommu_domain;
+struct malidp_iommu_mapping;
+
+struct malidp_iommu_mapping *malidp_iommu_map_sgt(struct malidp_iommu_domain *dp_domain,
+			   struct sg_table *sgt,
+			   enum dma_data_direction dir);
+
+void malidp_iommu_unmap_sgt(struct malidp_iommu_domain *dp_domain,
+			    struct malidp_iommu_mapping *map);
+
+dma_addr_t malidp_iommu_dma_addr(struct malidp_iommu_domain *dp_domain,
+				 struct malidp_iommu_mapping *map);
+
+struct malidp_iommu_domain *malidp_iommu_init(struct device *dev,
+				       struct bus_type *bus);
+
+void malidp_iommu_exit(struct malidp_iommu_domain *dp_domain);
+
+#endif /* __MALIDP_IOMMU_H__ */
diff --git a/drivers/video/adf/arm/malidp_of_graph.c b/drivers/video/adf/arm/malidp_of_graph.c
new file mode 100644
index 0000000..e2fc0f8
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_of_graph.c
@@ -0,0 +1,130 @@
+/*
+ * (C) COPYRIGHT 2014 ARM Limited. All rights reserved.
+ * 
+ * Copy of of_graph.h function implementations from drivers/of/base.c,
+ * from Linux 3.15.
+ *
+ * Paul Mackerras	August 1996.
+ * Copyright (C) 1996-2005 Paul Mackerras.
+ *
+ *  Adapted for 64bit PowerPC by Dave Engebretsen and Peter Bergner.
+ *    {engebret|bergner}@us.ibm.com
+ *
+ *  Adapted for sparc and sparc64 by David S. Miller davem@davemloft.net
+ *
+ *  Reconsolidated from arch/x/kernel/prom.c by Stephen Rothwell and
+ *  Grant Likely.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ */
+#include <linux/of.h>
+
+#include "malidp_of_graph.h"
+
+/**
+ * of_graph_get_next_endpoint() - get next endpoint node
+ * @parent: pointer to the parent device node
+ * @prev: previous endpoint node, or NULL to get first
+ *
+ * Return: An 'endpoint' node pointer with refcount incremented. Refcount
+ * of the passed @prev node is not decremented, the caller have to use
+ * of_node_put() on it when done.
+ */
+struct device_node *of_graph_get_next_endpoint(const struct device_node *parent,
+					struct device_node *prev)
+{
+	struct device_node *endpoint;
+	struct device_node *port;
+
+	if (!parent)
+		return NULL;
+
+	/*
+	 * Start by locating the port node. If no previous endpoint is specified
+	 * search for the first port node, otherwise get the previous endpoint
+	 * parent port node.
+	 */
+	if (!prev) {
+		struct device_node *node;
+
+		node = of_get_child_by_name(parent, "ports");
+		if (node)
+			parent = node;
+
+		port = of_get_child_by_name(parent, "port");
+		of_node_put(node);
+
+		if (!port) {
+			pr_err("%s(): no port node found in %s\n",
+			       __func__, parent->full_name);
+			return NULL;
+		}
+	} else {
+		port = of_get_parent(prev);
+		if (WARN_ONCE(!port, "%s(): endpoint %s has no parent node\n",
+			      __func__, prev->full_name))
+			return NULL;
+
+		/*
+		 * Avoid dropping prev node refcount to 0 when getting the next
+		 * child below.
+		 */
+		of_node_get(prev);
+	}
+
+	while (1) {
+		/*
+		 * Now that we have a port node, get the next endpoint by
+		 * getting the next child. If the previous endpoint is NULL this
+		 * will return the first child.
+		 */
+		endpoint = of_get_next_child(port, prev);
+		if (endpoint) {
+			of_node_put(port);
+			return endpoint;
+		}
+
+		/* No more endpoints under this port, try the next one. */
+		prev = NULL;
+
+		do {
+			port = of_get_next_child(parent, port);
+			if (!port)
+				return NULL;
+		} while (of_node_cmp(port->name, "port"));
+	}
+}
+EXPORT_SYMBOL(of_graph_get_next_endpoint);
+
+/**
+ * of_graph_get_remote_port_parent() - get remote port's parent node
+ * @node: pointer to a local endpoint device_node
+ *
+ * Return: Remote device node associated with remote endpoint node linked
+ *	   to @node. Use of_node_put() on it when done.
+ */
+struct device_node *of_graph_get_remote_port_parent(
+			       const struct device_node *node)
+{
+	struct device_node *np;
+	unsigned int depth;
+
+	/* Get remote endpoint node. */
+	np = of_parse_phandle(node, "remote-endpoint", 0);
+
+	/* Walk 3 levels up only if there is 'ports' node. */
+	for (depth = 3; depth && np; depth--) {
+		np = of_get_next_parent(np);
+		if (depth == 2 && of_node_cmp(np->name, "ports"))
+			break;
+	}
+	return np;
+}
+EXPORT_SYMBOL(of_graph_get_remote_port_parent);
diff --git a/drivers/video/adf/arm/malidp_of_graph.h b/drivers/video/adf/arm/malidp_of_graph.h
new file mode 100644
index 0000000..d13c14c
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_of_graph.h
@@ -0,0 +1,48 @@
+/*
+ * OF graph binding parsing helpers
+ *
+ * (C) COPYRIGHT 2014 ARM Limited. All rights reserved.
+ *
+ * Copyright (C) 2012 - 2013 Samsung Electronics Co., Ltd.
+ * Author: Sylwester Nawrocki <s.nawrocki@samsung.com>
+ *
+ * Copyright (C) 2012 Renesas Electronics Corp.
+ * Author: Guennadi Liakhovetski <g.liakhovetski@gmx.de>
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ * This is a partial direct copy of include/linux/of_graph.h from Linux 3.15
+ */
+#ifndef __LINUX_OF_GRAPH_H
+#define __LINUX_OF_GRAPH_H
+
+#ifdef CONFIG_OF
+struct device_node *of_graph_get_next_endpoint(const struct device_node *parent,
+					struct device_node *previous);
+struct device_node *of_graph_get_remote_port_parent(
+					const struct device_node *node);
+#else
+
+static inline struct device_node *of_graph_get_next_endpoint(
+					const struct device_node *parent,
+					struct device_node *previous)
+{
+	return NULL;
+}
+
+static inline struct device_node *of_graph_get_remote_port_parent(
+					const struct device_node *node)
+{
+	return NULL;
+}
+
+#endif /* CONFIG_OF */
+
+#endif /* __LINUX_OF_GRAPH_H */
diff --git a/drivers/video/adf/arm/malidp_se_device.c b/drivers/video/adf/arm/malidp_se_device.c
new file mode 100644
index 0000000..17f85a7
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_se_device.c
@@ -0,0 +1,668 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/clk.h>
+#include <linux/io.h>
+#include <linux/ioport.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/platform_device.h>
+
+#include <uapi/drm/drm_fourcc.h>
+#include <uapi/video/malidp_adf.h>
+
+#include "malidp_hw_types.h"
+#include "malidp_product_api.h"
+#include "malidp_se_device.h"
+#include "malidp_de_device.h"
+
+#define SE_N_QUEUE_EVENTS 8
+#define SE_N_RGB2YUV_COEFFS 12
+#define SE_N_ENH_COEFFS 9
+
+#define SE_N_PHASE	4	/* 2^SE_N_PHASE is real number */
+#define SE_SHIFT_N_PHASE 12
+
+/* pre-define fix-point numbers */
+#define FP_1_00000		0x00010000			/* 1.0 */
+#define FP_0_66667		0x0000AAAA			/* 0.6667 = 1/1.5 */
+#define FP_0_50000		0x00008000			/* 0.5 = 1/2 */
+#define FP_0_36363		0x00005D17			/* 0.36363 = 1/2.75 */
+#define FP_0_25000		0x00004000			/* 0.25 = 1/4 */
+#define FP_0_12610		0x00002048			/* 0.12610 = 1/7.93 */
+
+extern const char *const op_mode_name[];
+
+static const s32 malidp_se_bt601_narrow_coeffs[SE_N_RGB2YUV_COEFFS] = {
+	 66, 129,  25,
+	-38, -74, 112,
+	112, -94, -18,
+
+	 16, 128, 128
+};
+
+static const s32 malidp_se_bt601_wide_coeffs[SE_N_RGB2YUV_COEFFS] = {
+	 77,  150,  29,
+	-43,  -85, 128,
+	128, -107, -21,
+
+	  0,  128, 128
+};
+
+static const s32 malidp_se_bt709_narrow_coeffs[SE_N_RGB2YUV_COEFFS] = {
+	  47,  157,   16,
+	 -26,  -87,  112,
+	 112, -102,  -10,
+
+	  16,  128,  128
+};
+
+static const s32 malidp_se_bt709_wide_coeffs[SE_N_RGB2YUV_COEFFS] = {
+	  54,  183,  19,
+	 -29,  -99, 128,
+	 128, -116, -12,
+
+	   0,  128, 128
+};
+
+static const s32 malidp_se_enhancer_coeffs[3][SE_N_ENH_COEFFS] = {
+	[MALIDP_SE_ENHANCER_HORZ] = {
+		  0,   0,   0, -32, 128, -32,   0,   0,   0
+	},
+	[MALIDP_SE_ENHANCER_VERT] = {
+		  0, -32,   0,   0, 128,   0,   0, -32,   0
+	},
+	[MALIDP_SE_ENHANCER_BOTH] = {
+		 -8,  -8,  -8,  -8, 128,  -8,  -8,  -8,  -8
+	},
+};
+
+int malidp_se_fmt_drm2mw(struct malidp_se_device *dev, u32 drm_fmt)
+{
+	int i, idx;
+	int n_fmts = dev->n_mw_formats;
+	const u32 *fmts = dev->mw_formats;
+	const u32 *ids = dev->mw_format_ids;
+
+	for (i = 0; i < n_fmts; i++) {
+		if (ids)
+			idx = ids[i];
+		else
+			idx = i;
+
+		if (fmts[i] == drm_fmt)
+			return idx;
+	}
+
+	return -1;
+}
+
+static enum malidp_scaling_coeff_set
+malidp_se_scaling_coeffstab_select(u32 factor)
+{
+	/* NOTE: factor should be upscaling factor */
+	if (factor >= FP_1_00000)
+		return MALIDP_UPSCALING_COEFFS;
+	else if ((factor < FP_1_00000) && (factor >= FP_0_66667))
+		return MALIDP_DOWNSCALING_1_5_COEFFS;
+	else if ((factor < FP_0_66667) && (factor >= FP_0_50000))
+		return MALIDP_DOWNSCALING_2_COEFFS;
+	else if ((factor < FP_0_50000) && (factor >= FP_0_36363))
+		return MALIDP_DOWNSCALING_2_75_COEFFS;
+
+	return MALIDP_DOWNSCALING_4_COEFFS;
+}
+
+void malidp_se_write(struct malidp_se_device *dev,
+					  u32 value, u32 reg)
+{
+	writel(value, dev->regs + reg);
+}
+
+u32 malidp_se_read(struct malidp_se_device *dev, u32 reg)
+{
+	return readl(dev->regs + reg);
+}
+
+void malidp_se_setbits(struct malidp_se_device *dev, u32 mask,
+				     u32 reg)
+{
+	u32 data = malidp_se_read(dev, reg);
+	data |= mask;
+	malidp_se_write(dev, data, reg);
+}
+
+void malidp_se_clearbits(struct malidp_se_device *dev,
+				       u32 mask, u32 reg)
+{
+	u32 data = malidp_se_read(dev, reg);
+	data &= ~mask;
+	malidp_se_write(dev, data, reg);
+}
+
+/*
+ * Set a user callback that will be triggered when the memory write out
+ * interface finishes writing the current buffer.
+ * @dev: pointer to the private malidp_de_device structure.
+ * @callback: the user callback we want to call. This will have the
+ *   the following arguments:
+ *      @device: low level device structure
+ *      event: the kind of event that has occurred in the SE.
+ */
+void malidp_se_set_flip_callback(struct malidp_se_device *dev,
+		void (*callback)(struct device *, void *, struct malidp_hw_event_queue *),
+		void *opaque)
+{
+	dev->flip_callback = callback;
+	dev->callback_opaque = opaque;
+}
+
+static void malidp_se_cfg_enhancer(struct malidp_se_device *dev,
+		enum malidp_se_enhancer_cfg cfg)
+{
+	u32 control;
+	u32 i;
+	const struct malidp_se_regmap *reg = dev->se_regmap;
+
+	/* Don't update anything unless we need to */
+	if (dev->enh_cfg == cfg)
+		return;
+
+	control = malidp_se_read(dev, reg->control);
+	control &= ~(SE_ENH_H_EN | SE_ENH_V_EN);
+
+	switch (cfg) {
+	case MALIDP_SE_ENHANCER_HORZ:
+		control |= SE_ENH_H_EN;
+		break;
+	case MALIDP_SE_ENHANCER_VERT:
+		control |= SE_ENH_V_EN;
+		break;
+	case MALIDP_SE_ENHANCER_BOTH:
+		control |= (SE_ENH_H_EN | SE_ENH_V_EN);
+		break;
+	case MALIDP_SE_ENHANCER_OFF:
+		break;
+	default:
+		BUG();
+	}
+
+	malidp_se_write(dev, control, reg->control);
+	dev->enh_cfg = cfg;
+
+	if (cfg == MALIDP_SE_ENHANCER_OFF) {
+		dev_dbg(dev->device, "%s : Turning enhancer off\n", __func__);
+		return;
+	}
+
+	dev_dbg(dev->device, "%s : Changing enhancer coefficients\n", __func__);
+
+	/* This assumes the coefficients are adjacent in the register map */
+	for (i = 0; i < SE_N_ENH_COEFFS; i++)
+		malidp_se_write(dev, malidp_se_enhancer_coeffs[cfg][i],
+			reg->enhancer_control + (i * 4) + SE_REG_ENH_COEFF1);
+}
+
+static void malidp_se_set_rgb2yuv_coeffs(struct malidp_se_device *dev,
+		struct malidp_hw_buffer *buf)
+{
+	int i;
+	const s32 *coeffs;
+	const struct malidp_se_regmap *reg = dev->se_regmap;
+
+	dev_dbg(dev->device, "%s", __func__);
+
+	switch (buf->flags & MALIDP_FLAG_YUV_MASK) {
+	case (MALIDP_FLAG_YUV_BT601 | MALIDP_FLAG_YUV_NARROW):
+		coeffs = malidp_se_bt601_narrow_coeffs;
+		break;
+	case (MALIDP_FLAG_YUV_BT601 | MALIDP_FLAG_YUV_WIDE):
+		coeffs = malidp_se_bt601_wide_coeffs;
+		break;
+	case (MALIDP_FLAG_YUV_BT709 | MALIDP_FLAG_YUV_NARROW):
+		coeffs = malidp_se_bt709_narrow_coeffs;
+		break;
+	case (MALIDP_FLAG_YUV_BT709 | MALIDP_FLAG_YUV_WIDE):
+		coeffs = malidp_se_bt709_wide_coeffs;
+		break;
+	default:
+		BUG();
+	}
+
+	if (coeffs != dev->rgb2yuv_coeffs) {
+		dev->rgb2yuv_coeffs = coeffs;
+		dev_dbg(dev->device, "%s : changing coefficients", __func__);
+		/*
+		 * This assumes the coefficient registers are adjacent in the
+		 * register map
+		 */
+		for (i = 0; i < SE_N_RGB2YUV_COEFFS; i++)
+			malidp_se_write(dev, dev->rgb2yuv_coeffs[i],
+					reg->conv_control + SE_REG_CONV_COEFF1 +
+					(i * 4));
+	}
+}
+
+/*
+ * Set the configuration for the memory write out interface and scaler.
+ * @dev: private SE hw device.
+ * @cfg: memory write out mode and buffer.
+ * @s0: scaler configuration for scaler 0.
+ */
+void malidp_se_cfg_processing(struct malidp_se_device *dev,
+				struct malidp_se_mw_conf *cfg,
+				struct malidp_se_scaler_conf *s0)
+{
+	u32 control, mw_reg;
+	const struct malidp_se_regmap *reg = dev->se_regmap;
+
+	mw_reg = reg->mw_control;
+	if (cfg->mode != MALIDP_SE_MW_DISABLE) {
+		dev->scene_changing = true;
+
+		if (cfg->buf->fmt == DRM_FORMAT_NV12)
+			malidp_se_set_rgb2yuv_coeffs(dev, cfg->buf);
+
+		switch (cfg->buf->n_planes) {
+		case 2:
+			malidp_se_write(dev, lower_32_bits(cfg->buf->addr[1]),
+				SE_REG_WP2_PTR0_LOW + mw_reg);
+			malidp_se_write(dev, upper_32_bits(cfg->buf->addr[1]),
+				SE_REG_WP2_PTR0_HIGH + mw_reg);
+			malidp_se_write(dev, cfg->buf->pitch[1],
+				SE_REG_WP2_STRIDE + mw_reg);
+			/* Fallthrough */
+		case 1:
+			malidp_se_write(dev, lower_32_bits(cfg->buf->addr[0]),
+				SE_REG_WP1_PTR0_LOW + mw_reg);
+			malidp_se_write(dev, upper_32_bits(cfg->buf->addr[0]),
+				SE_REG_WP1_PTR0_HIGH + mw_reg);
+			malidp_se_write(dev, cfg->buf->pitch[0],
+				SE_REG_WP1_STRIDE + mw_reg);
+			break;
+		default:
+			dev_err(dev->device, "%d plane output formats not supported\n",
+				cfg->buf->n_planes);
+		}
+
+		malidp_se_write(dev, SE_SET_WFORMAT(cfg->buf->hw_fmt),
+				SE_REG_FORMAT + mw_reg);
+
+		if (malidp_hw_format_has_alpha(cfg->buf->fmt))
+			malidp_se_setbits(dev, SE_ALPHA_EN, reg->control);
+		else
+			malidp_se_clearbits(dev, SE_ALPHA_EN, reg->control);
+	}
+
+	if (s0 != NULL)
+		malidp_se_cfg_enhancer(dev, s0->enh_cfg);
+
+	/* Set L0 size register and phase registers */
+	if (s0 != NULL && s0->scaling_enable == true) {
+		malidp_se_write(dev, SE_SET_H_SIZE(s0->input_w) |
+			SE_SET_V_SIZE(s0->input_h),
+			reg->layers_control + SE_REG_L0_IN_SIZE);
+		malidp_se_write(dev, SE_SET_H_SIZE(s0->output_w) |
+			SE_SET_V_SIZE(s0->output_h),
+			reg->layers_control + SE_REG_L0_OUT_SIZE);
+
+		malidp_se_write(dev, s0->h_init_phase,
+			reg->scaling_control + SE_REG_H_INIT_PH);
+		malidp_se_write(dev, s0->h_delta_phase,
+			reg->scaling_control + SE_REG_H_DELTA_PH);
+
+		malidp_se_write(dev, s0->v_init_phase,
+			reg->scaling_control + SE_REG_V_INIT_PH);
+		malidp_se_write(dev, s0->v_delta_phase,
+			reg->scaling_control + SE_REG_V_DELTA_PH);
+
+		if (s0->al == MALIDP_SE_ARGB_PP) {
+			dev->hwdev->topology->dp_api->se_api.set_scaler_coeff(dev,
+				s0->h_coeffs_set, s0->v_coeffs_set);
+			dev_dbg(dev->device,
+				"%s: PP is enabled v_set: %d h_set: %d\n",
+				__func__, s0->v_coeffs_set, s0->h_coeffs_set);
+		} else
+			BUG();
+	} else if (cfg->mode == MALIDP_SE_MW_L0) {
+		malidp_se_write(dev, SE_SET_H_SIZE(cfg->buf->natural_w) |
+				SE_SET_V_SIZE(cfg->buf->natural_h),
+				reg->layers_control + SE_REG_L0_IN_SIZE);
+		malidp_se_write(dev, SE_SET_H_SIZE(cfg->buf->natural_w) |
+				SE_SET_V_SIZE(cfg->buf->natural_h),
+				reg->layers_control + SE_REG_L0_OUT_SIZE);
+	}
+
+	/* set L1 size register */
+	if (cfg->mode == MALIDP_SE_MW_L1) {
+		malidp_se_write(dev, SE_SET_H_SIZE(cfg->buf->natural_w) |
+				SE_SET_V_SIZE(cfg->buf->natural_h),
+				reg->layers_control + SE_REG_L1_SIZE);
+	}
+
+	/* Set control register */
+	control = malidp_se_read(dev, reg->control);
+	/* set mw mode */
+	control &= (~SE_MW_IF_SET(SE_MW_IF_MASK));
+	control |= SE_MW_IF_SET(cfg->mode);
+	/* set scaling flag to control register */
+	if (s0 != NULL) {
+		if (s0->scaling_enable == true) {
+			control |= SE_SCALING_EN;
+
+			control &= ~(SE_RGB_MTH_SEL | SE_ALPHA_MTH_SEL);
+			control |= SE_ARGB_MTH_SET(s0->al);
+
+			if (s0->rgbo_enable)
+				control |= SE_RGBO_IF_EN;
+			else
+				control &= ~SE_RGBO_IF_EN;
+
+			if (s0->scale_alpha)
+				control |= SE_ALPHA_EN;
+			else
+				control &= ~SE_ALPHA_EN;
+		} else
+			control &= ~(SE_RGBO_IF_EN | SE_SCALING_EN);
+	}
+
+	/* if we disable mw and rgbo also is diabled, then the scaler will be disabled */
+	if ((cfg->mode == MALIDP_SE_MW_DISABLE) && ((control & SE_RGBO_IF_EN) ==0))
+		control &= ~SE_SCALING_EN;
+
+	malidp_se_write(dev, control, reg->control);
+}
+
+struct se_fixed_point {
+	u16 integer;
+	u16 fract;
+};
+
+/*
+ * Determine parameters for the filter/enhancer blocks (which depend on scaling
+ * factor), to be written at commit
+ */
+void malidp_se_set_scaling_dependent_state(struct malidp_se_device *dev,
+				struct malidp_se_scaler_conf *s0)
+{
+	u32 tmp_fp, phase;
+	struct se_fixed_point sf_h = { 0, 0 };
+	struct se_fixed_point sf_v = { 0, 0 };
+
+	if (s0->scaling_enable) {
+		/* 16.16 fixed point scaling factors */
+		tmp_fp = (s0->output_w << 16) / (s0->input_w);
+		sf_h.integer = (tmp_fp >> 16) & 0xFFFF;
+		sf_h.fract = tmp_fp & 0xFFFF;
+
+		tmp_fp = (s0->output_h << 16) / (s0->input_h);
+		sf_v.integer = (tmp_fp >> 16) & 0xFFFF;
+		sf_v.fract = tmp_fp & 0xFFFF;
+
+		s0->v_coeffs_set = malidp_se_scaling_coeffstab_select(
+				(sf_v.integer << 16) | sf_v.fract);
+		s0->h_coeffs_set = malidp_se_scaling_coeffstab_select(
+				(sf_h.integer << 16) | sf_h.fract);
+
+		s0->al = MALIDP_SE_ARGB_PP;
+
+		/* Calculate initial_phase and delta_phase
+			for horizontal dimension */
+		phase = s0->input_w;
+		s0->h_init_phase =
+				((phase << SE_N_PHASE) / s0->output_w + 1) / 2;
+
+		phase = s0->input_w;
+		phase <<= (SE_SHIFT_N_PHASE + SE_N_PHASE);
+		s0->h_delta_phase = phase / s0->output_w;
+
+		/* Calculate initial_phase and delta_phase
+			for vertical dimension */
+		phase = s0->input_h;
+		s0->v_init_phase =
+				((phase << SE_N_PHASE) / s0->output_h + 1) / 2;
+
+		phase = s0->input_h;
+		phase <<= (SE_SHIFT_N_PHASE + SE_N_PHASE);
+		s0->v_delta_phase = phase / s0->output_h;
+	}
+
+	dev_dbg(dev->device, "%s : Scaling factors: 0x%04x.%04x 0x%04x.%04x\n",
+		__func__, sf_h.integer, sf_h.fract, sf_v.integer, sf_v.fract);
+
+	/* Determine Image Enhancer setting */
+	if (sf_h.integer >= 2) {
+		if (sf_v.integer >= 2)
+			s0->enh_cfg = MALIDP_SE_ENHANCER_BOTH;
+		else
+			s0->enh_cfg = MALIDP_SE_ENHANCER_HORZ;
+	} else if (sf_v.integer >= 2) {
+		s0->enh_cfg = MALIDP_SE_ENHANCER_VERT;
+	} else {
+		s0->enh_cfg = MALIDP_SE_ENHANCER_OFF;
+	}
+
+
+}
+
+irqreturn_t malidp_se_irq_thread_handler(int irq, void *data)
+{
+	struct malidp_se_device *dev = data;
+	void (*callback)(struct device *, void *, struct malidp_hw_event_queue *);
+	void *callback_opaque;
+	unsigned long flags;
+
+	spin_lock_irqsave(dev->hw_lock, flags);
+	callback = dev->flip_callback;
+	callback_opaque = dev->callback_opaque;
+	spin_unlock_irqrestore(dev->hw_lock, flags);
+
+	if (callback)
+		callback(dev->device, callback_opaque, dev->ev_queue);
+
+	return IRQ_HANDLED;
+}
+
+bool malidp_se_attr_valid(struct malidp_se_device *dev, u32 attr, u32 val)
+{
+	switch (attr) {
+	case MALIDP_ATTR_SE_WQOS:
+		if (val > 15)
+			return false;
+		break;
+	default:
+		return dev->hwdev->dp_api->se_api.axi_valid(attr, val);
+	}
+
+	return true;
+}
+
+void malidp_se_set_axi_cfg(struct malidp_se_device *dev, u32 outstran,
+		u32 burstlen, u32 wcache, u32 wqos)
+{
+	dev_dbg(dev->device, "%s: outstran: %i, burstlen: %i\n", __func__, outstran, burstlen);
+	dev_dbg(dev->device, "%s: wcache: %i, wqos: %i\n", __func__, wcache, wqos);
+
+	dev->outstran = outstran;
+	dev->burstlen = burstlen;
+	dev->wcache = wcache;
+	dev->wqos = wqos;
+	malidp_se_write(dev, SE_AXI_OUTSTDCAPB(dev->outstran) |
+			SE_AXI_BURSTLEN(dev->burstlen - 1) |
+			SE_AXI_WCACHE(dev->wcache) |
+			SE_AXI_WQOS(dev->wqos),
+			dev->se_regmap->axi_control);
+}
+
+struct malidp_se_device *malidp_se_hw_init(struct malidp_hw_device *hwdev,
+			     struct platform_device *pdev,
+			     struct malidp_hw_pdata *pdata,
+			     spinlock_t *hw_lock)
+{
+	int res;
+	struct malidp_se_device *dev = devm_kzalloc(&pdev->dev,
+					sizeof(struct malidp_se_device),
+						    GFP_KERNEL);
+
+	if (!dev)
+		return NULL;
+
+	dev->hw_lock = hw_lock;
+	dev->regs = pdata->regs + hwdev->hw_regmap->se_base;
+	dev->se_regmap = &hwdev->hw_regmap->se_regmap;
+	dev->hwdev = hwdev;
+	dev->scene_changing = false;
+
+	dev->n_mw_formats = hwdev->topology->n_mw_formats;
+	dev->mw_formats = hwdev->topology->mw_formats;
+	dev->mw_format_ids = hwdev->topology->mw_format_ids;
+
+	dev->device = &pdev->dev;
+
+	res = devm_request_threaded_irq(dev->device,
+			pdata->se_irq,
+			hwdev->dp_api->se_api.irq_handler,
+			malidp_se_irq_thread_handler,
+			IRQF_SHARED, "malidp-se", dev);
+	if (res < 0) {
+		dev_err(&pdev->dev, "%s: failed to request 'se' irq\n", __func__);
+		return NULL;
+	}
+
+	dev->ev_queue = malidp_hw_event_queue_create(SE_N_QUEUE_EVENTS);
+	if (!dev->ev_queue)
+		return NULL;
+
+	dev->op_mode = MALIDP_OP_MODE_UNKNOWN;
+
+	dev->outstran = pdata->se_axi_outstran;
+	dev->burstlen = pdata->se_axi_burstlen;
+	dev->wcache = pdata->se_axi_awcache;
+	dev->wqos = pdata->se_axi_awqos;
+
+	dev_dbg(dev->device, "%s : success!\n", __func__);
+
+	return dev;
+}
+
+void malidp_se_hw_exit(struct malidp_se_device *dev)
+{
+	malidp_hw_event_queue_destroy(dev->ev_queue);
+	return;
+}
+
+int malidp_se_get_attr(struct malidp_se_device *dev, u32 attr, u32 *val)
+{
+	switch (attr) {
+	case MALIDP_ATTR_SE_BURSTLEN:
+		*val = dev->burstlen;
+		break;
+	case MALIDP_ATTR_SE_OUTSTRAN:
+		*val = dev->outstran;
+		break;
+	case MALIDP_ATTR_SE_WQOS:
+		*val = dev->wqos;
+		break;
+	case MALIDP_ATTR_SE_WCACHE:
+		*val = dev->wcache;
+		break;
+	default:
+		dev_err(dev->device, "%s: unkown SE attribute %i\n",
+			__func__, attr);
+		return -EINVAL;
+	}
+
+	dev_dbg(dev->device, "%s: attr: %i, val: %u\n",
+		__func__, attr, *val);
+
+	return 0;
+}
+
+int malidp_se_set_attr(struct malidp_se_device *dev, u32 attr, u32 val)
+{
+	int ret = 0;
+
+	dev_dbg(dev->device, "%s: attr: %i, val: %u\n", __func__, attr, val);
+
+	if (!malidp_se_attr_valid(dev, attr, val)) {
+		dev_dbg(dev->device, "%s: invalid value %u for attr %u\n",
+			__func__, val, attr);
+		return -EINVAL;
+	}
+
+	switch (attr) {
+	case MALIDP_ATTR_SE_BURSTLEN:
+		malidp_se_set_axi_cfg(dev, dev->outstran, val,
+				      dev->wqos, dev->wcache);
+		break;
+	case MALIDP_ATTR_SE_OUTSTRAN:
+		malidp_se_set_axi_cfg(dev, val, dev->burstlen,
+				      dev->wqos, dev->wcache);
+		break;
+	case MALIDP_ATTR_SE_WCACHE:
+		malidp_se_set_axi_cfg(dev, dev->outstran, dev->burstlen,
+				      val, dev->wqos);
+		break;
+	case MALIDP_ATTR_SE_WQOS:
+		malidp_se_set_axi_cfg(dev, dev->outstran, dev->burstlen,
+				      dev->wcache, val);
+		break;
+	default:
+		dev_err(dev->device, "%s: unkown SE attribute %i\n",
+			__func__, attr);
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+int malidp_se_save_attr(struct malidp_se_device *dev, u32 attr, u32 val)
+{
+	int ret = 0;
+
+	dev_dbg(dev->device, "%s: attr: %i, val: %u\n", __func__, attr, val);
+
+	if (!malidp_se_attr_valid(dev, attr, val)) {
+		dev_dbg(dev->device, "%s: invalid value %u for attr %u\n",
+			__func__, val, attr);
+		return -EINVAL;
+	}
+
+	switch (attr) {
+	case MALIDP_ATTR_SE_BURSTLEN:
+		dev->burstlen = val;
+		break;
+	case MALIDP_ATTR_SE_OUTSTRAN:
+		dev->outstran = val;
+		break;
+	case MALIDP_ATTR_SE_WCACHE:
+		dev->wcache = val;
+		break;
+	case MALIDP_ATTR_SE_WQOS:
+		dev->wqos = val;
+		break;
+	default:
+		dev_err(dev->device, "%s: unkown SE attribute %i\n",
+			__func__, attr);
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
diff --git a/drivers/video/adf/arm/malidp_se_device.h b/drivers/video/adf/arm/malidp_se_device.h
new file mode 100644
index 0000000..99768b8
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_se_device.h
@@ -0,0 +1,296 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_SE_DEVICE_H_
+#define _MALIDP_SE_DEVICE_H_
+
+#include "malidp_hw_types.h"
+#include "malidp_hw.h"
+#include <linux/interrupt.h>
+
+#define SE_REG_STATUS			0x000
+#define		SE_ST_CONFIG		(1 << 0)
+#define		SE_ST_PTR_UPDATE	(1 << 4)
+#define		SE_ST_INIT_BUSY		(1 << 5)
+#define		SE_ST_AXIERR		(1 << 8)
+#define		SE_ST_OVERRUN		(1 << 9)
+#define		SE_ST_PROGLINE1		(1 << 12)
+#define		SE_ST_PROGLINE2		(1 << 13)
+#define		SE_ST_CONFIG_ACTIVE	(1 << 17)
+#define		SE_ST_PSM_ACTIVE	(1 << 18)
+#define		SE_ST_AXI_BUSY		(1 << 28)
+#define		SE_ST_IRQ		(1 << 31)
+#define SE_REG_SETIRQ			0x004
+#define SE_REG_MASKIRQ			0x008
+#define		SE_IRQ_CONFIG			(1 << 0)
+#define		SE_IRQ_PTR_UPDATE		(1 << 4)
+#define		SE_IRQ_INIT_BUSY		(1 << 5)
+#define		SE_IRQ_AXI_ERR			(1 << 8)
+#define		SE_IRQ_OVERRUN			(1 << 9)
+#define		SE_IRQ_PROGLINE1		(1 << 12)
+#define		SE_IRQ_PROGLINE2		(1 << 13)
+#define		SE_IRQ_ENABLE			(1 << 31)
+
+/* Control register bits and mask */
+#define		SE_SCALING_EN			(1 << 0)
+#define		SE_ALPHA_EN			(1 << 1)
+#define		SE_ENH_H_EN			(1 << 2)
+#define		SE_ENH_V_EN			(1 << 3)
+#define		SE_RGBO_IF_EN			(1 << 4)
+#define		SE_MW_IF_MASK			0x3
+#define		SE_MW_IF_SET(x)			(((x) & SE_MW_IF_MASK) << 5)
+#define		SE_RGB_MTH_SEL			(1 << 8)
+#define		SE_ALPHA_MTH_SEL		(1 << 9)
+#define		SE_ARGB_MTH_SET(x)		((x << 8) & (SE_RGB_MTH_SEL | SE_ALPHA_MTH_SEL))
+#define		SE_PTR_VALID			(1 << 12)
+#define		SE_SOFTRESET_REQ		(1 << 16)
+#define		SE_CONFIG_REQ			(1 << 17)
+#define		SE_MMU_PROT			(1 << 25)
+#define		SE_ENDIAN			(1 << 28)
+
+#define SE_REG_LINE_INT_CTRL		0x010
+#define		SE_LINE_INT_MASK		0x3fff
+#define		SE_LINE_INT_1(x)		(((x) & SE_LINE_INT_MASK) << 0)
+#define		SE_LINE_INT_2(x)		(((x) & SE_LINE_INT_MASK) << 16)
+
+/* AXI register bits and mask */
+#define		SE_AXI_OUTSTDCAPB_MASK		0xff
+#define		SE_AXI_OUTSTDCAPB(x)		(((x) & SE_AXI_OUTSTDCAPB_MASK) << 0)
+#define		SE_AXI_WCACHE_MASK		0xf
+#define		SE_AXI_WCACHE(x)		(((x) & SE_AXI_WCACHE_MASK) << 8)
+#define		SE_AXI_BURSTLEN_MASK		0xff
+#define		SE_AXI_BURSTLEN(x)		(((x) & SE_AXI_BURSTLEN_MASK) << 16)
+#define		SE_AXI_WQOS_MASK		0xf
+#define		SE_AXI_WQOS(x)			(((x) & SE_AXI_WQOS_MASK) << 28)
+
+#define SE_REG_SECURE_CTRL		0x01c
+
+/* Layer control register offset */
+#define SE_REG_L0_IN_SIZE		0x00
+#define SE_REG_L0_OUT_SIZE		0x04
+#define SE_REG_L0_3DSTRUCT		0x08
+#define SE_REG_L1_SIZE			0x0C
+#define		SE_SET_V_SIZE(x)		(((x) & 0x1fff) << 16)
+#define		SE_SET_H_SIZE(x)		(((x) & 0x1fff) << 0)
+
+/* Scaling control registers offset */
+#define SE_REG_H_INIT_PH		0x00
+#define SE_REG_H_DELTA_PH		0x04
+#define SE_REG_V_INIT_PH		0x08
+#define SE_REG_V_DELTA_PH		0x0c
+#define SE_REG_COEFFTAB_ADDR	0x10
+#define		SE_COEFFTAB_ADDR_MASK	0x7f
+#define		SE_V_COEFFTAB		(1 << 8)
+#define		SE_H_COEFFTAB		(1 << 9)
+#define		SE_SET_V_COEFFTAB_ADDR(x) \
+				(SE_V_COEFFTAB | ((x) & SE_COEFFTAB_ADDR_MASK))
+#define		SE_SET_H_COEFFTAB_ADDR(x) \
+				(SE_H_COEFFTAB | ((x) & SE_COEFFTAB_ADDR_MASK))
+#define SE_REG_COEFFTAB_DATA	0x14
+#define		SE_COEFFTAB_DATA_MASK	0x3fff
+#define		SE_SET_COEFFTAB_DATA(x)	((x) & SE_COEFFTAB_DATA_MASK)
+
+/* Enhance coeffents reigster offset */
+#define	SE_REG_ENH_COEFF1	0x04
+#define		SE_ENH_LIMIT_MASK		0xfff
+#define		SE_ENH_LIMIT_LOW_SHIFT		0
+#define		SE_ENH_LIMIT_HIGH_SHIFT		16
+#define		SE_SET_ENH_LIMIT_LOW(x)		(((x) & SE_ENH_LIMIT_MASK) << SE_ENH_LIMIT_LOW_SHIFT)
+#define		SE_SET_ENH_LIMIT_HIGH(x)	(((x) & SE_ENH_LIMIT_MASK) << SE_ENH_LIMIT_HIGH_SHIFT)
+#define		SE_SET_ENH_COEFF(x)		(((x) & 0x7ff) << 0)
+
+#define SE_ENH_LOW_LEVEL 24
+#define SE_ENH_HIGH_LEVEL 63
+
+/* Color space conversion register offset */
+#define SE_REG_CONV_COEFF1	0x04
+
+#define SE_REG_CONV_GAMMA_ADDR		0x0A4
+#define SE_REG_CONV_GAMMA_DATA		0x0A8
+
+/* Memory write out */
+#define SE_REG_FORMAT		0x00
+#define		SE_WFORMAT_MASK		0x3F
+#define		SE_SET_WFORMAT(x)	(((x) & SE_WFORMAT_MASK) << 0)
+#define SE_REG_WP1_STRIDE	0x04
+#define SE_REG_WP2_STRIDE	0x08
+#define SE_REG_WP1_PTR0_LOW	0x0C
+#define SE_REG_WP1_PTR0_HIGH	0x10
+#define SE_REG_WP1_PTR1_LOW		0x14
+#define SE_REG_WP1_PTR1_HIGH	0x18
+#define SE_REG_WP1_PTR0_R_LOW	0x1C
+#define SE_REG_WP1_PTR0_R_HIGH	0x20
+#define SE_REG_WP1_PTR1_R_LOW	0x24
+#define SE_REG_WP1_PTR1_R_HIGH	0x28
+#define SE_REG_WP2_PTR0_LOW		0x2C
+#define SE_REG_WP2_PTR0_HIGH	0x30
+#define SE_REG_WP2_PTR1_LOW		0x34
+#define SE_REG_WP2_PTR1_HIGH	0x38
+#define SE_REG_WP2_PTR0_R_LOW	0x3C
+#define SE_REG_WP2_PTR0_R_HIGH	0x40
+#define SE_REG_WP2_PTR1_R_LOW	0x44
+#define SE_REG_WP2_PTR1_R_HIGH	0x48
+
+#define SE_DEFAULT_AXI_BURSTLEN	16
+#define SE_DEFAULT_AXI_OUTSTRAN	16
+#define SE_DEFAULT_AXI_AWCACHE	0x0 /* Device non-bufferable */
+#define SE_DEFAULT_AXI_AWQOS	0x0 /* Not performing any QoS scheme */
+
+
+enum malidp_se_mw_mode {
+	MALIDP_SE_MW_DISABLE = 0,
+	MALIDP_SE_MW_L0,
+	MALIDP_SE_MW_L1,
+};
+
+enum malidp_se_scaling_algorithms {
+	MALIDP_SE_ARGB_PP = 0,		/* PolyPhase algorithm for both Alpha and RGB */
+	MALIDP_SE_RGB_NN = 1,		/* Nearest Neighbor algorithm for RGB, and PolyPhase for Alpha */
+	MALIDP_SE_A_PP = 1,			/* Same as MALIDP_SE_RGB_NN */
+	MALIDP_SE_RGB_PP = 2,		/* PolyPhase algorithm for RGB, and Nearest Neighbor algorithm for Alpha */
+	MALIDP_SE_A_NN = 2,			/* Same as MALIDP_SE_RGB_PP */
+	MALIDP_SE_ARGB_NN = 3,		/* Nearest Neighbor algorithm for both Alpha and RGB */
+};
+
+enum malidp_se_enhancer_cfg {
+	MALIDP_SE_ENHANCER_HORZ = 0,
+	MALIDP_SE_ENHANCER_VERT = 1,
+	MALIDP_SE_ENHANCER_BOTH = 2,
+	MALIDP_SE_ENHANCER_OFF  = 3,
+};
+
+enum malidp_scaling_coeff_set {
+	/* For upscaling */
+	MALIDP_UPSCALING_COEFFS = 0,
+	/* For noscaling or 1.5x downscaling */
+	MALIDP_DOWNSCALING_1_5_COEFFS = 1,
+	/* For 1.5x to 2x downscaling */
+	MALIDP_DOWNSCALING_2_COEFFS = 2,
+	/* For 2x to 2.75x downscaling */
+	MALIDP_DOWNSCALING_2_75_COEFFS = 3,
+	/* For 2.75x to 4x downscaling */
+	MALIDP_DOWNSCALING_4_COEFFS = 4,
+};
+
+struct malidp_se_mw_conf {
+	enum malidp_se_mw_mode mode;
+	struct malidp_hw_buffer *buf;
+};
+
+struct malidp_se_scaler_conf {
+	bool rgbo_enable;
+	bool scaling_enable;
+	u16 input_w, input_h;
+	u16 output_w, output_h;
+	enum malidp_scaling_coeff_set v_coeffs_set;
+	enum malidp_scaling_coeff_set h_coeffs_set;
+	enum malidp_se_scaling_algorithms al;
+	u32 v_init_phase, v_delta_phase;
+	u32 h_init_phase, h_delta_phase;
+	bool scale_alpha;
+	enum malidp_se_enhancer_cfg enh_cfg;
+};
+
+struct malidp_se_device {
+	void __iomem *regs;
+	enum malidp_op_mode op_mode;
+	struct device *device;
+	struct malidp_hw_device *hwdev;
+	void (*flip_callback)(struct device *, void *, struct malidp_hw_event_queue *);
+	void *callback_opaque;
+	const s32 *rgb2yuv_coeffs;
+	u16 v_coeffstab, h_coeffstab;
+	enum malidp_se_enhancer_cfg enh_cfg;
+	/*
+	 * Used to indicate that the next LINE1 IRQ is due to a
+	 * content change as opposed to re-writing the previous
+	 * scene to memory again.
+	 */
+	bool scene_changing;
+	struct malidp_hw_event_queue *ev_queue;
+	/*
+	 * This spinlock protects accesses to registers and clocks.
+	 * Also protects the shared variables in this structure:
+	 * "event".
+	 */
+	spinlock_t *hw_lock;
+
+	/* Attributes accessible through sysfs */
+	u16 burstlen;
+	u8 outstran;
+	u8 wqos;
+	u8 wcache;
+
+	const struct malidp_se_regmap *se_regmap;
+	/* Stored after entering PSM to handle any residual IRQs */
+	u32 pending_status;
+
+	u32 n_mw_formats;
+	const u32 *mw_formats;
+	/*
+	 * The HW id of the format at the same index in the supported_format
+	 * list
+	 */
+	const u32 *mw_format_ids;
+};
+
+struct malidp_se_device *malidp_se_hw_init(struct malidp_hw_device *hwdev,
+			     struct platform_device *pdev,
+			     struct malidp_hw_pdata *pdata,
+			     spinlock_t *hw_lock);
+
+int malidp_se_hw_cfg(struct malidp_se_device *dev,
+		struct malidp_hw_pdata *pdata);
+
+void malidp_se_hw_exit(struct malidp_se_device *dev);
+
+int malidp_dt_parse_se(struct platform_device *pdev,
+			       struct device_node *nproot,
+			       struct malidp_hw_pdata *pdata);
+
+int malidp_se_fmt_drm2mw(struct malidp_se_device *dev, u32 drm_fmt);
+
+void malidp_se_write(struct malidp_se_device *dev,
+				u32 value, u32 reg);
+u32 malidp_se_read(struct malidp_se_device *dev, u32 reg);
+void malidp_se_setbits(struct malidp_se_device *dev, u32 mask,
+				u32 reg);
+void malidp_se_clearbits(struct malidp_se_device *dev,
+			u32 mask, u32 reg);
+irqreturn_t malidp_se_irq_thread_handler(int irq, void *data);
+bool malidp_se_attr_valid(struct malidp_se_device *dev, u32 attr, u32 val);
+void malidp_se_set_axi_cfg(struct malidp_se_device *dev, u32 outstran,
+		u32 burstlen, u32 wcache, u32 wqos);
+/*
+ * The following functions need to be called while holding the HW spinlock
+ * unless they are used at initialization or exit time.
+ */
+void malidp_se_set_flip_callback(struct malidp_se_device *dev,
+		void (*callback)(struct device *, void *, struct malidp_hw_event_queue *),
+		void *opaque);
+
+void malidp_se_cfg_processing(struct malidp_se_device *dev,
+				struct malidp_se_mw_conf *mw_cfg,
+				struct malidp_se_scaler_conf *s0);
+
+void malidp_se_set_scaling_dependent_state(struct malidp_se_device *dev,
+				struct malidp_se_scaler_conf *s0);
+
+int malidp_se_get_attr(struct malidp_se_device *dev, u32 attr, u32 *val);
+int malidp_se_set_attr(struct malidp_se_device *dev, u32 attr, u32 val);
+int malidp_se_save_attr(struct malidp_se_device *dev, u32 attr, u32 val);
+#endif /* _MALIDP_SE_DEVICE_H_ */
diff --git a/drivers/video/adf/arm/malidp_sysfs.c b/drivers/video/adf/arm/malidp_sysfs.c
new file mode 100644
index 0000000..8e15a6d
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_sysfs.c
@@ -0,0 +1,220 @@
+/*
+ *
+ * (C) COPYRIGHT 2014-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/device.h>
+
+#include "malidp_hw.h"
+
+#ifdef DEBUG
+static ssize_t malidp_show_attr(struct device *dev, u32 attr, char *buf)
+{
+	struct malidp_device *dp_dev = dev_get_drvdata(dev);
+	u32 value;
+	int ret;
+
+	ret = malidp_hw_get_attr(dp_dev->hw_dev, attr, &value);
+	if (ret)
+		return ret;
+
+	return scnprintf(buf, PAGE_SIZE, "%u\n", value);
+}
+
+static ssize_t malidp_store_attr(struct device *dev, u32 attr, const char *buf,
+	size_t count)
+{
+	struct malidp_device *dp_dev = dev_get_drvdata(dev);
+	u32 value = 0;
+	int ret;
+
+	if (!count)
+		return 0;
+	if (sscanf(buf, "%u", &value) != 1)
+		return -EINVAL;
+
+	mutex_lock(&dp_dev->adf_dev.client_lock);
+	ret = malidp_hw_set_attr(dp_dev->hw_dev, attr, value);
+	mutex_unlock(&dp_dev->adf_dev.client_lock);
+
+	return ret ? ret : count;
+}
+
+#define MALIDP_DEVICE_ATTR(_name, _mode, _attr)				\
+	static ssize_t show_##_name(struct device *dev,			\
+				    struct device_attribute *attr,	\
+				    char *buf)				\
+	{								\
+		return malidp_show_attr(dev, _attr, buf);		\
+	}								\
+	static ssize_t store_##_name(struct device *dev,		\
+				     struct device_attribute *attr,	\
+				     const char *buf, size_t count)	\
+	{								\
+		return malidp_store_attr(dev, _attr, buf, count);	\
+	}								\
+	static struct device_attribute dev_attr_##_name = {		\
+		.attr = {						\
+			.name = __stringify(_name),			\
+			.mode = _mode,					\
+		},							\
+		.show   = show_##_name,					\
+		.store  = store_##_name,				\
+	}
+
+MALIDP_DEVICE_ATTR(de_burstlen, S_IWUSR | S_IRUGO, MALIDP_ATTR_DE_BURSTLEN);
+MALIDP_DEVICE_ATTR(de_poutstdcab, S_IWUSR | S_IRUGO, MALIDP_ATTR_DE_POUTSTDCAB);
+MALIDP_DEVICE_ATTR(de_outstran, S_IWUSR | S_IRUGO, MALIDP_ATTR_DE_OUTSTRAN);
+MALIDP_DEVICE_ATTR(de_rqos_low, S_IWUSR | S_IRUGO, MALIDP_ATTR_DE_RQOS_LOW);
+MALIDP_DEVICE_ATTR(de_rqos_high, S_IWUSR | S_IRUGO, MALIDP_ATTR_DE_RQOS_HIGH);
+MALIDP_DEVICE_ATTR(de_rqos_red, S_IWUSR | S_IRUGO, MALIDP_ATTR_DE_RQOS_RED);
+MALIDP_DEVICE_ATTR(de_rqos_green, S_IWUSR | S_IRUGO, MALIDP_ATTR_DE_RQOS_GREEN);
+MALIDP_DEVICE_ATTR(de_fifo_size, S_IRUGO, MALIDP_ATTR_DE_FIFO_SIZE);
+MALIDP_DEVICE_ATTR(se_burstlen, S_IWUSR | S_IRUGO, MALIDP_ATTR_SE_BURSTLEN);
+MALIDP_DEVICE_ATTR(se_outstran, S_IWUSR | S_IRUGO, MALIDP_ATTR_SE_OUTSTRAN);
+MALIDP_DEVICE_ATTR(se_wcache, S_IWUSR | S_IRUGO, MALIDP_ATTR_SE_WCACHE);
+MALIDP_DEVICE_ATTR(se_wqos, S_IWUSR | S_IRUGO, MALIDP_ATTR_SE_WQOS);
+
+static struct attribute *malidp_debug_attrs[] = {
+	&dev_attr_de_burstlen.attr,
+	&dev_attr_de_poutstdcab.attr,
+	&dev_attr_de_outstran.attr,
+	&dev_attr_de_rqos_low.attr,
+	&dev_attr_de_rqos_high.attr,
+	&dev_attr_de_rqos_red.attr,
+	&dev_attr_de_rqos_green.attr,
+	&dev_attr_de_fifo_size.attr,
+	&dev_attr_se_burstlen.attr,
+	&dev_attr_se_outstran.attr,
+	&dev_attr_se_wcache.attr,
+	&dev_attr_se_wqos.attr,
+	NULL,
+};
+
+static struct attribute_group malidp_debug_attr_group = {
+	.attrs = malidp_debug_attrs,
+};
+#endif
+
+static ssize_t show_hw_clock_ratio(struct device *dev,
+					struct device_attribute *attr,
+					char *buf)
+{
+	struct malidp_device *dp_dev = dev_get_drvdata(dev);
+	u32 clock_ratio = malidp_hw_clock_ratio_get(dp_dev->hw_dev);
+	u32 ratio_i = (clock_ratio >> 16) & 0xFFFF;
+	u32 ratio_f = 0;
+
+	clock_ratio &= 0xFFFF;
+	/* show clock_ratio as X.XX */
+	if (clock_ratio != 0)
+		ratio_f = (clock_ratio * 10000) >> 16;
+
+	return snprintf(buf, PAGE_SIZE, "%u.%04u\n", ratio_i, ratio_f);
+}
+
+#define RATIO_BASE	10
+static ssize_t store_hw_clock_ratio(struct device *dev,
+				struct device_attribute *attr,
+				const char *buf, size_t count)
+{
+	struct malidp_device *dp_dev = dev_get_drvdata(dev);
+	char str[5];
+	u32 ratio = 0, fraction = 0, base = RATIO_BASE;
+	int i;
+
+	if (!count)
+		return 0;
+
+	str[0] = '\0';
+	if (sscanf(buf, "%u.%4s", &ratio, str) > 0) {
+		ratio = (ratio << 16) & 0xFFFF0000;
+
+		for (i = 0; str[i] != '\0' && i < 5; i++) {
+			if (str[i] < '0' || str[i] > '9')
+				break;
+			fraction += ((str[i] - '0') << 16) / base;
+			base *= RATIO_BASE;
+		}
+
+		ratio += fraction;
+		i = malidp_hw_clock_ratio_set(dp_dev->hw_dev, ratio);
+		if (i != 0)
+			return -EINVAL;
+	}
+
+	return count;
+}
+
+static ssize_t show_core_id(struct device *dev,
+			    struct device_attribute *attr,
+			    char *buf)
+{
+	struct malidp_device *dp_dev = dev_get_drvdata(dev);
+	return snprintf(buf, PAGE_SIZE, "%08x\n", dp_dev->core_id);
+}
+
+DEVICE_ATTR(clock_ratio, S_IWUSR | S_IRUGO,
+		show_hw_clock_ratio, store_hw_clock_ratio);
+DEVICE_ATTR(core_id, S_IRUGO,
+	    show_core_id, NULL);
+
+static struct attribute *malidp_hw_attrs[] = {
+	&dev_attr_clock_ratio.attr,
+	&dev_attr_core_id.attr,
+	NULL
+};
+
+static struct attribute_group malidp_hw_attr_group = {
+	.attrs = malidp_hw_attrs,
+};
+
+static struct attribute_group *malidp_attr_groups[] = {
+#ifdef DEBUG
+	&malidp_debug_attr_group,
+#endif
+	&malidp_hw_attr_group,
+	NULL,
+};
+
+
+int malidp_sysfs_init(struct malidp_device *dev)
+{
+	struct attribute_group **group = malidp_attr_groups;
+	attr_visible_t func = malidp_hw_get_attr_visible_func(dev->hw_dev);
+	int ret = 0;
+
+	while (*group) {
+		(*group)->is_visible = func;
+		ret = sysfs_create_group(&dev->device->kobj, *group);
+		if (ret) {
+			dev_err(dev->device, "failed registering attribute group %p", *group);
+			break;
+		}
+		group++;
+	}
+
+	return ret;
+}
+
+void malidp_sysfs_destroy(struct malidp_device *dev)
+{
+	struct attribute_group **group = malidp_attr_groups;
+
+	while (*group) {
+		sysfs_remove_group(&dev->device->kobj, *group);
+		group++;
+	}
+}
diff --git a/drivers/video/adf/arm/malidp_sysfs.h b/drivers/video/adf/arm/malidp_sysfs.h
new file mode 100644
index 0000000..a4d87d8
--- /dev/null
+++ b/drivers/video/adf/arm/malidp_sysfs.h
@@ -0,0 +1,29 @@
+/*
+ *
+ * (C) COPYRIGHT 2014-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_SYSFS_H_
+#define _MALIDP_SYSFS_H_
+
+#include "malidp_drv.h"
+
+typedef umode_t (*attr_visible_t)(struct kobject*,
+			struct attribute *, int);
+
+int malidp_sysfs_init(struct malidp_device *dev);
+void malidp_sysfs_destroy(struct malidp_device *dev);
+
+#endif /* _MALIDP_SYSFS_H_ */
diff --git a/drivers/video/adf/arm/product/malidp_product_api.h b/drivers/video/adf/arm/product/malidp_product_api.h
new file mode 100644
index 0000000..a66ff38
--- /dev/null
+++ b/drivers/video/adf/arm/product/malidp_product_api.h
@@ -0,0 +1,165 @@
+/*
+ *
+ * (C) COPYRIGHT 2014-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _MALIDP_PRODUCT_API_H_
+#define _MALIDP_PRODUCT_API_H_
+
+#include "malidp_hw.h"
+#include "malidp_de_device.h"
+#include "malidp_se_device.h"
+#include "malidp_sysfs.h"
+
+/* HW description accessors for the different products.
+ * Could live in separate files, but that would cause lots of
+ * file-bloat
+ */
+void malidp_dp500_get_hw_description(struct malidp_hw_description *);
+void malidp_dp550_get_hw_description(struct malidp_hw_description *);
+
+enum malidp_scaling_coeff_set;
+
+struct malidp_de_product_api {
+	/* Must be called with the DE in Config Mode
+	 * Analogous to the current malidp_de_hw_cfg implementation
+	 *  - Register interrupt handler (use common "soft" handler)
+	 *  - Set AXI config
+	 *  - Set background color
+	 *  - Set interrupts
+	 *  - Set alpha lookup tables
+	 *  - Write coefficients if necessary
+	 */
+	int (*hw_cfg)(struct malidp_de_device *);
+	/* Must be called with the DE in Config Mode
+	 * Write the display mode to the HW registers
+	 * Can't be common due to HSP and VSP moving
+	 */
+	void (*modeset)(struct malidp_de_device *, struct malidp_de_hwmode *);
+	/* Called from malidp_de_cfg_layer and at modeset
+	 * Set the gamma/inverse gamma lookup table, writing coefficients if
+	 * needed. For inverse gamma, coeffs should be NULL.
+	 */
+	void (*set_gamma_coeff)(struct malidp_de_device *, u32 *coeffs);
+	/* Fixup a DRM format according to buffer flags, if necessary.
+	 * Returns the fixed-up format, to be converted to a hardware ID.
+	 */
+	u32 (*fmt_fixup)(u32 drm_format, u32 flags);
+	/* Call from malidp_de_attr_valid
+	 * Validate AXI setting for DE:
+	 * Three attributes: BURSTLEN, POUTSTDCAB and OUTSTRAN
+	 */
+	bool (*axi_valid)(u32 attr, u32 val);
+	/* Shouldn't be called directly. It is used for requestig IRQ */
+	irqreturn_t (*irq_handler)(int irq, void *data);
+};
+
+struct malidp_se_product_api {
+	/* Must be called with the SE in Config Mode
+	 * Analogous to the current malidp_de_hw_cfg implementation
+	 *  - Register interrupt handler (use common "soft" handler)
+	 *  - Set AXI config
+	 *  - Set image enhancer state
+	 *  - Set interrupts
+	 */
+	int (*hw_cfg)(struct malidp_se_device *);
+	/* Called from malidp_se_cfg_processing
+	 * Select the scaler coefficients, writing the table if necessary
+	 */
+	void (*set_scaler_coeff)(struct malidp_se_device *,
+		enum malidp_scaling_coeff_set hcoeff,
+		enum malidp_scaling_coeff_set vcoeff);
+	/* Checking the scaling limitation
+	 */
+	bool (*limitation_check)(struct malidp_se_device *,
+			struct malidp_se_scaler_conf *);
+	/* Calculate the downscaling threshold
+	 */
+	u32 (*calc_downscaling_threshold)(u32, u32, struct drm_mode_modeinfo *);
+	/* Call from malidp_se_attr_valid
+	 * Validate AXI setting for SE:
+	 * Tow attributes: BURSTLEN and OUTSTRAN
+	 */
+	bool (*axi_valid)(u32 attr, u32 val);
+	/* Shouldn't be called directly. It is used for requestig IRQ */
+	irqreturn_t (*irq_handler)(int irq, void *data);
+};
+
+struct malidp_product_api {
+	/* Change the operating mode of the DP
+	 * This must put both the DE and SE in the given mode (or its closest
+	 * equivalent), returning the old mode
+	 */
+	enum malidp_op_mode (*change_op_mode)(struct malidp_hw_device *,
+		enum malidp_op_mode);
+	/* Called from hw_init and hw_exit
+	 * Disable device interrupt.
+	 */
+	void (*disable_irq)(struct malidp_hw_device *);
+	/* Called by sysfs to check the condition of every attributes
+	 */
+	attr_visible_t attr_visible;
+	/* Called from hw_debugfs_init.
+	 * This API is used for the elements specific to the product.
+	 */
+	void (*debugfs_func)(struct malidp_hw_device *);
+	/* Calculate rotation memory size */
+	u32 (*rotmem_size_required)(const struct malidp_hw_buffer *);
+	/* The APIs for the DE and SE of this product */
+	struct malidp_de_product_api de_api;
+	struct malidp_se_product_api se_api;
+};
+
+/* Register offsets for use by the generic de/se/hw layer */
+struct malidp_de_regmap {
+	u16 axi_control;
+	u16 disp_func;
+	u16 output_depth;
+	/* Offset of the first color adjustment coefficient register */
+	u16 coloradj_coeff;
+	u16 qos_control;
+};
+
+struct malidp_se_regmap {
+	/* Offset of the SE_CONTROL register */
+	u16 control;
+	u16 axi_control;
+	/* Offset of the Layers Control register block */
+	u16 layers_control;
+	/* Offset of the Scaling Control register block */
+	u16 scaling_control;
+	/* Offset of the Image Enhancement register block */
+	u16 enhancer_control;
+	/* Offset of the RGB_YUV_CONTROL register */
+	u16 conv_control;
+	/* Offset of the Memory Write register block */
+	u16 mw_control;
+};
+
+struct malidp_hw_regmap {
+	/* Offset of the PERIPHERAL_ID 4 register */
+	u16 id_registers;
+	/* Offset of the Configuration Valid register */
+	u16 config_valid;
+	/* Base address offset of the DE registers */
+	u16 de_base;
+	/* Base address offset of the SE registers */
+	u16 se_base;
+	/* Regmap descriptors for the DE and SE */
+	struct malidp_de_regmap de_regmap;
+	struct malidp_se_regmap se_regmap;
+};
+
+#endif /* _MALIDP_PRODUCT_API_H_ */
diff --git a/drivers/video/adf/arm/product/malidp_product_dp500.c b/drivers/video/adf/arm/product/malidp_product_dp500.c
new file mode 100644
index 0000000..3ae3bbc
--- /dev/null
+++ b/drivers/video/adf/arm/product/malidp_product_dp500.c
@@ -0,0 +1,1364 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+#include <linux/clk.h>
+#include <linux/interrupt.h>
+#include "malidp_product_api.h"
+#include "malidp_de_device.h"
+#include "malidp_se_device.h"
+#include <uapi/video/malidp_adf.h>
+
+#define MALI_DP500_REG_DE_STATUS	0x0000
+#define		MALI_DP500_DE_LV_PTR_UPDATE	(1 << 8)
+#define		MALI_DP500_DE_LG1_PTR_UPDATE	(1 << 9)
+#define		MALI_DP500_DE_LG2_PTR_UPDATE	(1 << 10)
+#define		MALI_DP500_DE_STATUS_CONFIG	(1 << 17)
+#define		MALI_DP500_DE_STATUS_PSM	(1 << 18)
+#define		MALI_DP500_DE_STATUS_TEST	(1 << 19)
+#define		MALI_DP500_DE_STATUS_IRQ	(1 << 31)
+
+#define MALI_DP500_REG_DE_MASKIRQ	0x0008
+#define         MALI_DP500_DE_IRQ_UNDERRUN	(1 << 0)
+#define         MALI_DP500_DE_IRQ_AXI_ERR	(1 << 4)
+#define		MALI_DP500_DE_IRQ_PROG_LINE1	(1 << 5)
+#define		MALI_DP500_DE_IRQ_PROG_LINE2	(1 << 6)
+#define		MALI_DP500_DE_IRQ_SAT_ERR	(1 << 7)
+#define		MALI_DP500_DE_IRQ_LV_PTR	(1 << 8)
+#define		MALI_DP500_DE_IRQ_LG1_PTR	(1 << 9)
+#define		MALI_DP500_DE_IRQ_LG2_PTR	(1 << 10)
+#define		MALI_DP500_DE_IRQ_CONF_MODE	(1 << 11)
+#define		MALI_DP500_DE_IRQ_ENABLE	(1 << 31)
+
+#define MALI_DP500_REG_DE_CONTROL	0x000C
+#define		MALI_DP500_DE_PREFETCH_LINE_MASK	0x1fff
+#define		MALI_DP500_DE_PREFETCH_LINE_SHIFT	0
+#define		MALI_DP500_DE_PREFETCH_LINE_SET(x)	\
+	(((x) & MALI_DP500_DE_PREFETCH_LINE_MASK) << MALI_DP500_DE_PREFETCH_LINE_SHIFT)
+#define		MALI_DP500_DE_SOFTRESET_REQ_EN	(1 << 16)
+#define		MALI_DP500_DE_CONF_MODE_REQ_EN	(1 << 17)
+#define		MALI_DP500_DE_PSM_REQ_EN	(1 << 18)
+#define		MALI_DP500_DE_TESTMODE_REQ_EN	(1 << 19)
+#define		MALI_DP500_DE_HSYNC_POL_POS	(1 << 20)
+#define		MALI_DP500_DE_VSYNC_POL_POS	(1 << 21)
+
+#define MALI_DP500_REG_DE_LINE_INT_CTRL		0x0010
+#define		MALI_DP500_DE_AXI_OUTSTDCAPB_MASK	0xff
+#define		MALI_DP500_DE_AXI_OUTSTDCAPB(x)	(((x) & MALI_DP500_DE_AXI_OUTSTDCAPB_MASK) << 0)
+#define		MALI_DP500_DE_AXI_BURSTLEN_MASK	0xff
+#define		MALI_DP500_DE_AXI_BURSTLEN(x)	(((x) & MALI_DP500_DE_AXI_BURSTLEN_MASK) << 16)
+
+#define MALI_DP500_REG_DE_SECURE_CTRL		0x001C
+#define MALI_DP500_REG_DE_H_INTERVALS		0x0028
+#define MALI_DP500_REG_DE_V_INTERVALS		0x002C
+#define MALI_DP500_REG_DE_SYNCWIDTH		0x0030
+#define MALI_DP500_REG_DE_HV_ACTIVESIZE		0x0034
+
+#define MALI_DP500_REG_DE_BG_COLOR_RG		0x003C
+#define		MALI_DP500_DE_BG_COLOR_R(x)	(((x) & 0xfff) << 0)
+#define		MALI_DP500_DE_BG_COLOR_G(x)	(((x) & 0xfff) << 16)
+#define MALI_DP500_REG_DE_BG_COLOR_B		0x0040
+#define		MALI_DP500_DE_BG_COLOR_B(x)	(((x) & 0xfff) << 0)
+
+#define MALI_DP500_DE_COEFTAB_GAMMA	(DE_COEFTAB_TABLE_MASK << DE_COEFTAB_GAMMA_SHIFT)
+#define MALI_DP500_DE_COEFTAB_LV_DEGAMMA	(DE_COEFTAB_TABLE_MASK << 19)
+
+#define MALI_DP500_REG_ID		0x0FD0
+#define MALI_DP500_REG_CFG_VALID	0x0F00
+#define MALI_DP500_REG_DE_BASE		0x0000
+#define MALI_DP500_REG_SE_BASE		(3 * SZ_1K)
+
+#define MALI_DP500_REG_DE_AXI_CTL	0x0014
+#define MALI_DP500_REG_DE_DISP_FUNC	0x0020
+#define MALI_DP500_REG_DE_OD		0x0044
+#define MALI_DP500_REG_DE_COLORCOEFFS 0x0078
+#define MALI_DP500_REG_DE_QOS		0x0500
+#define MALI_DP500_REG_YUV2RGB		0x0048
+
+#define MALI_DP500_REG_SE_CTL		0x000C
+#define MALI_DP500_REG_SE_AXI_CRL	0x0014
+#define MALI_DP500_REG_SE_L_CTL		0x0020
+#define MALI_DP500_REG_SE_SCL_CTL	0x0030
+#define MALI_DP500_REG_SE_ENH_CTL	0x0048
+#define MALI_DP500_REG_SE_COV_CTL	0x0070
+#define MALI_DP500_REG_SE_MW_CTL	0x0200
+
+#define MALI_DP500_LV_BASE	0X0100
+#define MALI_DP500_LG1_BASE	0x0200
+#define MALI_DP500_LG2_BASE	0x0300
+
+#define MALI_DP500_AD_LV_CTRL	0x400
+#define MALI_DP500_AD_LV_CROP_H	0x404
+#define MALI_DP500_AD_LV_CROP_V	0x408
+#define MALI_DP500_AD_LG1_CTRL	0x40C
+#define MALI_DP500_AD_LG1_CROP_H	0x410
+#define MALI_DP500_AD_LG1_CROP_V	0x414
+#define MALI_DP500_AD_LG2_CTRL	0x418
+#define MALI_DP500_AD_LG2_CROP_H	0x41C
+#define MALI_DP500_AD_LG2_CROP_V	0x420
+
+extern const struct malidp_intf_hw_info dp_interfaces[];
+extern const char *const op_mode_name[];
+
+#define SE_N_SCALING_COEFFS_SET 5
+#define SE_N_SCALING_COEFFS_IN_SET	96
+static const u16 dp500_se_scaling_coeffs[SE_N_SCALING_COEFFS_SET][SE_N_SCALING_COEFFS_IN_SET] = {
+	/* SET 0: upscaling, without scaling */
+	{	0x0000, 0x0001, 0x0007, 0x0011, 0x001e, 0x002e, 0x003f, 0x0052,
+		0x0064, 0x0073, 0x007d, 0x0080, 0x007a, 0x006c, 0x0053, 0x002f,
+		0x0000, 0x3fc6, 0x3f83, 0x3f39, 0x3eea, 0x3e9b, 0x3e4f, 0x3e0a,
+		0x3dd4, 0x3db0, 0x3da2, 0x3db1, 0x3dde, 0x3e2f, 0x3ea5, 0x3f40,
+		0x0000, 0x00e5, 0x01ee, 0x0315, 0x0456, 0x05aa, 0x0709, 0x086c,
+		0x09c9, 0x0b15, 0x0c4a, 0x0d5d, 0x0e4a, 0x0f06, 0x0f91, 0x0fe5,
+		0x1000, 0x0fe5, 0x0f91, 0x0f06, 0x0e4a, 0x0d5d, 0x0c4a, 0x0b15,
+		0x09c9, 0x086c, 0x0709, 0x05aa, 0x0456, 0x0315, 0x01ee, 0x00e5,
+		0x0000, 0x3f40, 0x3ea5, 0x3e2f, 0x3dde, 0x3db1, 0x3da2, 0x3db0,
+		0x3dd4, 0x3e0a, 0x3e4f, 0x3e9b, 0x3eea, 0x3f39, 0x3f83, 0x3fc6,
+		0x0000, 0x002f, 0x0053, 0x006c, 0x007a, 0x0080, 0x007d, 0x0073,
+		0x0064, 0x0052, 0x003f, 0x002e, 0x001e, 0x0011, 0x0007, 0x0001
+	},
+	/* SET 1: without scaling, 1.5x down scaling*/
+	{	0x0059, 0x004f, 0x0041, 0x002e, 0x0016, 0x3ffb, 0x3fd9, 0x3fb4,
+		0x3f8c, 0x3f62, 0x3f36, 0x3f09, 0x3edd, 0x3eb3, 0x3e8d, 0x3e6c,
+		0x3e52, 0x3e3f, 0x3e35, 0x3e37, 0x3e46, 0x3e61, 0x3e8c, 0x3ec5,
+		0x3f0f, 0x3f68, 0x3fd1, 0x004a, 0x00d3, 0x0169, 0x020b, 0x02b8,
+		0x036e, 0x042d, 0x04f2, 0x05b9, 0x0681, 0x0745, 0x0803, 0x08ba,
+		0x0965, 0x0a03, 0x0a91, 0x0b0d, 0x0b75, 0x0bc6, 0x0c00, 0x0c20,
+		0x0c28, 0x0c20, 0x0c00, 0x0bc6, 0x0b75, 0x0b0d, 0x0a91, 0x0a03,
+		0x0965, 0x08ba, 0x0803, 0x0745, 0x0681, 0x05b9, 0x04f2, 0x042d,
+		0x036e, 0x02b8, 0x020b, 0x0169, 0x00d3, 0x004a, 0x3fd1, 0x3f68,
+		0x3f0f, 0x3ec5, 0x3e8c, 0x3e61, 0x3e46, 0x3e37, 0x3e35, 0x3e3f,
+		0x3e52, 0x3e6c, 0x3e8d, 0x3eb3, 0x3edd, 0x3f09, 0x3f36, 0x3f62,
+		0x3f8c, 0x3fb4, 0x3fd9, 0x3ffb, 0x0016, 0x002e, 0x0041, 0x004f
+	},
+	/* SET 2: 1.5x down scaling, 2x down scaling */
+	{	0x3f19, 0x3f03, 0x3ef0, 0x3edf, 0x3ed0, 0x3ec5, 0x3ebd, 0x3eb9,
+		0x3eb9, 0x3ebf, 0x3eca, 0x3ed9, 0x3eef, 0x3f0a, 0x3f2c, 0x3f52,
+		0x3f7f, 0x3fb0, 0x3fe8, 0x0026, 0x006a, 0x00b4, 0x0103, 0x0158,
+		0x01b1, 0x020d, 0x026c, 0x02cd, 0x032f, 0x0392, 0x03f4, 0x0455,
+		0x04b4, 0x051e, 0x0585, 0x05eb, 0x064c, 0x06a8, 0x06fe, 0x074e,
+		0x0796, 0x07d5, 0x080c, 0x0839, 0x085c, 0x0875, 0x0882, 0x0887,
+		0x0881, 0x0887, 0x0882, 0x0875, 0x085c, 0x0839, 0x080c, 0x07d5,
+		0x0796, 0x074e, 0x06fe, 0x06a8, 0x064c, 0x05eb, 0x0585, 0x051e,
+		0x04b4, 0x0455, 0x03f4, 0x0392, 0x032f, 0x02cd, 0x026c, 0x020d,
+		0x01b1, 0x0158, 0x0103, 0x00b4, 0x006a, 0x0026, 0x3fe8, 0x3fb0,
+		0x3f7f, 0x3f52, 0x3f2c, 0x3f0a, 0x3eef, 0x3ed9, 0x3eca, 0x3ebf,
+		0x3eb9, 0x3eb9, 0x3ebd, 0x3ec5, 0x3ed0, 0x3edf, 0x3ef0, 0x3f03
+	},
+	/* SET 3: 2x down scaling, 2.75x down scaling */
+	{	0x3f51, 0x3f60, 0x3f71, 0x3f84, 0x3f98, 0x3faf, 0x3fc8, 0x3fe3,
+		0x0000, 0x001f, 0x0040, 0x0064, 0x008a, 0x00b1, 0x00da, 0x0106,
+		0x0133, 0x0160, 0x018e, 0x01bd, 0x01ec, 0x021d, 0x024e, 0x0280,
+		0x02b2, 0x02e4, 0x0317, 0x0349, 0x037c, 0x03ad, 0x03df, 0x0410,
+		0x0440, 0x0468, 0x048f, 0x04b3, 0x04d6, 0x04f8, 0x0516, 0x0533,
+		0x054e, 0x0566, 0x057c, 0x0590, 0x05a0, 0x05ae, 0x05ba, 0x05c3,
+		0x05c9, 0x05c3, 0x05ba, 0x05ae, 0x05a0, 0x0590, 0x057c, 0x0566,
+		0x054e, 0x0533, 0x0516, 0x04f8, 0x04d6, 0x04b3, 0x048f, 0x0468,
+		0x0440, 0x0410, 0x03df, 0x03ad, 0x037c, 0x0349, 0x0317, 0x02e4,
+		0x02b2, 0x0280, 0x024e, 0x021d, 0x01ec, 0x01bd, 0x018e, 0x0160,
+		0x0133, 0x0106, 0x00da, 0x00b1, 0x008a, 0x0064, 0x0040, 0x001f,
+		0x0000, 0x3fe3, 0x3fc8, 0x3faf, 0x3f98, 0x3f84, 0x3f71, 0x3f60
+	},
+	/* SET 4: 2.75x down scaling, 4x down scaling */
+	{	0x0094, 0x00a9, 0x00be, 0x00d4, 0x00ea, 0x0101, 0x0118, 0x012f,
+		0x0148, 0x0160, 0x017a, 0x0193, 0x01ae, 0x01c8, 0x01e4, 0x01ff,
+		0x021c, 0x0233, 0x024a, 0x0261, 0x0278, 0x028f, 0x02a6, 0x02bd,
+		0x02d4, 0x02eb, 0x0302, 0x0319, 0x032f, 0x0346, 0x035d, 0x0374,
+		0x038a, 0x0397, 0x03a3, 0x03af, 0x03bb, 0x03c6, 0x03d1, 0x03db,
+		0x03e4, 0x03ed, 0x03f6, 0x03fe, 0x0406, 0x040d, 0x0414, 0x041a,
+		0x0420, 0x041a, 0x0414, 0x040d, 0x0406, 0x03fe, 0x03f6, 0x03ed,
+		0x03e4, 0x03db, 0x03d1, 0x03c6, 0x03bb, 0x03af, 0x03a3, 0x0397,
+		0x038a, 0x0374, 0x035d, 0x0346, 0x032f, 0x0319, 0x0302, 0x02eb,
+		0x02d4, 0x02bd, 0x02a6, 0x028f, 0x0278, 0x0261, 0x024a, 0x0233,
+		0x021c, 0x01ff, 0x01e4, 0x01c8, 0x01ae, 0x0193, 0x017a, 0x0160,
+		0x0148, 0x012f, 0x0118, 0x0101, 0x00ea, 0x00d4, 0x00be, 0x00a9
+	}
+};
+
+static const u32 malidp_de_bt709_degamma_coeffs[DE_N_COEFTAB_COEFS] = {
+	DE_COEFTAB_DATA(2, 0),
+	DE_COEFTAB_DATA(6, 0),
+	DE_COEFTAB_DATA(11, 2),
+	DE_COEFTAB_DATA(17, 5),
+	DE_COEFTAB_DATA(23, 9),
+	DE_COEFTAB_DATA(30, 15),
+	DE_COEFTAB_DATA(36, 22),
+	DE_COEFTAB_DATA(43, 31),
+	DE_COEFTAB_DATA(50, 42),
+	DE_COEFTAB_DATA(57, 55),
+	DE_COEFTAB_DATA(64, 69),
+	DE_COEFTAB_DATA(72, 85),
+	DE_COEFTAB_DATA(79, 103),
+	DE_COEFTAB_DATA(87, 123),
+	DE_COEFTAB_DATA(95, 145),
+	DE_COEFTAB_DATA(103, 168),
+	DE_COEFTAB_DATA(111, 194),
+	DE_COEFTAB_DATA(119, 222),
+	DE_COEFTAB_DATA(127, 251),
+	DE_COEFTAB_DATA(135, 283),
+	DE_COEFTAB_DATA(144, 317),
+	DE_COEFTAB_DATA(152, 353),
+	DE_COEFTAB_DATA(161, 391),
+	DE_COEFTAB_DATA(169, 431),
+	DE_COEFTAB_DATA(178, 474),
+	DE_COEFTAB_DATA(187, 518),
+	DE_COEFTAB_DATA(195, 565),
+	DE_COEFTAB_DATA(204, 614),
+	DE_COEFTAB_DATA(213, 665),
+	DE_COEFTAB_DATA(222, 718),
+	DE_COEFTAB_DATA(231, 774),
+	DE_COEFTAB_DATA(241, 832),
+	DE_COEFTAB_DATA(250, 892),
+	DE_COEFTAB_DATA(259, 954),
+	DE_COEFTAB_DATA(268, 1019),
+	DE_COEFTAB_DATA(278, 1086),
+	DE_COEFTAB_DATA(287, 1155),
+	DE_COEFTAB_DATA(297, 1227),
+	DE_COEFTAB_DATA(306, 1301),
+	DE_COEFTAB_DATA(316, 1378),
+	DE_COEFTAB_DATA(325, 1457),
+	DE_COEFTAB_DATA(335, 1538),
+	DE_COEFTAB_DATA(345, 1622),
+	DE_COEFTAB_DATA(354, 1708),
+	DE_COEFTAB_DATA(364, 1797),
+	DE_COEFTAB_DATA(374, 1888),
+	DE_COEFTAB_DATA(384, 1981),
+	DE_COEFTAB_DATA(394, 2077),
+	DE_COEFTAB_DATA(404, 2176),
+	DE_COEFTAB_DATA(414, 2277),
+	DE_COEFTAB_DATA(424, 2380),
+	DE_COEFTAB_DATA(434, 2486),
+	DE_COEFTAB_DATA(444, 2595),
+	DE_COEFTAB_DATA(454, 2706),
+	DE_COEFTAB_DATA(464, 2819),
+	DE_COEFTAB_DATA(475, 2936),
+	DE_COEFTAB_DATA(485, 3054),
+	DE_COEFTAB_DATA(495, 3176),
+	DE_COEFTAB_DATA(506, 3299),
+	DE_COEFTAB_DATA(516, 3426),
+	DE_COEFTAB_DATA(527, 3555),
+	DE_COEFTAB_DATA(537, 3687),
+	DE_COEFTAB_DATA(547, 3821),
+	DE_COEFTAB_DATA(558, 3958),
+};
+
+/*
+ * Supported formats are defined so that their index in the array matches
+ * the value for the lx_format field in the LX_FORMAT registers.
+ */
+const u32 malidp500_input_formats[] = {
+	DRM_FORMAT_ARGB2101010,
+	DRM_FORMAT_ABGR2101010,
+	DRM_FORMAT_ARGB8888,
+	DRM_FORMAT_ABGR8888,
+	DRM_FORMAT_XRGB8888,
+	DRM_FORMAT_XBGR8888,
+	DRM_FORMAT_RGB888,
+	DRM_FORMAT_BGR888,
+	DRM_FORMAT_RGBA5551,
+	DRM_FORMAT_ABGR1555,
+	DRM_FORMAT_RGB565,
+	DRM_FORMAT_BGR565,
+	/* Formats below here supported by Video layer only */
+	DRM_FORMAT_UYVY,  /* 1-plane UYVY */
+	DRM_FORMAT_YUYV,  /* 1-plane YUYV */
+	DRM_FORMAT_NV12,  /* YUV 4:2:0 2-plane */
+	DRM_FORMAT_YUV420,/* YUV 4:2:0 3-plane */
+	MALIDP_FORMAT_XYUV, /* [31:0] X:Y:Cb:Cr 8:8:8:8 little endian */
+	MALIDP_FORMAT_VYU30,/* [31:0] X:Cr:Y:Cb 2:10:10:10 little endian */
+	MALIDP_FORMAT_YUV10_420AFBC, /* AFBC compressed YUV 4:2:0, 10 bits per component */
+	MALIDP_FORMAT_NV12AFBC, /* AFBC compressed YUV 4:2:0. Maps to NV12 internally */
+};
+
+const u32 malidp500_output_formats[] = {
+	DRM_FORMAT_ARGB2101010,
+	DRM_FORMAT_ABGR2101010,
+	DRM_FORMAT_ARGB8888,
+	DRM_FORMAT_ABGR8888,
+	DRM_FORMAT_XRGB8888,
+	DRM_FORMAT_XBGR8888,
+	DRM_FORMAT_NV12,
+};
+
+const u32 malidp500_output_format_ids[] = {
+	0,
+	1,
+	2,
+	3,
+	4,
+	5,
+	14,
+};
+
+const u32 malidp500_afbc_formats[] = {
+	DRM_FORMAT_ARGB2101010,
+	DRM_FORMAT_ABGR2101010,
+	DRM_FORMAT_ARGB8888,
+	DRM_FORMAT_ABGR8888,
+	DRM_FORMAT_RGB888,
+	DRM_FORMAT_BGR888,
+	DRM_FORMAT_RGBA5551,
+	DRM_FORMAT_ABGR1555,
+	DRM_FORMAT_RGB565,
+	DRM_FORMAT_BGR565,
+	DRM_FORMAT_UYVY,
+	DRM_FORMAT_YUYV,
+	MALIDP_FORMAT_XYUV,
+	MALIDP_FORMAT_VYU30,
+	MALIDP_FORMAT_YUV10_420AFBC,
+	MALIDP_FORMAT_NV12AFBC
+};
+
+const u32 malidp500_xform_invalid_formats[] = {
+	DRM_FORMAT_RGB888,
+	DRM_FORMAT_BGR888,
+};
+
+/* Define layer information */
+static struct malidp_layer_hw_info dp500_hw_layers[] = {
+	{
+		.index = 0,
+		.name = "Video-1",
+		.type = MALIDP_HW_LAYER_VIDEO,
+		.features = MALIDP_LAYER_FEATURE_TRANSFORM |
+			    MALIDP_LAYER_FEATURE_AFBC |
+			    MALIDP_LAYER_FEATURE_SCALING,
+		.n_supported_formats = ARRAY_SIZE(malidp500_input_formats),
+		.supported_formats = malidp500_input_formats,
+		.n_max_planes = 3,
+		.n_supported_layers = 1,
+		.regs_base = MALI_DP500_LV_BASE,
+		.ad_ctrl_reg = MALI_DP500_AD_LV_CTRL,
+		.ad_crop_h_reg = MALI_DP500_AD_LV_CROP_H,
+		.ad_crop_v_reg = MALI_DP500_AD_LV_CROP_V,
+		.stride_offset = DE_REG_LV1_STRIDE,
+		.ptr0_low_offset = DE_REG_LV1_PTR0_LOW,
+		.ptr0_high_offset = DE_REG_LV1_PTR0_HIGH,
+		.p3_stride_offset = DE_REG_LV3_STRIDE,
+		.yuv2rgb_reg_offset = MALI_DP500_REG_YUV2RGB,
+	},
+	{
+		.index = 1,
+		.name = "Graphics-1",
+		.type = MALIDP_HW_LAYER_GRAPHICS,
+		.features = MALIDP_LAYER_FEATURE_TRANSFORM |
+			    MALIDP_LAYER_FEATURE_AFBC |
+			    MALIDP_LAYER_FEATURE_SCALING,
+		.n_supported_formats = 12,
+		.supported_formats = malidp500_input_formats,
+		.n_max_planes = 1,
+		.n_supported_layers = 1,
+		.regs_base = MALI_DP500_LG1_BASE,
+		.ad_ctrl_reg = MALI_DP500_AD_LG1_CTRL,
+		.ad_crop_h_reg = MALI_DP500_AD_LG1_CROP_H,
+		.ad_crop_v_reg = MALI_DP500_AD_LG1_CROP_V,
+		.stride_offset = DE_REG_LG_STRIDE,
+		.ptr0_low_offset = DE_REG_LG_PTR0_LOW,
+		.ptr0_high_offset = DE_REG_LG_PTR0_HIGH,
+	},
+	{
+		.index = 2,
+		.name = "Graphics-2",
+		.type = MALIDP_HW_LAYER_GRAPHICS,
+		.features = MALIDP_LAYER_FEATURE_TRANSFORM |
+			    MALIDP_LAYER_FEATURE_AFBC,
+		.n_supported_formats = 12,
+		.supported_formats = malidp500_input_formats,
+		.n_max_planes = 1,
+		.n_supported_layers = 1,
+		.regs_base = MALI_DP500_LG2_BASE,
+		.ad_ctrl_reg = MALI_DP500_AD_LG2_CTRL,
+		.ad_crop_h_reg = MALI_DP500_AD_LG2_CROP_H,
+		.ad_crop_v_reg = MALI_DP500_AD_LG2_CROP_V,
+		.stride_offset = DE_REG_LG_STRIDE,
+		.ptr0_low_offset = DE_REG_LG_PTR0_LOW,
+		.ptr0_high_offset = DE_REG_LG_PTR0_HIGH,
+	}
+};
+
+static const struct malidp_hw_regmap malidp500_regmap = {
+	.id_registers = MALI_DP500_REG_ID,
+	.config_valid = MALI_DP500_REG_CFG_VALID,
+	.de_base = MALI_DP500_REG_DE_BASE,
+	.se_base = MALI_DP500_REG_SE_BASE,
+	.de_regmap = {
+		.axi_control = MALI_DP500_REG_DE_AXI_CTL,
+		.disp_func = MALI_DP500_REG_DE_DISP_FUNC,
+		.output_depth = MALI_DP500_REG_DE_OD,
+		.coloradj_coeff = MALI_DP500_REG_DE_COLORCOEFFS,
+		.qos_control = MALI_DP500_REG_DE_QOS
+	},
+	.se_regmap = {
+		.control = MALI_DP500_REG_SE_CTL,
+		.axi_control = MALI_DP500_REG_SE_AXI_CRL,
+		.layers_control = MALI_DP500_REG_SE_L_CTL,
+		.scaling_control = MALI_DP500_REG_SE_SCL_CTL,
+		.enhancer_control = MALI_DP500_REG_SE_ENH_CTL,
+		.conv_control = MALI_DP500_REG_SE_COV_CTL,
+		.mw_control = MALI_DP500_REG_SE_MW_CTL
+	},
+};
+
+/* Declare of product APIs */
+static void dp500_disable_irq(struct malidp_hw_device *);
+static enum malidp_op_mode dp500_change_op_mode(
+		struct malidp_hw_device *,
+		enum malidp_op_mode);
+static int dp500_de_hw_cfg(struct malidp_de_device *);
+static void dp500_de_modeset(struct malidp_de_device *,
+		struct malidp_de_hwmode *);
+static void dp500_de_set_gamma_coeff(struct malidp_de_device *,
+		u32 *coeffs);
+static u32 dp500_de_fmt_fixup(u32 drm_format, u32 flags);
+static irqreturn_t dp500_de_irq_handler(int irq, void *data);
+static int dp500_se_hw_cfg(struct malidp_se_device *);
+static void dp500_se_set_scaler_coeff(struct malidp_se_device *,
+		enum malidp_scaling_coeff_set hcoeff,
+		enum malidp_scaling_coeff_set vcoeff);
+static bool dp500_se_limitation_check(struct malidp_se_device *,
+		struct malidp_se_scaler_conf *);
+static u32 dp500_se_calc_downscaling_threshold(u32, u32,
+		struct drm_mode_modeinfo *);
+static umode_t dp500_attr_visible(struct kobject *obj,
+		struct attribute *attr, int n);
+static bool dp500_de_axi_valid(u32 attr, u32 val);
+static bool dp500_se_axi_valid(u32 attr, u32 val);
+static irqreturn_t dp500_se_irq_handler(int irq, void *data);
+static u32 dp500_rotmem_required(const struct malidp_hw_buffer *hw_buf);
+
+static const struct malidp_product_api dp500_api = {
+	.change_op_mode = dp500_change_op_mode,
+	.disable_irq = dp500_disable_irq,
+	.attr_visible = dp500_attr_visible,
+	.rotmem_size_required = dp500_rotmem_required,
+	.de_api = {
+		.hw_cfg = dp500_de_hw_cfg,
+		.modeset = dp500_de_modeset,
+		.set_gamma_coeff = dp500_de_set_gamma_coeff,
+		.fmt_fixup = dp500_de_fmt_fixup,
+		.axi_valid = dp500_de_axi_valid,
+		.irq_handler = dp500_de_irq_handler,
+	},
+	.se_api = {
+		.hw_cfg = dp500_se_hw_cfg,
+		.set_scaler_coeff = dp500_se_set_scaler_coeff,
+		.limitation_check = dp500_se_limitation_check,
+		.calc_downscaling_threshold = dp500_se_calc_downscaling_threshold,
+		.axi_valid = dp500_se_axi_valid,
+		.irq_handler = dp500_se_irq_handler,
+	}
+};
+
+static struct malidp_hw_topology malidp_dp500_topology = {
+	.product_id = MALIDP_DP500_PRODUCT_ID,
+	.interfaces = dp_interfaces,
+	.n_interfaces = 2,
+	.layers = dp500_hw_layers,
+	.n_layers = ARRAY_SIZE(dp500_hw_layers),
+	.n_scalers = 1,
+	.n_supported_afbc_formats = ARRAY_SIZE(malidp500_afbc_formats),
+	.supported_afbc_formats = malidp500_afbc_formats,
+	.supported_afbc_splitblk = 0,
+	.dp_api = &dp500_api,
+	.regmap = &malidp500_regmap,
+	.n_mw_formats = ARRAY_SIZE(malidp500_output_formats),
+	.mw_formats = malidp500_output_formats,
+	.mw_format_ids = malidp500_output_format_ids,
+	.n_xform_invalid_formats = ARRAY_SIZE(malidp500_xform_invalid_formats),
+	.xform_invalid_formats = malidp500_xform_invalid_formats,
+};
+
+static const struct malidp_line_size_hw_info dp500_ls_configs[] = {
+	{
+		.max_line_size = 2048,
+		.min_line_size = 2,
+		.input_fifo_size = 2048,
+		.default_rotmem_size = 64 * SZ_1K,
+	},
+	{
+		.max_line_size = 4096,
+		.min_line_size = 2,
+		.input_fifo_size = 4096,
+		.default_rotmem_size = 128 * SZ_1K,
+	}
+};
+
+static struct malidp_hw_configuration malidp_hw_dp500_cf = {
+	.ls_configs = dp500_ls_configs,
+	.n_configs = ARRAY_SIZE(dp500_ls_configs),
+	.partition_type = MALIDP_HW_PARTITION_FIXED,
+};
+
+umode_t dp500_attr_visible(struct kobject *obj, struct attribute *attr,
+		int n)
+{
+	const char *hidden_attr_name[] = {
+#ifdef DEBUG
+		"de_poutstdcab",
+#endif
+		NULL /* Last item */
+	};
+	int i = 0;
+
+	/* if attr name is found in hidden list, don't show it */
+	while (hidden_attr_name[i] != NULL) {
+		if (strcmp(attr->name, hidden_attr_name[i]) == 0)
+			return 0;
+		i++;
+	}
+
+	return attr->mode;
+}
+
+void malidp_dp500_get_hw_description(struct malidp_hw_description *hwdes)
+{
+	hwdes->topology = &malidp_dp500_topology;
+	hwdes->config = &malidp_hw_dp500_cf;
+}
+
+static bool dp500_axi_burstlen_valid(u32 val)
+{
+	int i;
+	/* for 1, 2, 4, ... 256 */
+	for (i = 0; i < 9; i++)
+		if (val == (1 << i))
+			break;
+	return (i < 9) ? true : false;
+}
+
+/*
+ * Change the operation mode of the DE;
+ * @dev: pointer to the private malidp device structure.
+ * @new_mode: the mode we want the device to operate.
+ */
+static enum malidp_op_mode
+dp500_de_op_change(struct malidp_de_device *dev,
+	enum malidp_op_mode new_mode)
+{
+	u32 all_modes = MALI_DP500_DE_CONF_MODE_REQ_EN |
+			MALI_DP500_DE_PSM_REQ_EN |
+			MALI_DP500_DE_TESTMODE_REQ_EN;
+	enum malidp_op_mode old_mode = dev->op_mode;
+	u32 status = all_modes;
+	u32 control;
+
+	dev_dbg(dev->device, "performing DE mode change: %s->%s\n",
+		op_mode_name[old_mode], op_mode_name[new_mode]);
+
+	/* Verify that the HW is currently in the mode that we expected */
+	if (likely(old_mode != MALIDP_OP_MODE_UNKNOWN)) {
+		status = malidp_de_read(dev, MALI_DP500_REG_DE_STATUS);
+		if (status & MALI_DP500_DE_STATUS_CONFIG)
+			BUG_ON(old_mode != MALIDP_OP_MODE_CONFIG);
+		else if (status & MALI_DP500_DE_STATUS_PSM)
+			BUG_ON(old_mode != MALIDP_OP_MODE_POWERSAVE);
+		else if (status & MALI_DP500_DE_STATUS_TEST)
+			BUG_ON(old_mode != MALIDP_OP_MODE_TEST);
+		else
+			BUG_ON(old_mode != MALIDP_OP_MODE_NORMAL);
+	}
+
+	if (old_mode == new_mode) {
+		return old_mode;
+	} else if (old_mode == MALIDP_OP_MODE_POWERSAVE) {
+		/*
+		 * Exiting powersave mode, so clear the status register
+		 * and re-enable interrupts
+		 */
+		status = malidp_de_read(dev, MALI_DP500_REG_DE_STATUS);
+		malidp_de_write(dev, status, MALI_DP500_REG_DE_STATUS);
+		malidp_de_setbits(dev, MALI_DP500_DE_IRQ_UNDERRUN |
+					MALI_DP500_DE_IRQ_AXI_ERR |
+					MALI_DP500_DE_IRQ_PROG_LINE1,
+					MALI_DP500_REG_DE_MASKIRQ);
+	}
+
+	/* Unset any previous mode */
+	control = malidp_de_read(dev, MALI_DP500_REG_DE_CONTROL);
+	control &= (~all_modes);
+
+	if (new_mode == MALIDP_OP_MODE_CONFIG) {
+		control |= MALI_DP500_DE_CONF_MODE_REQ_EN;
+	} else if (new_mode == MALIDP_OP_MODE_POWERSAVE) {
+		control |= MALI_DP500_DE_PSM_REQ_EN;
+	} else {
+		dev->scene_changing = false;
+		malidp_hw_commit_scene_atomic(dev->hwdev, true);
+	}
+
+	/* Commit the new mode */
+	malidp_de_write(dev, control, MALI_DP500_REG_DE_CONTROL);
+
+	/*
+	 * Verify the new mode has been applied. We rely on status and control
+	 * registers having the same flags for setting/checking the mode.
+	 */
+	while ((status & all_modes) != (control & all_modes))
+		status = malidp_de_read(dev, MALI_DP500_REG_DE_STATUS);
+
+	if (new_mode == MALIDP_OP_MODE_POWERSAVE) {
+		/*
+		 * Clear the IRQ masks so that we don't get asked to handle
+		 * interrupts which happen in the future.
+		 * We can't just clear the global mask because this prevents
+		 * IRQ line from getting cleared.
+		 */
+		malidp_de_clearbits(dev, MALI_DP500_DE_IRQ_UNDERRUN |
+				MALI_DP500_DE_IRQ_AXI_ERR |
+				MALI_DP500_DE_IRQ_PROG_LINE1,
+				MALI_DP500_REG_DE_MASKIRQ);
+		/*
+		 * If an IRQ has happened whilst changing mode, we must handle
+		 * it (because the GIC has already seen it), without touching
+		 * registers (because we're about to turn the clocks off), so
+		 * we store the status register for use by our IRQ handler.
+		 */
+		dev->pending_status = status;
+		/* Clear any interrupt flags */
+		malidp_de_write(dev, status, MALI_DP500_REG_DE_STATUS);
+	}
+
+	dev->op_mode = new_mode;
+
+	dev_dbg(dev->device, "DE mode change ok: %s->%s\n",
+		op_mode_name[old_mode], op_mode_name[new_mode]);
+
+	return old_mode;
+}
+
+/*
+ * Change the operation mode of the SE and return the old value;
+ * @dev: pointer to the private malidp device structure.
+ * @new_mode: the mode we want the device to operate.
+ */
+static enum malidp_op_mode
+dp500_se_op_change(struct malidp_se_device *dev,
+	enum malidp_op_mode new_mode)
+{
+	u16 reg_control = malidp500_regmap.se_regmap.control;
+	u32 status;
+	enum malidp_op_mode old_mode = dev->op_mode;;
+
+	dev_dbg(dev->device, "performing SE mode change: %s->%s\n",
+		op_mode_name[old_mode], op_mode_name[new_mode]);
+
+	/* Verify that the HW is currently in the mode that we expected */
+	if (likely(old_mode != MALIDP_OP_MODE_UNKNOWN)) {
+		status = malidp_se_read(dev, SE_REG_STATUS);
+		/* This order is important. PSM has highest priority */
+		if (status & SE_ST_PSM_ACTIVE)
+			BUG_ON(old_mode != MALIDP_OP_MODE_POWERSAVE);
+		else if (status & SE_ST_CONFIG_ACTIVE)
+			BUG_ON(old_mode != MALIDP_OP_MODE_CONFIG);
+		else
+			BUG_ON(old_mode != MALIDP_OP_MODE_NORMAL);
+	}
+
+	if (old_mode == new_mode) {
+		return old_mode;
+	} else if (old_mode == MALIDP_OP_MODE_POWERSAVE) {
+		/*
+		 * Exiting powersave mode, so clear the status register
+		 * and re-enable interrupts
+		 */
+		status = malidp_se_read(dev, SE_REG_STATUS);
+		malidp_se_write(dev, status, SE_REG_STATUS);
+		malidp_se_setbits(dev, SE_IRQ_OVERRUN | SE_IRQ_AXI_ERR |
+			SE_IRQ_PROGLINE1 | SE_IRQ_PTR_UPDATE, SE_REG_MASKIRQ);
+	}
+
+	if (new_mode == MALIDP_OP_MODE_CONFIG) {
+		malidp_se_setbits(dev, SE_CONFIG_REQ, reg_control);
+	} else if (new_mode == MALIDP_OP_MODE_NORMAL) {
+		malidp_se_clearbits(dev, SE_CONFIG_REQ, reg_control);
+	} else if (new_mode == MALIDP_OP_MODE_POWERSAVE) {
+		/*
+		 * POWERSAVE mode is controlled by the DE, but we will enter
+		 * config mode here, so that we can guarantee all processing
+		 * is finished
+		 */
+		malidp_se_setbits(dev, SE_CONFIG_REQ, reg_control);
+		do {
+			status = malidp_se_read(dev, SE_REG_STATUS);
+		} while (!(status & SE_ST_CONFIG_ACTIVE));
+		/*
+		 * Clear the IRQ masks so that we don't get asked to handle
+		 * interrupts which happen in the future.
+		 * We can't just clear the global mask because this prevents
+		 * IRQ line from getting cleared.
+		 */
+		malidp_se_clearbits(dev, SE_IRQ_OVERRUN | SE_IRQ_AXI_ERR |
+			SE_IRQ_PROGLINE1 | SE_IRQ_PTR_UPDATE, SE_REG_MASKIRQ);
+		/*
+		 * If an IRQ has happened whilst changing mode, we must handle
+		 * it (because the GIC has already seen it) without touching
+		 * registers (because we're about to turn the clocks off) so
+		 * we store the status register for use by our IRQ handler.
+		 */
+		dev->pending_status = status;
+		/* Clear any interrupt flags */
+		malidp_se_write(dev, status, SE_REG_STATUS);
+	}
+
+	dev->op_mode = new_mode;
+
+	dev_dbg(dev->device, "SE mode change ok: %s\n", op_mode_name[new_mode]);
+
+	return old_mode;
+}
+
+static irqreturn_t dp500_de_irq_handler(int irq, void *data)
+{
+struct malidp_de_device *dev = data;
+	u32 status, irq_mask, irq_vector;
+	unsigned long flags;
+	struct malidp_hw_event event;
+
+	spin_lock_irqsave(dev->hw_lock, flags);
+
+	/* Drop any events if we already went to powersave */
+	if (unlikely(dev->op_mode == MALIDP_OP_MODE_POWERSAVE)) {
+		status = dev->pending_status;
+		dev->pending_status = 0;
+		spin_unlock_irqrestore(dev->hw_lock, flags);
+		return status & MALI_DP500_DE_STATUS_IRQ ? IRQ_HANDLED :
+			IRQ_NONE;
+	}
+
+	status = malidp_de_read(dev, MALI_DP500_REG_DE_STATUS);
+	irq_mask = malidp_de_read(dev, MALI_DP500_REG_DE_MASKIRQ);
+	irq_vector = status & irq_mask;
+
+	/* The IRQ does not belong to this device */
+	if (!(status & MALI_DP500_DE_STATUS_IRQ)) {
+		spin_unlock_irqrestore(dev->hw_lock, flags);
+		return IRQ_NONE;
+	}
+
+	/* Get the timestamp as soon as possible for more accuracy */
+	event.timestamp = ktime_get();
+	event.type = MALIDP_HW_EVENT_NONE;
+
+	if (irq_vector & MALI_DP500_DE_IRQ_UNDERRUN) {
+		dev_err(dev->device, "%s: underrun error\n", __func__);
+		event.type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_URUN;
+	}
+
+	if (irq_vector & MALI_DP500_DE_IRQ_AXI_ERR) {
+		dev_err(dev->device, "%s: axi error\n", __func__);
+		event.type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_AXI;
+	}
+
+	/* If there was a pointer update this is flip event. Otherwise
+	 * this is only a regular vsync.
+	 */
+	if (irq_vector &  MALI_DP500_DE_IRQ_PROG_LINE1) {
+		event.type |= MALIDP_HW_EVENT_VSYNC;
+		if ((status & MALI_DP500_DE_LV_PTR_UPDATE) ||
+		    (status & MALI_DP500_DE_LG1_PTR_UPDATE) ||
+		    (status & MALI_DP500_DE_LG2_PTR_UPDATE)) {
+			event.type |= MALIDP_HW_EVENT_NEWCFG;
+			if (dev->scene_changing) {
+				event.type |= MALIDP_HW_EVENT_FLIP;
+				dev->scene_changing = false;
+			}
+		}
+	}
+
+	/* IRQs not enabled should not be triggered */
+	BUG_ON((irq_vector & MALI_DP500_DE_IRQ_PROG_LINE2) ||
+		(irq_vector & MALI_DP500_DE_IRQ_LV_PTR) ||
+		(irq_vector & MALI_DP500_DE_IRQ_LG1_PTR) ||
+		(irq_vector & MALI_DP500_DE_IRQ_LG2_PTR) ||
+		(irq_vector & MALI_DP500_DE_IRQ_SAT_ERR) ||
+		(irq_vector & MALI_DP500_DE_IRQ_CONF_MODE));
+
+	/* There must always be a valid event if the IRQ is triggered */
+	BUG_ON(event.type == MALIDP_HW_EVENT_NONE);
+
+	/* Disable the offending error IRQ if there was an error */
+	if (event.type & MALIDP_HW_EVENT_ERROR) {
+		uint32_t mask_bits = irq_vector &
+				(MALI_DP500_DE_IRQ_UNDERRUN |
+				MALI_DP500_DE_IRQ_AXI_ERR);
+		malidp_de_clearbits(dev, mask_bits, MALI_DP500_REG_DE_MASKIRQ);
+	}
+
+	/* Clear the status register */
+	malidp_de_write(dev, status, MALI_DP500_REG_DE_STATUS);
+
+	/* If there's a new scene, re-enable the error interrupts */
+	if (event.type & MALIDP_HW_EVENT_FLIP) {
+		uint32_t mask_bits = (MALI_DP500_DE_IRQ_UNDERRUN |
+					MALI_DP500_DE_IRQ_AXI_ERR);
+		if ((mask_bits & irq_mask) != mask_bits)
+			malidp_de_setbits(dev, mask_bits, MALI_DP500_REG_DE_MASKIRQ);
+	}
+
+	malidp_hw_event_queue_enqueue(dev->ev_queue, &event);
+
+	spin_unlock_irqrestore(dev->hw_lock, flags);
+
+	return IRQ_WAKE_THREAD;
+}
+
+static irqreturn_t dp500_se_irq_handler(int irq, void *data)
+{
+	struct malidp_se_device *dev = data;
+	u32 status, irq_mask, irq_vector;
+	unsigned long flags;
+	struct malidp_hw_event event;
+
+	spin_lock_irqsave(dev->hw_lock, flags);
+
+	/* Drop any events if we already went to powersave */
+	if (unlikely(dev->op_mode == MALIDP_OP_MODE_POWERSAVE)) {
+		status = dev->pending_status;
+		dev->pending_status = 0;
+		spin_unlock_irqrestore(dev->hw_lock, flags);
+		return status & SE_ST_IRQ ? IRQ_HANDLED : IRQ_NONE;
+	}
+
+	status = malidp_se_read(dev, SE_REG_STATUS);
+	malidp_se_write(dev, status, SE_REG_STATUS);
+
+	irq_mask = malidp_se_read(dev, SE_REG_MASKIRQ);
+	irq_vector = status & irq_mask;
+
+	/* The IRQ does not belong to this device */
+	if (!(status & SE_ST_IRQ)) {
+		spin_unlock_irqrestore(dev->hw_lock, flags);
+		return IRQ_NONE;
+	}
+
+	dev_dbg(dev->device, "%s: start\n", __func__);
+
+	/* IRQs not enabled should not be triggered */
+	BUG_ON(irq_vector & SE_IRQ_CONFIG);
+
+	/* Get the timestamp as soon as possible for more accuracy */
+	event.timestamp = ktime_get();
+	event.type = MALIDP_HW_EVENT_NONE;
+
+	if (irq_vector & SE_IRQ_OVERRUN) {
+		dev_err(dev->device, "%s: overrun error\n", __func__);
+		event.type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_ORUN;
+	}
+
+	if (irq_vector & SE_IRQ_AXI_ERR) {
+		dev_err(dev->device, "%s: axi error\n", __func__);
+		event.type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_AXI;
+	}
+
+	/*
+	 * The init busy signal occurs in HW some cycles before the global
+	 * valid, which means we can use the IRQ handler for SE_IRQ_PTR_UPDATE
+	 * to check the status for SE_ST_INIT_BUSY.
+	 */
+	if (irq_vector & SE_IRQ_PTR_UPDATE) {
+		if (status & SE_ST_INIT_BUSY &&
+		    (malidp_se_read(dev, SE_REG_STATUS) & SE_ST_AXI_BUSY)) {
+			dev_err(dev->device, "%s: init busy error\n",
+				__func__);
+			event.type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_IBUSY;
+		}
+
+		event.type |= MALIDP_HW_EVENT_NEWCFG;
+		if (!dev->scene_changing)
+			event.type |= MALIDP_HW_EVENT_STOP;
+	}
+
+	/*
+	 * Prog line 1 means mw interface has begun to write out. Disable the
+	 * interface so that it does not write when the next frame period
+	 * starts.
+	 */
+	if (irq_vector &  SE_IRQ_PROGLINE1) {
+		struct malidp_se_mw_conf cfg = {
+			.mode = MALIDP_SE_MW_DISABLE,
+		};
+		dev_dbg(dev->device, "%s: disable memory interface\n", __func__);
+		malidp_se_cfg_processing(dev, &cfg, NULL);
+		malidp_hw_cfg_de_disable_mw_flows_atomic(dev->hwdev);
+
+		malidp_hw_commit_scene_atomic(dev->hwdev, true);
+
+		event.type |= MALIDP_HW_EVENT_START;
+
+		if (dev->scene_changing) {
+			event.type |= MALIDP_HW_EVENT_FLIP;
+			dev->scene_changing = false;
+		}
+	}
+
+	/* There must always be a valid event if the IRQ is triggered */
+	BUG_ON(event.type == MALIDP_HW_EVENT_NONE);
+
+	/* Disable the offending interrupts if there was an error */
+	if (event.type & MALIDP_HW_EVENT_ERROR) {
+		uint32_t mask_bits = irq_vector & (SE_IRQ_OVERRUN | SE_IRQ_AXI_ERR);
+		malidp_se_clearbits(dev, mask_bits, SE_REG_MASKIRQ);
+	}
+
+	/* If we're starting a new frame then re-enable error interrupts */
+	if (event.type & MALIDP_HW_EVENT_FLIP) {
+		uint32_t mask_bits = (SE_IRQ_OVERRUN | SE_IRQ_AXI_ERR);
+		if ((mask_bits & irq_mask) != mask_bits)
+			malidp_se_setbits(dev, mask_bits, SE_REG_MASKIRQ);
+	}
+
+	malidp_hw_event_queue_enqueue(dev->ev_queue, &event);
+
+	dev_dbg(dev->device, "%s: end\n", __func__);
+
+	spin_unlock_irqrestore(dev->hw_lock, flags);
+
+	return IRQ_WAKE_THREAD;
+}
+
+static u32 dp500_choose_scaling_coeffset(
+	enum malidp_scaling_coeff_set coeffset)
+{
+	u32 i = 4;
+
+	switch (coeffset) {
+	case MALIDP_UPSCALING_COEFFS:
+	case MALIDP_DOWNSCALING_1_5_COEFFS:
+	case MALIDP_DOWNSCALING_2_COEFFS:
+	case MALIDP_DOWNSCALING_2_75_COEFFS:
+	case MALIDP_DOWNSCALING_4_COEFFS:
+	  i = (u32)coeffset;
+		break;
+	default:
+		BUG();
+	}
+	return i;
+}
+
+static void dp500_se_writing_pp_coeffstab(
+		struct malidp_se_device *dev,
+		u32 orientation, u16 addr, u16 coeffs_set)
+{
+	int i;
+	u16 scl_reg = dev->se_regmap->scaling_control;
+
+	malidp_se_write(dev, orientation |
+		((addr) & SE_COEFFTAB_ADDR_MASK),
+		scl_reg + SE_REG_COEFFTAB_ADDR);
+	for (i = 0; i < SE_N_SCALING_COEFFS_IN_SET; i++)
+		malidp_se_write(dev, SE_SET_COEFFTAB_DATA(
+				dp500_se_scaling_coeffs[coeffs_set][i]),
+			 scl_reg + SE_REG_COEFFTAB_DATA);
+}
+
+/* Implementation of product APIs */
+static bool dp500_de_axi_valid(u32 attr, u32 val)
+{
+	switch (attr) {
+	case MALIDP_ATTR_DE_BURSTLEN:
+		return dp500_axi_burstlen_valid(val);
+	case MALIDP_ATTR_DE_OUTSTRAN:
+		if ((val < 1) || (val > 32))
+			return false;
+		break;
+	case MALIDP_ATTR_DE_POUTSTDCAB:
+		if (val != 0)
+			return false;
+		break;
+	default:
+		BUG();
+	}
+
+	return true;
+}
+
+static bool dp500_se_axi_valid(u32 attr, u32 val)
+{
+	switch (attr) {
+	case MALIDP_ATTR_SE_BURSTLEN:
+		return dp500_axi_burstlen_valid(val);
+	case MALIDP_ATTR_SE_OUTSTRAN:
+		if ((val < 1) || (val > 32))
+			return false;
+		break;
+	case MALIDP_ATTR_SE_WCACHE:
+		if (val > 15)
+			return false;
+		break;
+	default:
+		BUG();
+	}
+
+	return true;
+}
+
+static u32 dp500_rotmem_required(const struct malidp_hw_buffer *hw_buf)
+{
+	u32 bpp = malidp_hw_format_bpp(hw_buf->fmt);
+	/*
+	* The available rotation memory for each layer must be
+	* big enough to fit 8 lines worth of rotated,
+	* uncompressed, pixel data
+	*
+	* This memory used by a layer can be calculated
+	* (in bytes) for a paritucular pixel format as:
+	* size = (rotated_width * bits_per_pixel * 8) / 8
+	*
+	* We multiply by 8 for number of lines but
+	* we also divide by 8 for converting bits to bytes.
+	* These 2 cancel out meaning the final calculation is:
+	* size_in_bytes = rotated_width * bits_per_pixel
+	*/
+	return hw_buf->cmp_rect.src_w * bpp;
+}
+
+
+void dp500_disable_irq(struct malidp_hw_device *hwdev)
+{
+	malidp_hw_write(hwdev, 0,
+		hwdev->hw_regmap->se_base + SE_REG_MASKIRQ);
+	malidp_hw_write(hwdev, 0,
+		hwdev->hw_regmap->de_base + MALI_DP500_REG_DE_MASKIRQ);
+}
+
+enum malidp_op_mode dp500_change_op_mode(
+		struct malidp_hw_device *hwdev,
+		enum malidp_op_mode mode)
+{
+	unsigned long flags;
+	enum malidp_op_mode old_mode_de, old_mode_se;
+
+	BUG_ON(mode == MALIDP_OP_MODE_UNKNOWN);
+
+	/* We're protected by the power mutex, so just read the mode */
+	old_mode_de = malidp_de_get_op_mode(hwdev->de_dev);
+	if (old_mode_de == mode)
+		return old_mode_de;
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+
+	/* if old mode is unknown, device should be soft-reset */
+	if (old_mode_de == MALIDP_OP_MODE_UNKNOWN) {
+		malidp_se_setbits(hwdev->se_dev, SE_SOFTRESET_REQ,
+					malidp500_regmap.se_regmap.control);
+		malidp_de_setbits(hwdev->de_dev, MALI_DP500_DE_SOFTRESET_REQ_EN,
+					MALI_DP500_REG_DE_CONTROL);
+	}
+
+
+	/*
+	 * Changing the SE first is always the safest option, but the mode
+	 * change will not take effect until the DE exits powersave mode
+	 */
+	old_mode_se = dp500_se_op_change(hwdev->se_dev, mode);
+	dp500_de_op_change(hwdev->de_dev, mode);
+
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+
+	BUG_ON(old_mode_de != old_mode_se);
+
+	return old_mode_de;
+}
+
+static int dp500_de_hw_cfg(struct malidp_de_device *de_dev)
+{
+	extern const u32 malidp_de_bt709_degamma_coeffs[];
+
+	/* Set AXI configuration */
+	if (!malidp_de_attr_valid(de_dev, MALIDP_ATTR_DE_OUTSTRAN,
+				de_dev->outstran)) {
+		dev_warn(de_dev->device, "%s : invalid value '%d' for de_axi_outstran\n",
+			__func__, de_dev->outstran);
+		de_dev->outstran = DE_DEFAULT_AXI_OUTSTRAN;
+	}
+	if (!malidp_de_attr_valid(de_dev, MALIDP_ATTR_DE_BURSTLEN,
+			de_dev->burstlen)) {
+		dev_warn(de_dev->device, "%s : invalid value '%d' for de_axi_burstlen\n",
+			__func__, de_dev->burstlen);
+		de_dev->burstlen = DE_DEFAULT_AXI_BURSTLEN;
+	}
+	malidp_de_set_axi_cfg(de_dev, de_dev->outstran, 0, de_dev->burstlen);
+
+	/* Initialize the ARQOS settings */
+	malidp_de_init_axi_qos(de_dev,
+			de_dev->arqos_threshold_low,
+			de_dev->arqos_threshold_high,
+			de_dev->arqos_red,
+			de_dev->arqos_green);
+
+
+	/* Set default background */
+	malidp_de_write(de_dev, MALI_DP500_DE_BG_COLOR_R(DE_FIXED_BG_R) |
+			MALI_DP500_DE_BG_COLOR_G(DE_FIXED_BG_G),
+			MALI_DP500_REG_DE_BG_COLOR_RG);
+	malidp_de_write(de_dev, MALI_DP500_DE_BG_COLOR_B(DE_FIXED_BG_B),
+			MALI_DP500_REG_DE_BG_COLOR_B);
+
+	/* Set prefetch_line to default value */
+	malidp_de_clearbits(de_dev,
+		MALI_DP500_DE_PREFETCH_LINE_MASK << MALI_DP500_DE_PREFETCH_LINE_SHIFT,
+		MALI_DP500_REG_DE_CONTROL);
+	malidp_de_setbits(de_dev,
+		MALI_DP500_DE_PREFETCH_LINE_SET(DE_DEFAULT_PREFETCH_LINE),
+		MALI_DP500_REG_DE_CONTROL);
+
+	/*
+	 * We are always interested on getting an IRQ as soon as a frame begins
+	 * to be scanned out.
+	 */
+	malidp_de_write(de_dev, DE_LINE_INT_1(DE_DEFAULT_PREFETCH_LINE),
+			MALI_DP500_REG_DE_LINE_INT_CTRL);
+	malidp_de_write(de_dev, MALI_DP500_DE_IRQ_UNDERRUN |
+			MALI_DP500_DE_IRQ_AXI_ERR |
+			MALI_DP500_DE_IRQ_PROG_LINE1 |
+			MALI_DP500_DE_IRQ_ENABLE, MALI_DP500_REG_DE_MASKIRQ);
+
+	/* Write alpha lookup tables */
+	malidp_de_write_alpha_lookup(de_dev);
+
+	/* Set the Video layer inverse-gamma coefficients */
+	malidp_de_set_coeftab(de_dev, MALI_DP500_DE_COEFTAB_LV_DEGAMMA,
+			malidp_de_bt709_degamma_coeffs);
+
+	/* Always enable dithering */
+	malidp_de_setbits(de_dev, DE_DITH_EN, MALI_DP500_REG_DE_DISP_FUNC);
+
+	/* Disable all the layers so we don't scan out any stale config */
+	malidp_de_disable_all_layers(de_dev);
+
+	malidp_de_cleanup_yuv2rgb_coeffs(de_dev);
+
+	dev_dbg(de_dev->device, "%s : success!\n", __func__);
+	return 0;
+}
+
+static void dp500_de_modeset(struct malidp_de_device *de_dev,
+		struct malidp_de_hwmode *hwmode)
+{
+	malidp_de_write(de_dev, DE_H_FRONTPORCH(hwmode->hfp) |
+			DE_H_BACKPORCH(hwmode->hbp),
+			MALI_DP500_REG_DE_H_INTERVALS);
+	malidp_de_write(de_dev, DE_V_FRONTPORCH(hwmode->vfp) |
+			DE_V_BACKPORCH(hwmode->vbp),
+			MALI_DP500_REG_DE_V_INTERVALS);
+	malidp_de_write(de_dev, DE_H_SYNCWIDTH(hwmode->hsw) |
+			DE_V_SYNCWIDTH(hwmode->vsw),
+			MALI_DP500_REG_DE_SYNCWIDTH);
+	malidp_de_write(de_dev, DE_H_ACTIVE(hwmode->h_active) |
+			DE_V_ACTIVE(hwmode->v_active),
+			MALI_DP500_REG_DE_HV_ACTIVESIZE);
+
+	if (hwmode->hsync_pol_pos)
+		malidp_de_setbits(de_dev, MALI_DP500_DE_HSYNC_POL_POS,
+					MALI_DP500_REG_DE_CONTROL);
+	else
+		malidp_de_clearbits(de_dev, MALI_DP500_DE_HSYNC_POL_POS,
+					MALI_DP500_REG_DE_CONTROL);
+
+	if (hwmode->vsync_pol_pos)
+		malidp_de_setbits(de_dev, MALI_DP500_DE_VSYNC_POL_POS,
+					MALI_DP500_REG_DE_CONTROL);
+	else
+		malidp_de_clearbits(de_dev, MALI_DP500_DE_VSYNC_POL_POS,
+					MALI_DP500_REG_DE_CONTROL);
+}
+
+static u32 dp500_de_fmt_fixup(u32 drm_format, u32 flags)
+{
+	if (flags & MALIDP_FLAG_AFBC) {
+		switch (drm_format) {
+		case MALIDP_FORMAT_NV12AFBC:
+			/*
+			 * This format is only used for buffer dimension
+			 * validation, and needs to be transformed to the
+			 * generic version to be written to the HW
+			 */
+			drm_format = DRM_FORMAT_NV12;
+			break;
+		}
+	}
+	return drm_format;
+}
+
+static int dp500_se_hw_cfg(struct malidp_se_device *se_dev)
+{
+	u32 status;
+
+	/*
+	 * Make sure we're in CFM first. The HW layer should make sure the
+	 * DE is not in PSM for this to succeed
+	 */
+	do {
+		status = malidp_se_read(se_dev, SE_REG_STATUS);
+	} while (!(status & SE_ST_CONFIG_ACTIVE));
+
+	/* Set AXI configuration */
+	if (!malidp_se_attr_valid(se_dev, MALIDP_ATTR_SE_OUTSTRAN,
+				  se_dev->outstran)) {
+		dev_warn(se_dev->device, "%s : invalid value '%d' for se_axi_outstran\n",
+			 __func__, se_dev->outstran);
+		se_dev->outstran = SE_DEFAULT_AXI_OUTSTRAN;
+	}
+	if (!malidp_se_attr_valid(se_dev, MALIDP_ATTR_SE_BURSTLEN,
+				  se_dev->burstlen)) {
+		dev_warn(se_dev->device, "%s : invalid value '%d' for se_axi_burstlen\n",
+			 __func__, se_dev->burstlen);
+		se_dev->burstlen = SE_DEFAULT_AXI_BURSTLEN;
+	}
+	if (!malidp_se_attr_valid(se_dev, MALIDP_ATTR_SE_WCACHE,
+				  se_dev->wcache)) {
+		dev_warn(se_dev->device, "%s : invalid value '%d' for se_axi_awcache\n",
+			 __func__, se_dev->wcache);
+		se_dev->wcache = SE_DEFAULT_AXI_AWCACHE;
+	}
+	if (!malidp_se_attr_valid(se_dev, MALIDP_ATTR_SE_WQOS,
+				  se_dev->wqos)) {
+		dev_warn(se_dev->device, "%s : invalid value '%d' for se_axi_awqos\n",
+			 __func__, se_dev->wqos);
+		se_dev->wqos = SE_DEFAULT_AXI_AWQOS;
+	}
+	malidp_se_set_axi_cfg(se_dev, se_dev->outstran,
+			se_dev->burstlen,
+			se_dev->wcache,
+			se_dev->wqos);
+
+	/* Set initial image enhancer state */
+	se_dev->enh_cfg = MALIDP_SE_ENHANCER_OFF;
+	malidp_se_clearbits(se_dev, SE_ENH_H_EN | SE_ENH_V_EN,
+			MALI_DP500_REG_SE_CTL);
+	malidp_se_write(se_dev, SE_SET_ENH_LIMIT_LOW(SE_ENH_LOW_LEVEL) |
+			SE_SET_ENH_LIMIT_HIGH(SE_ENH_HIGH_LEVEL),
+			malidp500_regmap.se_regmap.enhancer_control);
+
+	/*
+	 * We get an IRQ as soon as a frame starts to be written to memory and
+	 * when config valid is latched by the init signal.
+	 */
+	malidp_se_write(se_dev, SE_LINE_INT_1(0), SE_REG_LINE_INT_CTRL);
+	malidp_se_write(se_dev, SE_IRQ_OVERRUN | SE_IRQ_AXI_ERR |
+			SE_IRQ_PROGLINE1 | SE_IRQ_ENABLE | SE_IRQ_PTR_UPDATE,
+			SE_REG_MASKIRQ);
+
+	se_dev->rgb2yuv_coeffs = NULL;
+	se_dev->v_coeffstab = 0xffff;
+	se_dev->h_coeffstab = 0xffff;
+
+	dev_dbg(se_dev->device, "%s: success!\n", __func__);
+	return 0;
+}
+
+static void dp500_de_set_gamma_coeff(struct malidp_de_device *de_dev, u32 *coeffs)
+{
+	malidp_de_set_coeftab(de_dev, MALI_DP500_DE_COEFTAB_GAMMA,
+				coeffs);
+}
+
+static void dp500_se_set_scaler_coeff(struct malidp_se_device *se_dev,
+		enum malidp_scaling_coeff_set hcoeff,
+		enum malidp_scaling_coeff_set vcoeff)
+{
+	u32 h = dp500_choose_scaling_coeffset(hcoeff);
+	u32 v = dp500_choose_scaling_coeffset(vcoeff);
+
+	if ((h == v) && (hcoeff != se_dev->h_coeffstab ||
+		vcoeff != se_dev->v_coeffstab)) {
+		se_dev->h_coeffstab = hcoeff;
+		se_dev->v_coeffstab = vcoeff;
+
+		dp500_se_writing_pp_coeffstab(se_dev,
+			(SE_V_COEFFTAB | SE_H_COEFFTAB), 0, v);
+	} else {
+		if (se_dev->v_coeffstab != vcoeff) {
+			se_dev->v_coeffstab = vcoeff;
+
+			dp500_se_writing_pp_coeffstab(se_dev,
+				SE_V_COEFFTAB, 0, v);
+		}
+
+		if (se_dev->h_coeffstab != hcoeff) {
+			se_dev->h_coeffstab = hcoeff;
+
+			dp500_se_writing_pp_coeffstab(se_dev,
+				SE_H_COEFFTAB, 0, h);
+		}
+	}
+}
+
+static bool dp500_se_limitation_check(struct malidp_se_device *se_dev,
+		struct malidp_se_scaler_conf *s0)
+{
+	bool ret = true;
+	struct malidp_hw_device *hwdev = se_dev->hwdev;
+	struct drm_mode_modeinfo mode;
+	unsigned long flags;
+	unsigned long mclk =
+		clk_get_rate(hwdev->mclk) / 100; /* 10KHz*/
+	unsigned long pxclk =
+		clk_get_rate(hwdev->pxclk) / 1000; /* KHz*/
+	unsigned long input_size = s0->input_w * s0->input_h;
+	unsigned long a;
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+	malidp_de_modeget(hwdev->de_dev, &mode);
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+
+	/*
+	 * Equation:
+	 *	a = 1.5*(h_input_size*v_input_size) /
+	 *		(h_total_size*v_output_size)
+	 *
+	 *	mclk = a*pxclk if a >= 1.5
+	 *			or
+	 *	mclk = 1.5*pxclk if a < 1.5
+	 *
+	 *	To avoid float calculaiton, using 15
+	 *	instead of 1.5, and 10Khz is
+	 *	measurement unit of mclk.
+	*/
+	a = 15 * input_size /
+		(mode.htotal * s0->output_h);
+	if (a < 15)
+		a = 15;
+	if (mclk < a * pxclk) {
+		dev_err(hwdev->device,
+			"%s: Clock ratio (mclk/pxclk) is not high enough for downscale factor.",
+			__func__);
+		ret = false;
+	}
+
+	return ret;
+}
+
+static u32 dp500_se_calc_downscaling_threshold(u32 mclk, u32 pxlclk,
+		struct drm_mode_modeinfo *mode)
+{
+	u64 mclk64 = mclk;
+
+	/* if mclk/pxlclk < 1.5, returns 0 */
+	mclk64 = mclk64 * 2;
+	pxlclk = pxlclk * 3;
+	if (mclk64 < pxlclk) {
+		return 0;
+	}
+
+	mclk64 *= mode->htotal;
+
+	/* factor is (16.16) fix point */
+	mclk64 <<= 16;
+	do_div(mclk64, pxlclk);
+
+	return mclk64;
+}
+
diff --git a/drivers/video/adf/arm/product/malidp_product_dp550.c b/drivers/video/adf/arm/product/malidp_product_dp550.c
new file mode 100644
index 0000000..4f5653c
--- /dev/null
+++ b/drivers/video/adf/arm/product/malidp_product_dp550.c
@@ -0,0 +1,1154 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/fs.h>
+
+#include "malidp_product_api.h"
+#include <uapi/video/malidp_adf.h>
+
+#define MALI_DP550_REG_DE_STATUS	0x0000
+#define		MALI_DP550_DE_IRQ_UNR	(1 << 0)
+#define		MALI_DP550_DE_IRQ_SAT	(1 << 8)
+#define		MALI_DP550_DE_IRQ_PL1	(1 << 12)
+#define		MALI_DP550_DE_IRQ_PL2	(1 << 13)
+#define		MALI_DP550_DE_AXIE	(1 << 16)
+
+#define MALI_DP550_REG_DE_IRQ_MSK	0x0008
+#define MALI_DP550_REG_DE_IRQ_CLR	0x000C
+#define MALI_DP550_REG_DE_CTRL		0x0010
+#define		DP550_PREFETCH_LINE_MASK	0x3ff
+#define		DP550_PREFETCH_LINE_SET(x)	\
+		((x) & DP550_PREFETCH_LINE_MASK)
+
+#define MALI_DP550_REG_LINE_INT_CTRL	0x0014
+
+#define MALI_DP550_REG_H_INTERVALS	0x0030
+#define MALI_DP550_REG_V_INTERVALS	0x0034
+#define MALI_DP550_REG_SYNC_CTRL	0x0038
+#define		MALI_DP550_VSP	(1 << 28)
+#define		MALI_DP550_HSP	(1 << 12)
+#define MALI_DP550_REG_HV_ACT_SIZE	0x003C
+#define MALI_DP550_REG_BG_COLOR		0x0044
+
+#define MALI_DP550_REG_ID			0xFFD0
+#define MALI_DP550_REG_CFG_VALID	0xC014
+#define MALI_DP550_REG_DE_BASE		0x0000
+#define MALI_DP550_REG_SE_BASE		0x8000
+
+#define MALI_DP550_REG_DE_AXI_CTL	0x0018
+#define MALI_DP550_REG_DE_QOS       0x001C
+#define MALI_DP550_REG_DE_DISP_FUNC	0x0020
+#define		MALI_DP550_COPROC_EN	(1 << 12)
+#define MALI_DP550_REG_DE_OD		0x004C
+#define MALI_DP550_REG_DE_COLORCOEFFS 0x0050
+#define MALI_DP550_DE_COEFTAB_GAMMA	(1 << DE_COEFTAB_GAMMA_SHIFT)
+
+#define MALI_DP550_REG_LV1_YUV2RGB	0x0184
+#define MALI_DP550_REG_LV2_YUV2RGB	0x0284
+
+#define MALI_DP550_REG_SE_IRQ_CLR	0x000C
+#define MALI_DP550_REG_SE_CTL		0x0010
+#define		MALI_DP550_SE_CTL_OFM	(1 << 7)
+#define		MALI_DP550_SE_CTL_xSEL_MASK	7
+#define		MALI_DP550_SE_CTL_VCSEL(x)	(((x) & MALI_DP550_SE_CTL_xSEL_MASK) << 20)
+#define		MALI_DP550_SE_CTL_HCSEL(x)	(((x) & MALI_DP550_SE_CTL_xSEL_MASK) << 16)
+#define MALI_DP550_REG_SE_PL		0x0014
+#define		MALI_DP550_SE_PL_LINE_MASK	0x1fff
+#define		MALI_DP550_SE_PL_LINE(x)	(((x) & MALI_DP550_SE_PL_LINE_MASK) << 0)
+#define		MALI_DP550_SE_PL_INTERVAL_MASK	0x3ff
+#define		MALI_DP550_SE_PL_INTERVAL(x)	(((x) & MALI_DP550_SE_PL_INTERVAL_MASK) << 16)
+#define MALI_DP550_REG_SE_AXI_CRL	0x0018
+#define MALI_DP550_REG_SE_L_CTL		0x0024
+#define MALI_DP550_REG_SE_SCL_CTL	0x0034
+#define MALI_DP550_REG_SE_ENH_CTL	0x004C
+#define MALI_DP550_REG_SE_COV_CTL	0x0074
+#define MALI_DP550_REG_SE_MW_CTL	0x0100
+
+#define MALI_DP550_REG_DC_STATUS	0xC000
+#define		MALI_DP550_DC_IRQ_CVAL	(1 << 0)
+#define		MALI_DP550_DC_IRQ_CM	(1 << 4)
+#define		MALI_DP550_DC_IRQDE	(1 << 20)
+#define		MALI_DP550_DC_IRQSE	(1 << 24)
+#define MALI_DP550_REG_DC_IRQ_SET	0xC004
+#define MALI_DP550_REG_DC_IRQ_MSK	0xC008
+#define MALI_DP550_REG_DC_IRQ_CLR	0xC00C
+#define MALI_DP550_REG_DC_CTRL		0xC010
+#define		MALI_DP550_DC_CM	(1 << 16)
+#define		MALI_DP550_DC_CRST	(1 << 17)
+
+#define MALI_DP550_LV1_BASE		0x0100
+#define MALI_DP550_LV2_BASE		0x0200
+#define MALI_DP550_LG1_BASE		0x0300
+#define MALI_DP550_LS1_BASE		0x0400
+
+#define MALI_DP550_LV1_AD_CTRL	0x01B8
+#define MALI_DP550_LV1_AD_H_CROP	0x01BC
+#define MALI_DP550_LV1_AD_V_CROP	0x01C0
+#define MALI_DP550_LV2_AD_CTRL	0x02B8
+#define MALI_DP550_LV2_AD_H_CROP	0x02BC
+#define MALI_DP550_LV2_AD_V_CROP	0x02C0
+#define MALI_DP550_LG1_AD_CTRL	0x0330
+#define MALI_DP550_LG1_AD_H_CROP	0x0334
+#define MALI_DP550_LG1_AD_V_CROP	0x0338
+
+#define MALI_DP550_SE_IRQ_EOW	(1 << 0)
+#define MALI_DP550_SE_IRQ_PL	(1 << 12)
+#define MALI_DP550_SE_IRQ_PI	(1 << 13)
+
+#define MALI_DP550_SE_AXIE	(1 << 16)
+#define MALI_DP550_SE_OVR	(1 << 17)
+#define MALI_DP550_SE_IBUSY	(1 << 18)
+
+#define MALIDP_FORMAT_ID(__group, __format) ((((__group) & 0x7) << 3) | \
+		(((__format) & 0x7) << 0))
+#define N_RGB_INPUT_FORMATS 18
+
+#define SMART_INPUT_FORMAT_START_IDX 4
+#define N_SMART_INPUT_FORMATS        8
+#define N_SUPPORTED_SMART_LAYERS     4
+
+extern const char *const op_mode_name[];
+extern const struct malidp_intf_hw_info dp_interfaces[];
+
+const u32 malidp550_input_formats[] = {
+	DRM_FORMAT_ARGB2101010,
+	DRM_FORMAT_ABGR2101010,
+	DRM_FORMAT_RGBA1010102,
+	DRM_FORMAT_BGRA1010102,
+	DRM_FORMAT_ARGB8888,
+	DRM_FORMAT_ABGR8888,
+	DRM_FORMAT_RGBA8888,
+	DRM_FORMAT_BGRA8888,
+	DRM_FORMAT_XRGB8888,
+	DRM_FORMAT_XBGR8888,
+	DRM_FORMAT_RGBX8888,
+	DRM_FORMAT_BGRX8888,
+	DRM_FORMAT_RGB888,
+	DRM_FORMAT_BGR888,
+	DRM_FORMAT_RGBA5551,
+	DRM_FORMAT_ABGR1555,
+	DRM_FORMAT_RGB565,
+	DRM_FORMAT_BGR565,
+	/* Formats below here supported by Video layers only */
+	MALIDP_FORMAT_XYUV, /* [31:0] X:Y:Cb:Cr 8:8:8:8 little endian */
+	MALIDP_FORMAT_NV16AFBC, /* AFBC compressed YUV 4:2:2 */
+	DRM_FORMAT_YUYV,  /* YUV 4:2:2 1-plane */
+	DRM_FORMAT_UYVY,  /* YUV 4:2:2 1-plane */
+	DRM_FORMAT_NV12,  /* YUV 4:2:0 2-plane */
+	DRM_FORMAT_YUV420,/* YUV 4:2:0 3-plane */
+	MALIDP_FORMAT_VYU30, /* [31:0] X:Cr:Y:Cb 2:10:10:10 little endian */
+	MALIDP_FORMAT_Y0L2, /* ARM Linear 10-bit packed YUV 4:2:0 */
+	MALIDP_FORMAT_P010, /* 10-bit YUV 4:2:0 2-plane */
+	/* AFBC formats which map to non-compressed format IDs */
+	MALIDP_FORMAT_NV12AFBC, /* Included for backwards-compatibility only. Maps to NV12 */
+	MALIDP_FORMAT_YUV10_420AFBC, /* AFBC compressed YUV 4:2:0, 10 bits per component */
+};
+
+/* We can use the same list for all the input formats */
+const u32 malidp550_input_format_ids[] = {
+	MALIDP_FORMAT_ID(0, 0),
+	MALIDP_FORMAT_ID(0, 1),
+	MALIDP_FORMAT_ID(0, 2),
+	MALIDP_FORMAT_ID(0, 3),
+	MALIDP_FORMAT_ID(1, 0),
+	MALIDP_FORMAT_ID(1, 1),
+	MALIDP_FORMAT_ID(1, 2),
+	MALIDP_FORMAT_ID(1, 3),
+	MALIDP_FORMAT_ID(2, 0),
+	MALIDP_FORMAT_ID(2, 1),
+	MALIDP_FORMAT_ID(2, 2),
+	MALIDP_FORMAT_ID(2, 3),
+	MALIDP_FORMAT_ID(3, 0),
+	MALIDP_FORMAT_ID(3, 1),
+	MALIDP_FORMAT_ID(4, 0),
+	MALIDP_FORMAT_ID(4, 1),
+	MALIDP_FORMAT_ID(4, 2),
+	MALIDP_FORMAT_ID(4, 3),
+	/* Start YUV formats */
+	MALIDP_FORMAT_ID(5, 0),
+	MALIDP_FORMAT_ID(5, 1),
+	MALIDP_FORMAT_ID(5, 2),
+	MALIDP_FORMAT_ID(5, 3),
+	MALIDP_FORMAT_ID(5, 6),
+	MALIDP_FORMAT_ID(5, 7),
+	MALIDP_FORMAT_ID(6, 0),
+	MALIDP_FORMAT_ID(6, 6),
+	MALIDP_FORMAT_ID(6, 7),
+	/* AFBC formats which map to non-compressed format IDs */
+	MALIDP_FORMAT_ID(5, 6),
+	MALIDP_FORMAT_ID(6, 7),
+};
+
+const u32 malidp550_output_formats[] = {
+	DRM_FORMAT_ARGB2101010,
+	DRM_FORMAT_ABGR2101010,
+	DRM_FORMAT_RGBA1010102,
+	DRM_FORMAT_BGRA1010102,
+	DRM_FORMAT_ARGB8888,
+	DRM_FORMAT_ABGR8888,
+	DRM_FORMAT_RGBA8888,
+	DRM_FORMAT_BGRA8888,
+	DRM_FORMAT_XRGB8888,
+	DRM_FORMAT_XBGR8888,
+	DRM_FORMAT_RGBX8888,
+	DRM_FORMAT_BGRX8888,
+	DRM_FORMAT_RGB888,
+	DRM_FORMAT_BGR888,
+	DRM_FORMAT_NV12,  /* YUV 4:2:0 2-plane */
+};
+
+const u32 malidp550_output_format_ids[] = {
+	MALIDP_FORMAT_ID(0, 0),
+	MALIDP_FORMAT_ID(0, 1),
+	MALIDP_FORMAT_ID(0, 2),
+	MALIDP_FORMAT_ID(0, 3),
+	MALIDP_FORMAT_ID(1, 0),
+	MALIDP_FORMAT_ID(1, 1),
+	MALIDP_FORMAT_ID(1, 2),
+	MALIDP_FORMAT_ID(1, 3),
+	MALIDP_FORMAT_ID(2, 0),
+	MALIDP_FORMAT_ID(2, 1),
+	MALIDP_FORMAT_ID(2, 2),
+	MALIDP_FORMAT_ID(2, 3),
+	MALIDP_FORMAT_ID(3, 0),
+	MALIDP_FORMAT_ID(3, 1),
+	MALIDP_FORMAT_ID(5, 6),
+};
+
+const u32 malidp550_afbc_formats[] = {
+	DRM_FORMAT_ARGB2101010,
+	DRM_FORMAT_ABGR2101010,
+	DRM_FORMAT_RGBA1010102,
+	DRM_FORMAT_BGRA1010102,
+	DRM_FORMAT_ARGB8888,
+	DRM_FORMAT_ABGR8888,
+	DRM_FORMAT_RGBA8888,
+	DRM_FORMAT_BGRA8888,
+	DRM_FORMAT_RGB888,
+	DRM_FORMAT_BGR888,
+	DRM_FORMAT_RGBA5551,
+	DRM_FORMAT_ABGR1555,
+	DRM_FORMAT_RGB565,
+	DRM_FORMAT_BGR565,
+	MALIDP_FORMAT_XYUV,
+	MALIDP_FORMAT_NV16AFBC,
+	DRM_FORMAT_YUYV,
+	DRM_FORMAT_UYVY,
+	MALIDP_FORMAT_VYU30,
+	MALIDP_FORMAT_NV12AFBC,
+	MALIDP_FORMAT_YUV10_420AFBC,
+};
+
+const u32 malidp550_xform_invalid_formats[] = {
+	DRM_FORMAT_RGB888,
+	DRM_FORMAT_BGR888,
+	MALIDP_FORMAT_Y0L2,
+};
+
+/*
+ * Format name				Block split support
+ * DRM_FORMAT_ABGR2101010		Yes
+ * DRM_FORMAT_ABGR8888			Yes
+ * DRM_FORMAT_BGR888			Yes
+ * DRM_FORMAT_RGBA5551			No
+ * DRM_FORMAT_RGB565			No
+ * MALIDP_FORMAT_XYUV			Yes
+ * MALIDP_FORMAT_NV16AFBC		No
+ * MALIDP_FORMAT_NV12AFBC		No
+ * MALIDP_FORMAT_VYU30			Yes
+ * MALIDP_FORMAT_YUV10_420AFBC	Yes
+*/
+#define MALIDP_AFBC_SPLIBLK_BITS 0x1443FF
+
+/* Define layer information */
+static struct malidp_layer_hw_info dp550_hw_layers[] = {
+	{
+		.index = 0,
+		.name = "Video-1",
+		.type = MALIDP_HW_LAYER_VIDEO,
+		.features = MALIDP_LAYER_FEATURE_TRANSFORM |
+			    MALIDP_LAYER_FEATURE_AFBC |
+			    MALIDP_LAYER_FEATURE_SCALING |
+			    MALIDP_LAYER_FEATURE_SRGB,
+		.n_supported_formats = ARRAY_SIZE(malidp550_input_formats),
+		.supported_formats = malidp550_input_formats,
+		.format_ids = malidp550_input_format_ids,
+		.n_max_planes = 3,
+		.n_supported_layers = 1,
+		.regs_base = MALI_DP550_LV1_BASE,
+		.ad_ctrl_reg = MALI_DP550_LV1_AD_CTRL,
+		.ad_crop_h_reg = MALI_DP550_LV1_AD_H_CROP,
+		.ad_crop_v_reg = MALI_DP550_LV1_AD_V_CROP,
+		.stride_offset = DE_REG_LV1_STRIDE,
+		.ptr0_low_offset = DE_REG_LV1_PTR0_LOW,
+		.ptr0_high_offset = DE_REG_LV1_PTR0_HIGH,
+		 /* The stride register for plane 3 is unused on DP550 */
+		.p3_stride_offset = 0,
+		.yuv2rgb_reg_offset = MALI_DP550_REG_LV1_YUV2RGB,
+	},
+	{
+		.index = 1,
+		.name = "Graphics-1",
+		.type = MALIDP_HW_LAYER_GRAPHICS,
+		.features = MALIDP_LAYER_FEATURE_TRANSFORM |
+			    MALIDP_LAYER_FEATURE_AFBC |
+			    MALIDP_LAYER_FEATURE_SCALING |
+			    MALIDP_LAYER_FEATURE_SRGB,
+		.n_supported_formats = N_RGB_INPUT_FORMATS,
+		.supported_formats = malidp550_input_formats,
+		.format_ids = malidp550_input_format_ids,
+		.n_max_planes = 1,
+		.n_supported_layers = 1,
+		.regs_base = MALI_DP550_LG1_BASE,
+		.ad_ctrl_reg = MALI_DP550_LG1_AD_CTRL,
+		.ad_crop_h_reg = MALI_DP550_LG1_AD_H_CROP,
+		.ad_crop_v_reg = MALI_DP550_LG1_AD_V_CROP,
+		.stride_offset = DE_REG_LG_STRIDE,
+		.ptr0_low_offset = DE_REG_LG_PTR0_LOW,
+		.ptr0_high_offset = DE_REG_LG_PTR0_HIGH,
+	},
+	{
+		.index = 2,
+		.name = "Video-2",
+		.type = MALIDP_HW_LAYER_VIDEO,
+		.features = MALIDP_LAYER_FEATURE_TRANSFORM |
+			    MALIDP_LAYER_FEATURE_AFBC |
+			    MALIDP_LAYER_FEATURE_SCALING |
+			    MALIDP_LAYER_FEATURE_SRGB,
+		.n_supported_formats = ARRAY_SIZE(malidp550_input_formats),
+		.supported_formats = malidp550_input_formats,
+		.format_ids = malidp550_input_format_ids,
+		.n_max_planes = 3,
+		.n_supported_layers = 1,
+		.regs_base = MALI_DP550_LV2_BASE,
+		.ad_ctrl_reg = MALI_DP550_LV2_AD_CTRL,
+		.ad_crop_h_reg = MALI_DP550_LV2_AD_H_CROP,
+		.ad_crop_v_reg = MALI_DP550_LV2_AD_V_CROP,
+		.stride_offset = DE_REG_LV1_STRIDE,
+		.ptr0_low_offset = DE_REG_LV1_PTR0_LOW,
+		.ptr0_high_offset = DE_REG_LV1_PTR0_HIGH,
+		 /* The stride register for plane 3 is unused on DP550 */
+		.p3_stride_offset = 0,
+		.yuv2rgb_reg_offset = MALI_DP550_REG_LV2_YUV2RGB,
+	},
+	{
+		.index = 3,
+		.name = "Smart-1",
+		.type = MALIDP_HW_LAYER_SMART,
+		.features = MALIDP_LAYER_FEATURE_SRGB,
+		.n_supported_formats = N_SMART_INPUT_FORMATS,
+		.supported_formats = &malidp550_input_formats[SMART_INPUT_FORMAT_START_IDX],
+		.format_ids = &malidp550_input_format_ids[SMART_INPUT_FORMAT_START_IDX],
+		.n_max_planes = 1,
+		.n_supported_layers = N_SUPPORTED_SMART_LAYERS,
+		.regs_base = MALI_DP550_LS1_BASE,
+		.ls_r1_in_size = DE_REG_LS_R1_IN_SIZE,
+		.ls_r1_offset = DE_REG_LS_R1_OFFSET,
+		.ls_r1_stride = DE_REG_LS_R1_STRIDE,
+		.ls_r1_ptr_low = DE_REG_LS_R1_PTR_LOW,
+		.ls_r1_ptr_high = DE_REG_LS_R1_PTR_HIGH,
+	},
+};
+
+static const struct malidp_hw_regmap malidp550_regmap = {
+	.id_registers = MALI_DP550_REG_ID,
+	.config_valid = MALI_DP550_REG_CFG_VALID,
+	.de_base = MALI_DP550_REG_DE_BASE,
+	.se_base = MALI_DP550_REG_SE_BASE,
+	.de_regmap = {
+		.axi_control = MALI_DP550_REG_DE_AXI_CTL,
+		.disp_func = MALI_DP550_REG_DE_DISP_FUNC,
+		.output_depth = MALI_DP550_REG_DE_OD,
+		.coloradj_coeff = MALI_DP550_REG_DE_COLORCOEFFS,
+		.qos_control = MALI_DP550_REG_DE_QOS
+	},
+	.se_regmap = {
+		.control = MALI_DP550_REG_SE_CTL,
+		.axi_control = MALI_DP550_REG_SE_AXI_CRL,
+		.layers_control = MALI_DP550_REG_SE_L_CTL,
+		.scaling_control = MALI_DP550_REG_SE_SCL_CTL,
+		.enhancer_control = MALI_DP550_REG_SE_ENH_CTL,
+		.conv_control = MALI_DP550_REG_SE_COV_CTL,
+		.mw_control = MALI_DP550_REG_SE_MW_CTL
+	},
+};
+
+/* Declare of DP550 API */
+static void dp550_disable_irq(struct malidp_hw_device *);
+static enum malidp_op_mode dp550_change_op_mode(
+		struct malidp_hw_device *,
+		enum malidp_op_mode);
+static int dp550_de_hw_cfg(struct malidp_de_device *);
+static void dp550_de_modeset(struct malidp_de_device *,
+		struct malidp_de_hwmode *);
+static void dp550_de_set_gamma_coeff(struct malidp_de_device *,
+		u32 *coeffs);
+static u32 dp550_de_fmt_fixup(u32 drm_format, u32 flags);
+static irqreturn_t dp550_de_irq_handler(int irq, void *data);
+static int dp550_se_hw_cfg(struct malidp_se_device *);
+static void dp550_se_set_scaler_coeff(struct malidp_se_device *,
+		enum malidp_scaling_coeff_set hcoeff,
+		enum malidp_scaling_coeff_set vcoeff);
+static bool dp550_se_limitation_check(struct malidp_se_device *,
+		struct malidp_se_scaler_conf *);
+static u32 dp550_se_calc_downscaling_threshold(u32, u32,
+		struct drm_mode_modeinfo *);
+static umode_t dp550_attr_visible(struct kobject *obj,
+		struct attribute *attr, int n);
+static void dp550_debugfs(struct malidp_hw_device *);
+static bool dp550_de_axi_valid(u32 attr, u32 val);
+static bool dp550_se_axi_valid(u32 attr, u32 val);
+static irqreturn_t dp550_se_irq_handler(int irq, void *data);
+static u32 dp550_rotmem_required(const struct malidp_hw_buffer *hw_buf);
+
+static const struct malidp_product_api dp550_api = {
+	.change_op_mode = dp550_change_op_mode,
+	.disable_irq = dp550_disable_irq,
+	.attr_visible = dp550_attr_visible,
+	.debugfs_func = dp550_debugfs,
+	.rotmem_size_required = dp550_rotmem_required,
+	.de_api = {
+		.hw_cfg = dp550_de_hw_cfg,
+		.modeset = dp550_de_modeset,
+		.set_gamma_coeff = dp550_de_set_gamma_coeff,
+		.fmt_fixup = dp550_de_fmt_fixup,
+		.axi_valid = dp550_de_axi_valid,
+		.irq_handler = dp550_de_irq_handler,
+	},
+	.se_api = {
+		.hw_cfg = dp550_se_hw_cfg,
+		.set_scaler_coeff = dp550_se_set_scaler_coeff,
+		.limitation_check = dp550_se_limitation_check,
+		.calc_downscaling_threshold = dp550_se_calc_downscaling_threshold,
+		.axi_valid = dp550_se_axi_valid,
+		.irq_handler = dp550_se_irq_handler,
+	}
+};
+
+struct malidp_hw_topology malidp_dp550_topology = {
+	.product_id = MALIDP_DP550_PRODUCT_ID,
+	.interfaces = dp_interfaces,
+	.n_interfaces = 2,
+	.layers = dp550_hw_layers,
+	.n_layers = ARRAY_SIZE(dp550_hw_layers),
+	.n_scalers = 1,
+	.n_supported_afbc_formats = ARRAY_SIZE(malidp550_afbc_formats),
+	.supported_afbc_formats = malidp550_afbc_formats,
+	.supported_afbc_splitblk = MALIDP_AFBC_SPLIBLK_BITS,
+	.n_mw_formats = ARRAY_SIZE(malidp550_output_formats),
+	.mw_formats = malidp550_output_formats,
+	.mw_format_ids = malidp550_output_format_ids,
+	.n_xform_invalid_formats = ARRAY_SIZE(malidp550_xform_invalid_formats),
+	.xform_invalid_formats = malidp550_xform_invalid_formats,
+	.dp_api = &dp550_api,
+	.regmap = &malidp550_regmap,
+};
+
+static const struct malidp_line_size_hw_info dp550_ls_configs[] = {
+	{
+		.max_line_size = 2048,
+		.min_line_size = 2,
+		.input_fifo_size = 4096,
+		.default_rotmem_size = 128 * SZ_1K,
+	},
+	{
+		.max_line_size = 4096,
+		.min_line_size = 2,
+		.input_fifo_size = 8192,
+		.default_rotmem_size = 256 * SZ_1K,
+	},
+	{
+		.max_line_size = 1280,
+		.min_line_size = 2,
+		.input_fifo_size = 2560,
+		.default_rotmem_size = 80 * SZ_1K,
+	},
+};
+
+static struct malidp_hw_configuration malidp_hw_dp550_cf = {
+	.ls_configs = dp550_ls_configs,
+	.n_configs = ARRAY_SIZE(dp550_ls_configs),
+	.partition_type = MALIDP_HW_PARTITION_FIXED,
+};
+
+umode_t dp550_attr_visible(struct kobject *obj,
+	struct attribute *attr, int n)
+{
+	/* so far DP550 shows all attributes */
+	return attr->mode;
+}
+
+void malidp_dp550_get_hw_description(struct malidp_hw_description *hwdes)
+{
+	hwdes->topology = &malidp_dp550_topology;
+	hwdes->config = &malidp_hw_dp550_cf;
+}
+
+static int coproc_set(void *data, u64 val)
+{
+	struct malidp_hw_device *hwdev = data;
+	bool b = (val != 0) ? true : false;
+	enum malidp_op_mode curr_mode;
+
+	if (hwdev->cproc_en == b)
+		return 0;
+
+	curr_mode = malidp_de_get_op_mode(hwdev->de_dev);
+	if (curr_mode == MALIDP_OP_MODE_POWERSAVE) {
+		dev_err(hwdev->device,
+			"%s:Couldn't set co-processor enable bit in power save mode",
+			__func__);
+		return -EFAULT;
+	}
+
+	hwdev->cproc_en = b;
+	if (b)
+		malidp_hw_setbits(hwdev,
+				  MALI_DP550_COPROC_EN,
+				  MALI_DP550_REG_DE_DISP_FUNC);
+	else
+		malidp_hw_clearbits(hwdev,
+				    MALI_DP550_COPROC_EN,
+				    MALI_DP550_REG_DE_DISP_FUNC);
+	return 0;
+}
+
+static int coproc_get(void *data, u64 *val)
+{
+	struct malidp_hw_device *hwdev = data;
+
+	*val = (u8)hwdev->cproc_en;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(f_ops_coproc, coproc_get, coproc_set, "0x%02llx\n");
+
+static void dp550_debugfs(struct malidp_hw_device *hwdev)
+{
+	struct dentry *dbg_coproc;
+
+	dbg_coproc = debugfs_create_file("coprocessor", S_IRUSR | S_IWUSR,
+			hwdev->dbg_folder, hwdev, &f_ops_coproc);
+	if (dbg_coproc == NULL)
+		dev_err(hwdev->device,
+			"debugfs coprocessor is created error!\n");
+}
+
+static bool dp550_axi_burstlen_valid(u32 val)
+{
+	int i;
+
+	/* for 8, 16, 32, 64 */
+	for (i = 3; i < 7; i++)
+		if (val == (1 << i))
+			break;
+	return (i < 7) ? true : false;
+}
+
+static irqreturn_t dp550_de_irq_handler(int irq, void *data)
+{
+	struct malidp_de_device *dev = data;
+	u32 status, irq_mask, irq_vector, dc_status;
+	unsigned long flags;
+	struct malidp_hw_event event;
+
+	spin_lock_irqsave(dev->hw_lock, flags);
+
+	/* Drop any events if we already went to powersave */
+	if (dev->op_mode == MALIDP_OP_MODE_POWERSAVE) {
+		status = dev->pending_status;
+		dev->pending_status = 0;
+		spin_unlock_irqrestore(dev->hw_lock, flags);
+		return status & MALI_DP550_DC_IRQDE ? IRQ_HANDLED : IRQ_NONE;
+	}
+
+	dc_status = malidp_hw_read(dev->hwdev, MALI_DP550_REG_DC_STATUS);
+	/* The IRQ does not belong to this device */
+	if (!(dc_status & MALI_DP550_DC_IRQDE)) {
+		spin_unlock_irqrestore(dev->hw_lock, flags);
+		return IRQ_NONE;
+	}
+
+	status = malidp_de_read(dev, MALI_DP550_REG_DE_STATUS);
+	irq_mask = malidp_de_read(dev, MALI_DP550_REG_DE_IRQ_MSK);
+	irq_vector = status & irq_mask;
+
+	/* Get the timestamp as soon as possible for more accuracy */
+	event.timestamp = ktime_get();
+	event.type = MALIDP_HW_EVENT_NONE;
+
+	if (irq_vector & MALI_DP550_DE_IRQ_UNR) {
+		dev_err(dev->device, "%s: underrun error\n", __func__);
+		event.type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_URUN;
+
+		/* Check if this underrun was caused by AXI error */
+		if (status & MALI_DP550_DE_AXIE) {
+			dev_err(dev->device, "%s: axi error\n", __func__);
+			event.type |= MALIDP_HW_ERROR_AXI;
+		}
+	}
+
+	/* If there was a pointer update this is flip event. Otherwise
+	 * this is only a regular vsync.
+	 */
+	if (irq_vector &  MALI_DP550_DE_IRQ_PL1) {
+		event.type |= MALIDP_HW_EVENT_VSYNC;
+		if (dc_status & MALI_DP550_DC_IRQ_CVAL) {
+			event.type |= MALIDP_HW_EVENT_FLIP;
+			dev->scene_changing = false;
+			malidp_hw_write(dev->hwdev, MALI_DP550_DC_IRQ_CVAL,
+					MALI_DP550_REG_DC_IRQ_CLR);
+		}
+	}
+
+	/* IRQs not enabled should not be triggered */
+	BUG_ON((irq_vector & MALI_DP550_DE_IRQ_PL2) ||
+		(irq_vector & MALI_DP550_DE_IRQ_SAT));
+
+	/* There must always be a valid event if the IRQ is triggered */
+	BUG_ON(event.type == MALIDP_HW_EVENT_NONE);
+
+	/* Disable the offending error IRQ if there was an error */
+	if (event.type & MALIDP_HW_EVENT_ERROR)
+		malidp_de_clearbits(dev, MALI_DP550_DE_IRQ_UNR,
+			MALI_DP550_REG_DE_IRQ_MSK);
+
+	/* Clear IRQ */
+	malidp_de_write(dev, status, MALI_DP550_REG_DE_IRQ_CLR);
+
+	/* If there's a new scene, re-enable the error interrupts */
+	if (event.type & MALIDP_HW_EVENT_FLIP) {
+		uint32_t mask_bits = MALI_DP550_DE_IRQ_UNR;
+		if ((mask_bits & irq_mask) != mask_bits)
+			malidp_de_setbits(dev, mask_bits, MALI_DP550_REG_DE_IRQ_MSK);
+	}
+
+	malidp_hw_event_queue_enqueue(dev->ev_queue, &event);
+
+	spin_unlock_irqrestore(dev->hw_lock, flags);
+
+	return IRQ_WAKE_THREAD;
+}
+
+static irqreturn_t dp550_se_irq_handler(int irq, void *data)
+{
+	struct malidp_se_device *dev = data;
+	u32 status, irq_mask, irq_vector, dc_status;
+	unsigned long flags;
+	struct malidp_hw_event event;
+
+	spin_lock_irqsave(dev->hw_lock, flags);
+
+	/* Drop any events if we already went to powersave */
+	if (dev->op_mode == MALIDP_OP_MODE_POWERSAVE) {
+		status = dev->pending_status;
+		dev->pending_status = 0;
+		spin_unlock_irqrestore(dev->hw_lock, flags);
+		return status & MALI_DP550_DC_IRQSE ? IRQ_HANDLED : IRQ_NONE;
+	}
+
+	dc_status = malidp_hw_read(dev->hwdev, MALI_DP550_REG_DC_STATUS);
+	/* The IRQ does not belong to this device */
+	if (!(dc_status & MALI_DP550_DC_IRQSE)) {
+		spin_unlock_irqrestore(dev->hw_lock, flags);
+		return IRQ_NONE;
+	}
+
+	status = malidp_se_read(dev, SE_REG_STATUS);
+	irq_mask = malidp_se_read(dev, SE_REG_MASKIRQ);
+	irq_vector = status & irq_mask;
+
+	dev_dbg(dev->device, "%s: start\n", __func__);
+
+	/* IRQs not enabled should not be triggered */
+	BUG_ON(irq_vector & MALI_DP550_SE_IRQ_PI);
+
+	/* Get the timestamp as soon as possible for more accuracy */
+	event.timestamp = ktime_get();
+	event.type = MALIDP_HW_EVENT_NONE;
+
+	if (status & MALI_DP550_SE_OVR) {
+		dev_err(dev->device, "%s: overrun error\n", __func__);
+		event.type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_ORUN;
+	}
+
+	if (status & MALI_DP550_SE_AXIE) {
+		dev_err(dev->device, "%s: axi error\n", __func__);
+		event.type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_AXI;
+	}
+
+	if (status & MALI_DP550_SE_IBUSY) {
+		dev_err(dev->device, "%s: init busy error\n", __func__);
+		event.type |= MALIDP_HW_EVENT_ERROR | MALIDP_HW_ERROR_IBUSY;
+	}
+
+	/*
+	 * Prog line 1 means mw interface has begun to write out. Disable the
+	 * interface so that it does not write when the next frame period
+	 * starts.
+	 */
+	if (irq_vector &  MALI_DP550_SE_IRQ_PL) {
+		event.type |= MALIDP_HW_EVENT_START;
+
+		if (dev->scene_changing) {
+			event.type |= MALIDP_HW_EVENT_FLIP;
+			dev->scene_changing = false;
+		}
+	}
+
+	if (irq_vector & MALI_DP550_SE_IRQ_EOW) {
+		event.type |= MALIDP_HW_EVENT_STOP;
+	}
+
+	malidp_hw_event_queue_enqueue(dev->ev_queue, &event);
+
+	/* Clear interrupts */
+	malidp_se_write(dev, irq_vector, MALI_DP550_REG_SE_IRQ_CLR);
+
+	dev_dbg(dev->device, "%s: end\n", __func__);
+
+	spin_unlock_irqrestore(dev->hw_lock, flags);
+
+	return IRQ_WAKE_THREAD;
+}
+
+/* Implementation of DP550 API */
+static bool dp550_de_axi_valid(u32 attr, u32 val)
+{
+	switch (attr) {
+	case MALIDP_ATTR_DE_BURSTLEN:
+		return dp550_axi_burstlen_valid(val);
+	case MALIDP_ATTR_DE_OUTSTRAN:
+	case MALIDP_ATTR_DE_POUTSTDCAB:
+		if ((val < 1) || (val > 32))
+			return false;
+		break;
+	default:
+		BUG();
+	}
+
+	return true;
+}
+
+static bool dp550_se_axi_valid(u32 attr, u32 val)
+{
+	switch (attr) {
+	case MALIDP_ATTR_SE_BURSTLEN:
+		return dp550_axi_burstlen_valid(val);
+	case MALIDP_ATTR_SE_OUTSTRAN:
+		if ((val < 1) || (val > 32))
+			return false;
+		break;
+	case MALIDP_ATTR_SE_WCACHE:
+		if (val > 15)
+			return false;
+		break;
+	default:
+		BUG();
+	}
+
+	return true;
+}
+
+static u32 dp550_rotmem_required(const struct malidp_hw_buffer *hw_buf)
+{
+	u32 bytes_per_col;
+
+	switch (hw_buf->fmt) {
+	/* 8 lines at 4 bytes per pixel */
+	case DRM_FORMAT_ARGB2101010:
+	case DRM_FORMAT_ABGR2101010:
+	case DRM_FORMAT_RGBA1010102:
+	case DRM_FORMAT_BGRA1010102:
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_BGRA8888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBX8888:
+	case DRM_FORMAT_BGRX8888:
+	case DRM_FORMAT_RGB888:
+	case DRM_FORMAT_BGR888:
+	case MALIDP_FORMAT_VYU30: /* 4:4:4 10-bit per component */
+	case MALIDP_FORMAT_XYUV: /* 4:4:4 8-bit per component */
+	/* 16 lines at 2 bytes per pixel */
+	case DRM_FORMAT_RGBA5551:
+	case DRM_FORMAT_ABGR1555:
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_BGR565:
+	case DRM_FORMAT_UYVY:
+	case DRM_FORMAT_YUYV:
+	case MALIDP_FORMAT_NV16AFBC: /* 4:2:2 8-bit per component */
+	case MALIDP_FORMAT_YUV10_420AFBC: /* 4:2:0 10-bit per component */
+	case MALIDP_FORMAT_Y0L2:
+	case MALIDP_FORMAT_P010:
+		bytes_per_col = 32;
+		break;
+	/* 16 lines at 1.5 bytes per pixel */
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_YUV420:
+	case MALIDP_FORMAT_NV12AFBC:
+		bytes_per_col = 24;
+		break;
+	default:
+		BUG();
+	}
+	return hw_buf->cmp_rect.src_w * bytes_per_col;
+}
+
+static void dp550_disable_irq(struct malidp_hw_device *hwdev)
+{
+	malidp_hw_write(hwdev, 0,
+		hwdev->hw_regmap->se_base + SE_REG_MASKIRQ);
+	malidp_hw_write(hwdev, 0, MALI_DP550_REG_DC_IRQ_MSK);
+	malidp_hw_write(hwdev, 0,
+		hwdev->hw_regmap->de_base + MALI_DP550_REG_DE_IRQ_MSK);
+}
+
+/* Must be called with the power_mutex held */
+static enum malidp_op_mode dp550_change_op_mode(
+		struct malidp_hw_device *hwdev,
+		enum malidp_op_mode mode)
+{
+	unsigned long flags;
+	enum malidp_op_mode old_mode_de;
+	u32 status_bits = 0;
+	u32 status;
+
+	BUG_ON(mode == MALIDP_OP_MODE_UNKNOWN);
+
+
+	/* We're protected by the power mutex, so just read the mode */
+	old_mode_de = malidp_de_get_op_mode(hwdev->de_dev);
+	dev_dbg(hwdev->device, "performing op mode change: %s->%s\n",
+		op_mode_name[old_mode_de], op_mode_name[mode]);
+	if (old_mode_de == MALIDP_OP_MODE_UNKNOWN) {
+		/* reset */
+		dev_dbg(hwdev->device, "Requesting configuration reset\n");
+		malidp_hw_setbits(hwdev, MALI_DP550_DC_CRST,
+			MALI_DP550_REG_DC_CTRL);
+	} else if (old_mode_de == mode) {
+		return old_mode_de;
+	} else if (old_mode_de == MALIDP_OP_MODE_POWERSAVE) {
+		/*
+		 * Exiting powersave mode, so clear the status registers
+		 * and re-enable interrupts
+		 */
+		status = malidp_de_read(hwdev->de_dev,
+					MALI_DP550_REG_DE_STATUS);
+		malidp_de_write(hwdev->de_dev, status,
+				MALI_DP550_REG_DE_IRQ_CLR);
+		malidp_de_write(hwdev->de_dev, MALI_DP550_DE_IRQ_UNR |
+				MALI_DP550_DE_IRQ_PL1,
+				MALI_DP550_REG_DE_IRQ_MSK);
+		status = malidp_se_read(hwdev->se_dev,
+					MALI_DP550_REG_DE_STATUS);
+		malidp_se_write(hwdev->se_dev, status,
+				MALI_DP550_REG_SE_IRQ_CLR);
+		malidp_se_write(hwdev->se_dev, MALI_DP550_SE_IRQ_PL |
+				MALI_DP550_SE_IRQ_EOW, SE_REG_MASKIRQ);
+	}
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+
+	switch (mode) {
+	case MALIDP_OP_MODE_POWERSAVE:
+	case MALIDP_OP_MODE_CONFIG:
+		malidp_hw_setbits(hwdev, MALI_DP550_DC_CM,
+			MALI_DP550_REG_DC_CTRL);
+		status_bits = MALI_DP550_DC_CM;
+		break;
+	case MALIDP_OP_MODE_NORMAL:
+		malidp_hw_clearbits(hwdev, MALI_DP550_DC_CM,
+			MALI_DP550_REG_DC_CTRL);
+		break;
+	case MALIDP_OP_MODE_UNKNOWN:
+	default:
+		BUG();
+	}
+
+	/* Wait for the mode change to be applied */
+	do {
+		status = malidp_hw_read(hwdev,
+			MALI_DP550_REG_DC_STATUS);
+	} while ((status & MALI_DP550_DC_CM) != status_bits);
+
+	/* If we did a configuration reset, we have to clear the CRST bit */
+	if (old_mode_de == MALIDP_OP_MODE_UNKNOWN) {
+		malidp_hw_clearbits(hwdev, MALI_DP550_DC_CRST,
+				    MALI_DP550_REG_DC_CTRL);
+	}
+
+	/*
+	 * On entering powersave, disable IRQs and store the pending status
+	 * incase there is still one left to be handled
+	 */
+	if (mode == MALIDP_OP_MODE_POWERSAVE) {
+		status = malidp_hw_read(hwdev, MALI_DP550_REG_DC_STATUS);
+		hwdev->de_dev->pending_status = status;
+		hwdev->se_dev->pending_status = status;
+
+		dp550_disable_irq(hwdev);
+
+		status = malidp_de_read(hwdev->de_dev,
+					MALI_DP550_REG_DE_STATUS);
+		malidp_de_write(hwdev->de_dev, status,
+				MALI_DP550_REG_DE_IRQ_CLR);
+
+		status = malidp_se_read(hwdev->se_dev, SE_REG_STATUS);
+		malidp_se_write(hwdev->se_dev, status,
+				MALI_DP550_REG_SE_IRQ_CLR);
+	}
+
+	hwdev->de_dev->op_mode = mode;
+	hwdev->se_dev->op_mode = mode;
+
+	dev_dbg(hwdev->device, "mode change ok: %s\n", op_mode_name[mode]);
+
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+
+	return old_mode_de;
+}
+
+static int dp550_de_hw_cfg(struct malidp_de_device *de_dev)
+{
+	/* Set AXI configuration */
+	if (!malidp_de_attr_valid(de_dev, MALIDP_ATTR_DE_OUTSTRAN,
+					de_dev->outstran)) {
+		dev_warn(de_dev->device, "%s : invalid value '%d' for de_axi_outstran\n",
+				__func__, de_dev->outstran);
+		de_dev->outstran = DE_DEFAULT_AXI_OUTSTRAN;
+	}
+
+	if (!malidp_de_attr_valid(de_dev, MALIDP_ATTR_DE_POUTSTDCAB,
+					de_dev->poutstdcab)) {
+		dev_warn(de_dev->device, "%s : invalid value '%d' for de_axi_poutstdcab\n",
+				__func__, de_dev->poutstdcab);
+		de_dev->poutstdcab = DE_DEFAULT_AXI_POUTSTDCAB;
+	}
+
+	if (!malidp_de_attr_valid(de_dev, MALIDP_ATTR_DE_BURSTLEN,
+					de_dev->burstlen)) {
+		dev_warn(de_dev->device, "%s : invalid value '%d' for de_axi_burstlen\n",
+				__func__, de_dev->burstlen);
+		de_dev->burstlen = DE_DEFAULT_AXI_BURSTLEN;
+	}
+
+	malidp_de_set_axi_cfg(de_dev, de_dev->outstran,
+			de_dev->poutstdcab,
+			de_dev->burstlen);
+
+	/* Initialize the ARQOS settings */
+	malidp_de_init_axi_qos(de_dev,
+		de_dev->arqos_threshold_low,
+		de_dev->arqos_threshold_high,
+		de_dev->arqos_red,
+		de_dev->arqos_green);
+
+	/* Set default background (black (0, 0, 0))*/
+	malidp_de_write(de_dev, 0, MALI_DP550_REG_BG_COLOR);
+
+	/* Clear display function, as CRST might not have worked */
+	malidp_de_write(de_dev, 0, MALI_DP550_REG_DE_DISP_FUNC);
+
+	/* Set prefetch_line to default value */
+	malidp_de_clearbits(de_dev, DP550_PREFETCH_LINE_MASK,
+		MALI_DP550_REG_DE_CTRL);
+	malidp_de_setbits(de_dev, DP550_PREFETCH_LINE_SET(DE_DEFAULT_PREFETCH_LINE),
+		MALI_DP550_REG_DE_CTRL);
+
+	/*
+	 * We are always interested on getting an IRQ as soon as a frame begins
+	 * to be scanned out.
+	 */
+	malidp_de_write(de_dev, DE_LINE_INT_1(DE_DEFAULT_PREFETCH_LINE),
+		MALI_DP550_REG_LINE_INT_CTRL);
+	malidp_de_write(de_dev, MALI_DP550_DE_IRQ_UNR |
+			MALI_DP550_DE_IRQ_PL1, MALI_DP550_REG_DE_IRQ_MSK);
+
+	/* Write alpha lookup tables */
+	malidp_de_write_alpha_lookup(de_dev);
+
+	/* Disable all the layers so we don't scan out any stale config */
+	malidp_de_disable_all_layers(de_dev);
+
+	malidp_de_cleanup_yuv2rgb_coeffs(de_dev);
+
+	dev_dbg(de_dev->device, "%s : success!\n", __func__);
+	return 0;
+}
+
+static void dp550_de_modeset(struct malidp_de_device *de_dev,
+		struct malidp_de_hwmode *hwmode)
+{
+	u32 sync_ctl = DE_H_SYNCWIDTH(hwmode->hsw) | DE_V_SYNCWIDTH(hwmode->vsw);
+
+	if (hwmode->vsync_pol_pos)
+		sync_ctl |= MALI_DP550_VSP;
+	if (hwmode->hsync_pol_pos)
+		sync_ctl |= MALI_DP550_HSP;
+
+	malidp_de_write(de_dev, DE_H_FRONTPORCH(hwmode->hfp) | DE_H_BACKPORCH(hwmode->hbp),
+			MALI_DP550_REG_H_INTERVALS);
+	malidp_de_write(de_dev, DE_V_FRONTPORCH(hwmode->vfp) | DE_V_BACKPORCH(hwmode->vbp),
+			MALI_DP550_REG_V_INTERVALS);
+	malidp_de_write(de_dev, sync_ctl, MALI_DP550_REG_SYNC_CTRL);
+	malidp_de_write(de_dev, DE_H_ACTIVE(hwmode->h_active) | DE_V_ACTIVE(hwmode->v_active),
+		MALI_DP550_REG_HV_ACT_SIZE);
+
+}
+
+static void dp550_de_set_gamma_coeff(struct malidp_de_device *de_dev, u32 *coeffs)
+{
+	malidp_de_set_coeftab(de_dev, MALI_DP550_DE_COEFTAB_GAMMA,
+		coeffs);
+}
+
+static u32 dp550_de_fmt_fixup(u32 drm_format, u32 flags)
+{
+	if (flags & MALIDP_FLAG_AFBC) {
+		switch (drm_format) {
+		case DRM_FORMAT_ARGB2101010:
+		case DRM_FORMAT_RGBA1010102:
+		case DRM_FORMAT_BGRA1010102:
+			return DRM_FORMAT_ABGR2101010;
+		case DRM_FORMAT_ARGB8888:
+		case DRM_FORMAT_RGBA8888:
+		case DRM_FORMAT_BGRA8888:
+			return DRM_FORMAT_ABGR8888;
+		case DRM_FORMAT_RGB888:
+			return DRM_FORMAT_BGR888;
+		case DRM_FORMAT_RGBA5551:
+			return DRM_FORMAT_ABGR1555;
+		case DRM_FORMAT_RGB565:
+			return DRM_FORMAT_BGR565;
+		case DRM_FORMAT_YUYV:
+		case DRM_FORMAT_UYVY:
+			return MALIDP_FORMAT_NV16AFBC;
+		}
+	}
+	return drm_format;
+}
+
+static int dp550_se_hw_cfg(struct malidp_se_device *se_dev)
+{
+	malidp_se_set_axi_cfg(se_dev, se_dev->outstran,
+			se_dev->burstlen,
+			se_dev->wcache,
+			se_dev->wqos);
+
+	/* Set initial image enhancer state */
+	se_dev->enh_cfg = MALIDP_SE_ENHANCER_OFF;
+	malidp_se_clearbits(se_dev, SE_ENH_H_EN | SE_ENH_V_EN,
+			MALI_DP550_REG_SE_CTL);
+	malidp_se_write(se_dev, SE_SET_ENH_LIMIT_LOW(SE_ENH_LOW_LEVEL) |
+			SE_SET_ENH_LIMIT_HIGH(SE_ENH_HIGH_LEVEL),
+			malidp550_regmap.se_regmap.enhancer_control);
+
+	/*
+	 * Enable OFM in SE, disable everything else as CRST might not
+	 * have worked
+	 */
+	malidp_se_write(se_dev, MALI_DP550_SE_CTL_OFM,
+			MALI_DP550_REG_SE_CTL);
+	/*
+	 * We get an IRQ as soon as a frame starts to be written to memory and
+	 * when config valid is latched by the init signal.
+	 */
+	malidp_se_write(se_dev, MALI_DP550_SE_PL_INTERVAL(32) | MALI_DP550_SE_PL_LINE(0),
+		MALI_DP550_REG_SE_PL);
+	malidp_se_write(se_dev, MALI_DP550_SE_IRQ_PL | MALI_DP550_SE_IRQ_EOW,
+		SE_REG_MASKIRQ);
+
+	/* Force coefficients to be updated next time they are used */
+	se_dev->rgb2yuv_coeffs = NULL;
+	se_dev->v_coeffstab = 0xffff;
+	se_dev->h_coeffstab = 0xffff;
+
+	dev_dbg(se_dev->device, "%s: success!\n", __func__);
+	return 0;
+}
+
+static void dp550_se_set_scaler_coeff(struct malidp_se_device *se_dev,
+		enum malidp_scaling_coeff_set hcoeff,
+		enum malidp_scaling_coeff_set vcoeff)
+{
+	u32 mask = MALI_DP550_SE_CTL_VCSEL(MALI_DP550_SE_CTL_xSEL_MASK) |
+		   MALI_DP550_SE_CTL_HCSEL(MALI_DP550_SE_CTL_xSEL_MASK);
+	u32 new_value = MALI_DP550_SE_CTL_VCSEL(vcoeff + 1) |
+			MALI_DP550_SE_CTL_HCSEL(hcoeff + 1);
+
+	malidp_se_clearbits(se_dev, mask, MALI_DP550_REG_SE_CTL);
+
+	malidp_se_setbits(se_dev, new_value, MALI_DP550_REG_SE_CTL);
+}
+
+static bool dp550_se_limitation_check(struct malidp_se_device *se_dev,
+		struct malidp_se_scaler_conf *s0)
+{
+	bool ret = true;
+	struct malidp_hw_device *hwdev = se_dev->hwdev;
+	struct drm_mode_modeinfo mode;
+	unsigned long flags;
+	unsigned long mclk =
+		clk_get_rate(hwdev->mclk);
+	unsigned long pxclk =
+		clk_get_rate(hwdev->pxclk);
+	unsigned long numerator, denominator;
+
+	spin_lock_irqsave(&hwdev->hw_lock, flags);
+	malidp_de_modeget(hwdev->de_dev, &mode);
+	spin_unlock_irqrestore(&hwdev->hw_lock, flags);
+
+	/*
+	 * Equation:
+	 * a = (max(h_input_size, h_output_size) * v_input_size) /
+	 *         ((h_total_size - 2) * v_output_size)
+	 *
+	 * mclk = a * pxclk
+	 *
+	 * i.e. (h_total_size - 2) * v_output_size * mclk >=
+	 *         max(h_input_size, h_output_size) * v_input_size * pxclk
+	 */
+
+	numerator = max(s0->input_w, s0->output_w) * s0->input_h;
+	denominator = (mode.htotal - 2) * s0->output_h;
+
+	if ((u64)mclk * denominator < (u64)pxclk * numerator) {
+		dev_err(hwdev->device,
+			"%s: Clock ratio (mclk/pxclk) is not high enough for downscale factor.",
+			__func__);
+		ret = false;
+	}
+
+	return ret;
+}
+
+static u32 dp550_se_calc_downscaling_threshold(u32 mclk, u32 pxlclk,
+		struct drm_mode_modeinfo *mode)
+{
+	u64 mclk64 = mclk;
+
+	mclk64 *= mode->htotal - 2;
+
+	/* factor is (16.16) fix point */
+	mclk64 <<= 16;
+	do_div(mclk64, pxlclk);
+
+	return mclk64;
+}
diff --git a/drivers/video/video-tx/Kbuild b/drivers/video/video-tx/Kbuild
new file mode 100644
index 0000000..c216b85
--- /dev/null
+++ b/drivers/video/video-tx/Kbuild
@@ -0,0 +1,23 @@
+#
+# (C) COPYRIGHT ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+video-tx-y += video_tx.o
+obj-$(CONFIG_VIDEO_TX) += video-tx.o
+
+test-video-tx-y += test_video_tx.o
+obj-$(CONFIG_TEST_VIDEO_TX) += test-video-tx.o
+
+obj-$(CONFIG_SII902X) += sii902x.o
+
+obj-$(CONFIG_SENC_TX) += senc_tx.o
diff --git a/drivers/video/video-tx/Kconfig b/drivers/video/video-tx/Kconfig
new file mode 100644
index 0000000..5fe0814
--- /dev/null
+++ b/drivers/video/video-tx/Kconfig
@@ -0,0 +1,37 @@
+#
+# (C) COPYRIGHT ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+config VIDEO_TX
+	tristate "Video Transmitter Framework"
+	---help---
+	This framework provides an abstraction for the video transmitter
+	hardware.
+
+if VIDEO_TX
+config TEST_VIDEO_TX
+	depends on VIDEO_TX
+	tristate "Test driver for the Video Transmitter Framework"
+	---help---
+	This video transmitter device driver provides a test implementation of
+	the video transmitter framework useful for initial platform bringup
+	as well as testing the transmitter framework functionality.
+
+config SENC_TX
+	depends on VIDEO_TX
+	tristate "DRM Slave encoder wrapper for Video Transmitter Framework"
+	---help---
+	This module can wrap around a DRM slave encoder implementation to provide
+	a video-tx driver.
+
+endif
diff --git a/drivers/video/video-tx/Makefile b/drivers/video/video-tx/Makefile
new file mode 100644
index 0000000..5739b37
--- /dev/null
+++ b/drivers/video/video-tx/Makefile
@@ -0,0 +1,38 @@
+#
+# (C) COPYRIGHT 2014-2015 ARM Limited. All rights reserved.
+#
+# This program is free software and is provided to you under the terms of the
+# GNU General Public License version 2 as published by the Free Software
+# Foundation, and any use by you of this program is subject to the terms
+# of such GNU licence.
+#
+# A copy of the licence is included with the program, and can also be obtained
+# from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+# Boston, MA  02110-1301, USA.
+#
+#
+
+
+# default to building for the host
+ARCH ?= $(shell uname -m)
+
+ifeq ($(KDIR),)
+$(error Must specify KDIR to point to the kernel to target))
+endif
+
+all: video-tx test_video_tx
+
+video-tx:
+	$(MAKE) ARCH=$(ARCH) -C $(KDIR) M=$(CURDIR) EXTRA_CFLAGS="-I$(CURDIR)/../../../include" CONFIG_VIDEO_TX=m
+
+test_video_tx:
+	$(MAKE) ARCH=$(ARCH) -C $(KDIR) M=$(CURDIR) EXTRA_CFLAGS="-I$(CURDIR)/../../../include" CONFIG_TEST_VIDEO_TX=m
+
+sii902x:
+	$(MAKE) ARCH=$(ARCH) -C $(KDIR) M=$(CURDIR) EXTRA_CFLAGS="-I$(CURDIR)/../../../include" CONFIG_SII902X=m
+
+senc_tx:
+	$(MAKE) ARCH=$(ARCH) -C $(KDIR) M=$(CURDIR) EXTRA_CFLAGS="-I$(CURDIR)/../../../include" CONFIG_SENC_TX=m
+
+clean:
+	$(MAKE) ARCH=$(ARCH) -C $(KDIR) M=$(CURDIR) clean
diff --git a/drivers/video/video-tx/senc_tx.c b/drivers/video/video-tx/senc_tx.c
new file mode 100644
index 0000000..d4e6bea
--- /dev/null
+++ b/drivers/video/video-tx/senc_tx.c
@@ -0,0 +1,586 @@
+/*
+ *
+ * (C) COPYRIGHT 2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+/* This implements a wrapper around the DRM slave encoder framework so that
+ * slave encoder drivers can be used as video-tx drivers
+ */
+
+#define DEBUG
+
+#include <linux/module.h>
+#include <linux/of_i2c.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/sysfs.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/mutex.h>
+
+#include <drm/drmP.h>
+#include <drm/drm_crtc_helper.h>
+#include <drm/drm_edid.h>
+#include <drm/drm_encoder_slave.h>
+
+#include <video/video_tx.h>
+
+#define DEFAULT_ENCODER_TYPE   DRM_MODE_ENCODER_TMDS
+#define DEFAULT_CONNECTOR_TYPE DRM_MODE_CONNECTOR_HDMIA
+
+struct senc_tx {
+	struct device *dev;
+	struct i2c_client *client;
+	/* Skeleton DRM objects */
+	struct drm_device drm_dev;
+	struct drm_encoder_slave drm_slave;
+	struct drm_connector drm_conn;
+	/* Video-tx objects */
+	struct video_tx_device *vtx_dev;
+	struct video_tx_info tx_info;
+	/* Mutex to make sure we are thread-safe with the polling thread */
+	struct mutex mode_mutex;
+	enum drm_connector_status connector_status;
+	int n_modes;
+};
+
+static void drm_display_mode_to_modeinfo(struct drm_display_mode *disp_mode,
+	struct drm_mode_modeinfo *modeinfo)
+{
+	modeinfo->clock = disp_mode->clock;
+	modeinfo->hdisplay = disp_mode->hdisplay;
+	modeinfo->hsync_start = disp_mode->hsync_start;
+	modeinfo->hsync_end = disp_mode->hsync_end;
+	modeinfo->htotal = disp_mode->htotal;
+	modeinfo->hskew = disp_mode->hskew;
+	modeinfo->vdisplay = disp_mode->vdisplay;
+	modeinfo->vsync_start = disp_mode->vsync_start;
+	modeinfo->vsync_end = disp_mode->vsync_end;
+	modeinfo->vtotal = disp_mode->vtotal;
+	modeinfo->vscan = disp_mode->vscan;
+	modeinfo->vrefresh = disp_mode->vrefresh;
+
+	modeinfo->flags = disp_mode->flags;
+	modeinfo->type = disp_mode->type;
+
+	strncpy(modeinfo->name, disp_mode->name, DRM_DISPLAY_MODE_LEN);
+}
+
+static void drm_modeinfo_to_display_mode(struct drm_mode_modeinfo *modeinfo,
+	struct drm_display_mode *disp_mode)
+{
+	disp_mode->clock = modeinfo->clock;
+	disp_mode->hdisplay = modeinfo->hdisplay;
+	disp_mode->hsync_start = modeinfo->hsync_start;
+	disp_mode->hsync_end = modeinfo->hsync_end;
+	disp_mode->htotal = modeinfo->htotal;
+	disp_mode->hskew = modeinfo->hskew;
+	disp_mode->vdisplay = modeinfo->vdisplay;
+	disp_mode->vsync_start = modeinfo->vsync_start;
+	disp_mode->vsync_end = modeinfo->vsync_end;
+	disp_mode->vtotal = modeinfo->vtotal;
+	disp_mode->vscan = modeinfo->vscan;
+	disp_mode->vrefresh = modeinfo->vrefresh;
+
+	disp_mode->flags = modeinfo->flags;
+	disp_mode->type = modeinfo->type;
+
+	strncpy(disp_mode->name, modeinfo->name, DRM_DISPLAY_MODE_LEN);
+}
+
+static int senc_tx_get_modes(struct video_tx_device *vtx_dev,
+	struct drm_mode_modeinfo *mode_info, int n)
+{
+	struct senc_tx *tx = video_tx_get_drvdata(vtx_dev);
+	struct drm_display_mode *p;
+	int min, i = 0;
+
+	mutex_lock(&tx->mode_mutex);
+	min = n < tx->n_modes ? n : tx->n_modes;
+
+	if (mode_info == NULL) {
+		dev_dbg(tx->dev, "%s: %d modes available\n", __func__,
+			tx->n_modes);
+		mutex_unlock(&tx->mode_mutex);
+		return tx->n_modes;
+	}
+
+	dev_dbg(tx->dev, "%s: copying %d modes\n", __func__, min);
+	list_for_each_entry(p, &tx->drm_conn.modes, head) {
+		struct drm_mode_modeinfo *m = &mode_info[i++];
+		drm_display_mode_to_modeinfo(p, m);
+	}
+	mutex_unlock(&tx->mode_mutex);
+	return min;
+}
+
+static int senc_tx_set_mode(struct video_tx_device *vtx_dev,
+	struct drm_mode_modeinfo *modeinfo)
+{
+	struct senc_tx *tx = video_tx_get_drvdata(vtx_dev);
+	struct drm_encoder_slave_funcs *slave_funcs =
+		tx->drm_slave.slave_funcs;
+	struct drm_display_mode disp_mode;
+
+	memset(&disp_mode, 0, sizeof(disp_mode));
+
+	drm_modeinfo_to_display_mode(modeinfo, &disp_mode);
+
+	dev_dbg(tx->dev, "%s: Setting %s\n", __func__, modeinfo->name);
+	dev_dbg(tx->dev, "%s: %d %d %d %d %d\n", __func__,
+		modeinfo->hdisplay, modeinfo->hsync_start, modeinfo->hsync_end,
+		modeinfo->htotal, modeinfo->hskew);
+	dev_dbg(tx->dev, "%s: %d %d %d %d %d\n", __func__,
+		modeinfo->vdisplay, modeinfo->vsync_start, modeinfo->vsync_end,
+		modeinfo->vtotal, modeinfo->vscan);
+	dev_dbg(tx->dev, "%s: vrefresh: %d flags: 0x%x type: 0x%x\n",
+		__func__, modeinfo->vrefresh, modeinfo->flags, modeinfo->type);
+
+	slave_funcs->mode_set(&tx->drm_slave.base, &disp_mode, &disp_mode);
+
+	return 0;
+}
+
+static int senc_tx_dpms(struct video_tx_device *vtx_dev, int mode)
+{
+	struct senc_tx *tx = video_tx_get_drvdata(vtx_dev);
+	struct drm_encoder_slave_funcs *slave_funcs =
+		tx->drm_slave.slave_funcs;
+
+	slave_funcs->dpms(&tx->drm_slave.base, mode);
+
+	return 0;
+}
+
+static int senc_tx_get_tx_info(struct video_tx_device *dev,
+	struct video_tx_info *tx_info)
+{
+	struct senc_tx *tx = video_tx_get_drvdata(dev);
+
+	if (tx_info == NULL)
+		return -ENOMEM;
+
+	memcpy(tx_info, &tx->tx_info,
+	       sizeof(struct video_tx_info));
+
+	return 0;
+}
+
+/* Should be called with the tx->mode_mutex held
+ * This broadly copies drm_helper_probe_single_connector_modes
+ */
+static void senc_tx_handle_hotplug(struct senc_tx *tx,
+	enum drm_connector_status status)
+{
+	struct drm_encoder_slave_funcs *slave_funcs =
+		tx->drm_slave.slave_funcs;
+	struct drm_display_mode *mode;
+
+	if (status == connector_status_connected) {
+		int n_probed, n = 0;
+
+		n_probed = slave_funcs->get_modes(&tx->drm_slave.base,
+			&tx->drm_conn);
+		/* If we couldn't get any, add some default DMT ones */
+		if (!n_probed)
+			drm_add_modes_noedid(&tx->drm_conn, 1024, 768);
+
+		/* Copy the probed modes into the modes list */
+		drm_mode_connector_list_update(&tx->drm_conn);
+
+		/* Validate the probed modes */
+		list_for_each_entry(mode, &tx->drm_conn.modes, head) {
+			if ((mode->flags & DRM_MODE_FLAG_INTERLACE) &&
+			    !(tx->drm_conn.interlace_allowed))
+				mode->status = MODE_NO_INTERLACE;
+
+			if ((mode->flags & DRM_MODE_FLAG_DBLSCAN) &&
+			    !(tx->drm_conn.doublescan_allowed))
+				mode->status = MODE_NO_DBLESCAN;
+
+			if ((mode->status == MODE_OK) && slave_funcs &&
+			    slave_funcs->mode_valid)
+				mode->status = slave_funcs->mode_valid(&tx->drm_slave.base,
+					mode);
+		}
+		dev_dbg(tx->dev, "%s: Probed %d modes\n", __func__, n_probed);
+
+		drm_mode_prune_invalid(&tx->drm_dev, &tx->drm_conn.modes,
+				       false);
+		if (!list_empty(&tx->drm_conn.modes)) {
+			drm_mode_sort(&tx->drm_conn.modes);
+			list_for_each_entry(mode, &tx->drm_conn.modes, head) {
+				mode->vrefresh = drm_mode_vrefresh(mode);
+				drm_mode_debug_printmodeline(mode);
+				n++;
+			}
+		}
+		tx->n_modes = n;
+		dev_dbg(tx->dev, "%s: Have %d valid modes\n", __func__, n);
+	} else {
+		struct drm_display_mode *t;
+		/* Wipe out the current mode lists */
+		list_for_each_entry_safe(mode, t, &tx->drm_conn.probed_modes, head)
+			drm_mode_remove(&tx->drm_conn, mode);
+		list_for_each_entry_safe(mode, t, &tx->drm_conn.modes, head)
+			drm_mode_remove(&tx->drm_conn, mode);
+		tx->n_modes = 0;
+
+		drm_mode_connector_update_edid_property(&tx->drm_conn, NULL);
+	}
+}
+
+static enum drm_connector_status senc_tx_detect(struct video_tx_device *vtx_dev)
+{
+	struct senc_tx *tx = video_tx_get_drvdata(vtx_dev);
+	struct drm_encoder_slave_funcs *slave_funcs =
+		tx->drm_slave.slave_funcs;
+	enum drm_connector_status status = connector_status_unknown;
+
+	mutex_lock(&tx->mode_mutex);
+
+	if (slave_funcs->detect)
+		status = slave_funcs->detect(&tx->drm_slave.base,
+				&tx->drm_conn);
+
+	if (status != tx->connector_status) {
+		dev_dbg(tx->dev, "%s: Status change: %s->%s\n", __func__,
+			drm_get_connector_status_name(tx->connector_status),
+			drm_get_connector_status_name(status));
+		tx->connector_status = status;
+
+		senc_tx_handle_hotplug(tx, status);
+	}
+
+	mutex_unlock(&tx->mode_mutex);
+
+	return status;
+}
+
+static int senc_tx_get_display_info(struct video_tx_device *vtx_dev,
+	struct video_tx_display_info *disp_info)
+{
+	struct senc_tx *tx = video_tx_get_drvdata(vtx_dev);
+	struct edid *edid =  NULL;
+
+	mutex_lock(&tx->mode_mutex);
+
+	if (!tx->drm_conn.edid_blob_ptr) {
+		dev_warn(tx->dev, "%s: No edid property available. Using defaults\n",
+			 __func__);
+		/* Gamma = 2.2 */
+		disp_info->gamma = 120;
+		/* sRGB color space coordinates */
+		disp_info->red_x = 655;
+		disp_info->red_y = 338;
+		disp_info->blue_x = 154;
+		disp_info->blue_y = 61;
+		disp_info->green_x = 307;
+		disp_info->green_y = 614;
+		disp_info->white_x = 320;
+		disp_info->white_y = 337;
+		mutex_unlock(&tx->mode_mutex);
+		return 0;
+	}
+
+	edid = (struct edid *)tx->drm_conn.edid_blob_ptr->data;
+
+	disp_info->gamma = edid->gamma;
+
+	disp_info->red_x =
+		(edid->red_x << 2) | ((edid->red_green_lo >> 6) & 0x3);
+	disp_info->red_y =
+		(edid->red_y << 2) | ((edid->red_green_lo >> 4) & 0x3);
+	disp_info->green_x =
+		(edid->green_x << 2) | ((edid->red_green_lo >> 2) & 0x3);
+	disp_info->green_y =
+		(edid->green_y << 2) | ((edid->red_green_lo >> 0) & 0x3);
+
+	disp_info->blue_x =
+		(edid->blue_x << 2) | ((edid->black_white_lo >> 6) & 0x3);
+	disp_info->blue_y =
+		(edid->blue_y << 2) | ((edid->black_white_lo >> 4) & 0x3);
+	disp_info->white_x =
+		(edid->white_x << 2) | ((edid->black_white_lo >> 2) & 0x3);
+	disp_info->white_y =
+		(edid->white_y << 2) | ((edid->black_white_lo >> 0) & 0x3);
+
+	disp_info->width_mm = tx->drm_conn.display_info.width_mm;
+	disp_info->height_mm = tx->drm_conn.display_info.height_mm;
+
+	mutex_unlock(&tx->mode_mutex);
+
+	return 0;
+}
+
+static struct video_tx_driver senc_vtx_driver = {
+	.get_modes = senc_tx_get_modes,
+	.set_mode = senc_tx_set_mode,
+	.dpms = senc_tx_dpms,
+	.get_tx_info = senc_tx_get_tx_info,
+	.detect = senc_tx_detect,
+	.get_display_info = senc_tx_get_display_info,
+};
+
+static void senc_tx_drm_dev_init(struct senc_tx *tx)
+{
+	struct drm_device *dev = &tx->drm_dev;
+
+	dev->dev = tx->dev;
+
+	drm_mode_config_init(&tx->drm_dev);
+}
+
+static int senc_tx_drm_slave_init(struct senc_tx *tx,
+		struct i2c_board_info *i2c_info)
+{
+	int ret;
+
+	ret = drm_encoder_init(&tx->drm_dev, &tx->drm_slave.base, NULL,
+		DEFAULT_ENCODER_TYPE);
+	if (ret) {
+		dev_err(tx->dev, "%s: encoder_init failed\n", __func__);
+		return ret;
+	}
+
+	/* LEOSW-408: drm_i2c_encoder_attach is what we want actually:
+	 * http://lists.freedesktop.org/archives/dri-devel/2015-January/075409.html
+	 */
+	ret = drm_i2c_encoder_init(&tx->drm_dev, &tx->drm_slave, NULL,
+			i2c_info);
+	if (ret) {
+		dev_err(tx->dev, "%s: i2c_encoder_init failed\n", __func__);
+		goto fail_encoder_cleanup;
+	}
+
+	return 0;
+
+fail_encoder_cleanup:
+	drm_encoder_cleanup(&tx->drm_slave.base);
+	return ret;
+}
+
+static void senc_tx_drm_slave_exit(struct senc_tx *tx)
+{
+	if (tx->drm_slave.slave_funcs && tx->drm_slave.slave_funcs->destroy)
+		tx->drm_slave.slave_funcs->destroy(&tx->drm_slave.base);
+	drm_encoder_cleanup(&tx->drm_slave.base);
+}
+
+static int senc_tx_drm_conn_init(struct senc_tx *tx)
+{
+	int ret;
+
+	tx->drm_conn.interlace_allowed = false;
+	tx->drm_conn.doublescan_allowed = false;
+	ret = drm_connector_init(&tx->drm_dev, &tx->drm_conn, NULL,
+			tx->tx_info.connector_type);
+	if (ret) {
+		dev_err(tx->dev, "%s: connector_init failed\n", __func__);
+		return ret;
+	}
+
+	return 0;
+}
+
+static int senc_tx_drm_init(struct senc_tx *tx,
+		struct i2c_board_info *i2c_info)
+{
+	int ret;
+
+	senc_tx_drm_dev_init(tx);
+
+	ret = senc_tx_drm_slave_init(tx, i2c_info);
+	if (ret)
+		return ret;
+
+	ret = senc_tx_drm_conn_init(tx);
+	if (ret) {
+		senc_tx_drm_slave_exit(tx);
+		return ret;
+	}
+
+	return 0;
+}
+
+static void senc_tx_drm_exit(struct senc_tx *tx)
+{
+	drm_connector_cleanup(&tx->drm_conn);
+	senc_tx_drm_slave_exit(tx);
+}
+
+#define MAX_TYPE_STRLEN 5
+static int senc_tx_conn_type(const char *str, u32 *type)
+{
+	int i;
+	struct {
+		char str[MAX_TYPE_STRLEN];
+		u32 type;
+	} connector_types[] = {
+		{ "HDMI", DRM_MODE_CONNECTOR_HDMIA },
+		{ "DVI", DRM_MODE_CONNECTOR_DVII },
+	};
+
+	for (i = 0; i < ARRAY_SIZE(connector_types); i++) {
+		if (!strncmp(connector_types[i].str, str, MAX_TYPE_STRLEN)) {
+			*type = connector_types[i].type;
+			return 0;
+		}
+	}
+
+	return -EINVAL;
+}
+
+static int senc_tx_parse_dt(struct senc_tx *tx, struct device_node *np)
+{
+	int ret;
+	const char *str;
+	struct device_node *slave_node;
+	phandle slave_phandle;
+
+	if (of_property_read_u32(np, "i2c-slave", &slave_phandle)) {
+		dev_err(tx->dev, "no i2c-slave handle provided!\n");
+		return -ENODEV;
+	} else {
+		slave_node = of_find_node_by_phandle(slave_phandle);
+		BUG_ON(!slave_node);
+	}
+	tx->client = of_find_i2c_device_by_node(slave_node);
+	of_node_put(slave_node);
+	if (!tx->client) {
+		dev_err(tx->dev, "Couldn't find i2c client\n");
+		return -ENODEV;
+	}
+
+	/* Init video tx info */
+	ret = of_property_read_string(np, "type", &str);
+	if (ret) {
+		dev_warn(tx->dev, "%s: type not found. Using default\n",
+			 __func__);
+		tx->tx_info.connector_type = DEFAULT_CONNECTOR_TYPE;
+	} else {
+		ret = senc_tx_conn_type(str, &tx->tx_info.connector_type);
+		if (ret) {
+			dev_err(tx->dev, "%s: unrecognized output type '%s'\n",
+				__func__, str);
+			return ret;
+		}
+	}
+
+	ret = of_property_read_u32(np, "type-idx", &tx->tx_info.idx);
+	if (ret) {
+		tx->tx_info.idx = np->phandle;
+		dev_warn(tx->dev, "%s: type-idx not found. Using phandle\n",
+			 __func__);
+	}
+
+	snprintf(tx->tx_info.name, DRM_CONNECTOR_NAME_LEN, "%s",
+		 dev_name(tx->dev));
+
+	/* LEOSW-188 This can actually change at runtime! */
+	tx->tx_info.red_bits = 8;
+	tx->tx_info.green_bits = 8;
+	tx->tx_info.blue_bits = 8;
+
+	return 0;
+}
+
+static int senc_tx_probe(struct platform_device *pdev)
+{
+	int ret;
+	struct senc_tx *tx;
+	struct device_node *np = pdev->dev.of_node;
+	struct i2c_board_info i2c_info;
+
+	if (!np) {
+		dev_err(&pdev->dev, "only device tree set up supported\n");
+		return -ENODEV;
+	}
+
+	tx = devm_kzalloc(&pdev->dev, sizeof(*tx), GFP_KERNEL);
+	if (!tx)
+		return -ENOMEM;
+
+	tx->dev = &pdev->dev;
+	tx->connector_status = connector_status_unknown;
+	mutex_init(&tx->mode_mutex);
+
+	ret = senc_tx_parse_dt(tx, np);
+	if (ret)
+		return ret;
+
+	/* get the driver for the i2c slave node */
+	memset(&i2c_info, 0, sizeof(i2c_info));
+	i2c_info.of_node = tx->client->dev.of_node;
+	ret = of_modalias_node(i2c_info.of_node, i2c_info.type,
+		sizeof(i2c_info.type));
+	if (ret < 0) {
+		dev_err(tx->dev, "failed to get a module alias for node %s\n",
+			i2c_info.of_node->full_name);
+	}
+
+	ret = senc_tx_drm_init(tx, &i2c_info);
+	if (ret)
+		return ret;
+
+	tx->vtx_dev = video_tx_register_device(tx->dev, &senc_vtx_driver);
+	if (!tx->vtx_dev) {
+		senc_tx_drm_exit(tx);
+		dev_err(tx->dev, "%s: Failed to register with video-tx framework\n",
+			__func__);
+		return -EINVAL;
+	}
+
+	platform_set_drvdata(pdev, tx);
+	video_tx_set_drvdata(tx->vtx_dev, tx);
+
+	video_tx_request_polling(tx->vtx_dev);
+
+	dev_dbg(tx->dev, "Probed device '%s'", tx->tx_info.name);
+
+	return 0;
+}
+
+static int senc_tx_remove(struct platform_device *pdev)
+{
+	struct senc_tx *tx = platform_get_drvdata(pdev);
+
+	video_tx_cancel_polling(tx->vtx_dev);
+	senc_tx_dpms(tx->vtx_dev, DRM_MODE_DPMS_OFF);
+
+	video_tx_unregister_device(tx->vtx_dev);
+	senc_tx_drm_exit(tx);
+	return 0;
+}
+
+static const struct of_device_id slave_enc_tx_ids[] = {
+	{ .compatible = "generic,slave_enc_video_tx" },
+	{ /*empty*/ }
+};
+
+static struct platform_driver slave_enc_tx_driver = {
+	.probe = senc_tx_probe,
+	.remove = senc_tx_remove,
+	.driver = {
+		.name = "senc_tx",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(slave_enc_tx_ids),
+	},
+};
+
+module_platform_driver(slave_enc_tx_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("DRM slave encoder Video-Tx driver");
diff --git a/drivers/video/video-tx/test_video_tx.c b/drivers/video/video-tx/test_video_tx.c
new file mode 100644
index 0000000..a6eea78
--- /dev/null
+++ b/drivers/video/video-tx/test_video_tx.c
@@ -0,0 +1,701 @@
+/*
+ *
+ * (C) COPYRIGHT 2014 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/sysfs.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/mutex.h>
+
+#include <video/video_tx.h>
+
+#define TEST_VD_TX_DEV	"fake_vd_tx"
+
+struct video_tx_client_data {
+	struct mutex tx_client_lock;
+	struct device *dev;
+	u16 current_mode_index;
+	struct video_tx_display_info dummy_display_info;
+	struct video_tx_info dummy_tx_info;
+	int dpms_status;
+	enum drm_connector_status conn_status;
+	bool polling_enabled;
+};
+
+/* internal func */
+static const char *conn_status_str(enum drm_connector_status c)
+{
+	const char *p;
+
+	switch (c) {
+	case connector_status_connected:
+		p = "connected";
+		break;
+	case connector_status_disconnected:
+		p = "disconnected";
+		break;
+	case connector_status_unknown:
+		p = "unknown";
+		break;
+	default:
+		p = "connect error";
+	}
+	return p;
+}
+
+static struct video_tx_client_data *get_from_dev(struct device *dev)
+{
+	struct video_tx_client_data *vcd;
+	struct video_tx_device *vtd;
+
+	vtd = dev_get_drvdata(dev);
+	vcd = video_tx_get_drvdata(vtd);
+	return vcd;
+}
+
+/* sysfs file for connection */
+static ssize_t show_connect(struct device *dev, struct device_attribute *attr,
+	char *buf)
+{
+	struct video_tx_client_data *video_tx_client = get_from_dev(dev);
+
+	return scnprintf(buf, 20, "%s\n",
+		conn_status_str(video_tx_client->conn_status));
+}
+
+static ssize_t store_connect(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count)
+{
+	enum drm_connector_status c;
+	const char *p;
+	struct video_tx_device *tx_device = dev_get_drvdata(dev);
+	struct video_tx_client_data *video_tx_client;
+	bool report_hotplug_event = false;
+
+	video_tx_client = video_tx_get_drvdata(tx_device);
+	/*NOTE: only match 7 characters from the begining of the string */
+	mutex_lock(&video_tx_client->tx_client_lock);
+	for (c = connector_status_connected;
+			c <= connector_status_unknown && count >= 7;
+			c++) {
+		p = conn_status_str(c);
+		if (strncasecmp(buf, p, 7) == 0)
+			break;
+	}
+
+	if (video_tx_client->conn_status != c) {
+		video_tx_client->conn_status = c;
+		if (video_tx_client->polling_enabled == false)
+			report_hotplug_event = true;
+	}
+	mutex_unlock(&video_tx_client->tx_client_lock);
+
+	if (report_hotplug_event)
+		video_tx_report_hotplug_event(tx_device);
+	return count;
+}
+
+/* sysfs file for gamma */
+static ssize_t show_gamma(struct device *dev, struct device_attribute *attr,
+	char *buf)
+{
+	struct video_tx_client_data *video_tx_client = get_from_dev(dev);
+
+	return scnprintf(buf, 20, "%hhu\n",
+			video_tx_client->dummy_display_info.gamma);
+}
+
+static ssize_t store_gamma(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count)
+{
+	struct video_tx_client_data *video_tx_client = get_from_dev(dev);
+
+	mutex_lock(&video_tx_client->tx_client_lock);
+	if (sscanf(buf, "%hhu", &video_tx_client->dummy_display_info.gamma) != 1)
+		dev_err(dev, "input gamma error\n");
+	mutex_unlock(&video_tx_client->tx_client_lock);
+
+	return count;
+}
+
+/* sysfs file for polling */
+#define STR_POLLING_EN	"enabled"
+#define STR_POLLING_DIS	"disabled"
+
+static ssize_t show_polling(struct device *dev, struct device_attribute *attr,
+	char *buf)
+{
+	struct video_tx_client_data *video_tx_client = get_from_dev(dev);
+
+	return scnprintf(buf, 32, "%s\n",
+				(video_tx_client->polling_enabled == true) ?
+				STR_POLLING_EN : STR_POLLING_DIS);
+}
+
+static ssize_t store_polling(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count)
+{
+	struct video_tx_device *tx_device = dev_get_drvdata(dev);
+	struct video_tx_client_data *video_tx_client;
+	bool polling_en;
+
+	video_tx_client = video_tx_get_drvdata(tx_device);
+	if (count == 0 || video_tx_client == NULL)
+		return -EINVAL;
+
+	if (strncasecmp(buf, STR_POLLING_EN, strlen(STR_POLLING_EN)) == 0)
+		polling_en = true;
+	else if (strncasecmp(buf, STR_POLLING_DIS,
+			strlen(STR_POLLING_DIS)) == 0)
+		polling_en = false;
+	else
+		return -EINVAL;
+
+	mutex_lock(&video_tx_client->tx_client_lock);
+
+	if (polling_en != video_tx_client->polling_enabled) {
+		video_tx_client->polling_enabled = polling_en;
+		if (polling_en == true)
+			video_tx_request_polling(tx_device);
+		else
+			video_tx_cancel_polling(tx_device);
+	}
+
+	mutex_unlock(&video_tx_client->tx_client_lock);
+
+	return count;
+}
+
+/* sysfs files for color space coordinates */
+enum color_id {
+	color_id_red = 0,
+	color_id_green,
+	color_id_blue,
+	color_id_white
+};
+
+static ssize_t show_color_xy(u16 color_x, u16 color_y, char *buf)
+{
+	/* show coordinates as 10bits format */
+	u32 x = color_x;
+	u32 y = color_y;
+
+	return scnprintf(buf, 32, "%u,%u\n", x, y);
+}
+
+static ssize_t store_color_xy(const char *buf, size_t count,
+	u16 *color_x, u16 *color_y)
+{
+	u32 x, y;
+
+	if (sscanf(buf, "%u,%u", &x, &y) != 2)
+		return 0;
+
+	if (x > 1023 || y > 1023)
+		return 0;
+
+	*color_x = x;
+	*color_y = y;
+	return count;
+}
+
+static ssize_t show_color(struct device *dev, char *buf,
+	enum color_id color)
+{
+	struct video_tx_client_data *video_tx_client = get_from_dev(dev);
+	u16 color_x, color_y;
+
+	mutex_lock(&video_tx_client->tx_client_lock);
+	switch (color) {
+	case color_id_red:
+		color_x = video_tx_client->dummy_display_info.red_x;
+		color_y = video_tx_client->dummy_display_info.red_y;
+		break;
+	case color_id_green:
+		color_x = video_tx_client->dummy_display_info.green_x;
+		color_y = video_tx_client->dummy_display_info.green_y;
+		break;
+	case color_id_blue:
+		color_x = video_tx_client->dummy_display_info.blue_x;
+		color_y = video_tx_client->dummy_display_info.blue_y;
+		break;
+	case color_id_white:
+		color_x = video_tx_client->dummy_display_info.white_x;
+		color_y = video_tx_client->dummy_display_info.white_y;
+		break;
+	default:
+		BUG();
+	}
+	mutex_unlock(&video_tx_client->tx_client_lock);
+
+	return show_color_xy(color_x, color_y, buf);
+}
+
+static ssize_t store_color(struct device *dev, const char *buf,
+	size_t count, enum color_id color)
+{
+	struct video_tx_client_data *video_tx_client = get_from_dev(dev);
+	size_t ret;
+	u16 *color_x, *color_y;
+
+	switch (color) {
+	case color_id_red:
+		color_x = &video_tx_client->dummy_display_info.red_x;
+		color_y = &video_tx_client->dummy_display_info.red_y;
+		break;
+	case color_id_green:
+		color_x = &video_tx_client->dummy_display_info.green_x;
+		color_y = &video_tx_client->dummy_display_info.green_y;
+		break;
+	case color_id_blue:
+		color_x = &video_tx_client->dummy_display_info.blue_x;
+		color_y = &video_tx_client->dummy_display_info.blue_y;
+		break;
+	case color_id_white:
+		color_x = &video_tx_client->dummy_display_info.white_x;
+		color_y = &video_tx_client->dummy_display_info.white_y;
+		break;
+	default:
+		BUG();
+	}
+	mutex_lock(&video_tx_client->tx_client_lock);
+	ret = store_color_xy(buf, count, color_x, color_y);
+	mutex_unlock(&video_tx_client->tx_client_lock);
+
+	return (ret == 0) ? -EINVAL : ret;
+}
+
+static ssize_t show_red(struct device *dev, struct device_attribute *attr,
+	char *buf)
+{
+	return show_color(dev, buf, color_id_red);
+}
+
+static ssize_t store_red(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count)
+{
+	return store_color(dev, buf, count, color_id_red);
+}
+
+static ssize_t show_green(struct device *dev, struct device_attribute *attr,
+	char *buf)
+{
+	return show_color(dev, buf, color_id_green);
+}
+
+static ssize_t store_green(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count)
+{
+	return store_color(dev, buf, count, color_id_green);
+}
+
+static ssize_t show_blue(struct device *dev, struct device_attribute *attr,
+	char *buf)
+{
+	return show_color(dev, buf, color_id_blue);
+}
+
+static ssize_t store_blue(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count)
+{
+	return store_color(dev, buf, count, color_id_blue);
+}
+
+static ssize_t show_white(struct device *dev, struct device_attribute *attr,
+	char *buf)
+{
+	return show_color(dev, buf, color_id_white);
+}
+
+static ssize_t store_white(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count)
+{
+	return store_color(dev, buf, count, color_id_white);
+}
+
+static ssize_t show_dpms(struct device *dev, struct device_attribute *attr,
+		char *buf)
+{
+	struct video_tx_client_data *video_tx_client = get_from_dev(dev);
+	int state;
+	mutex_lock(&video_tx_client->tx_client_lock);
+	state = video_tx_client->dpms_status;
+	mutex_unlock(&video_tx_client->tx_client_lock);
+
+	return scnprintf(buf, PAGE_SIZE, "%u\n", state);
+}
+
+#define attr_mode (S_IWUGO | S_IRUGO)
+DEVICE_ATTR(disp_connect, attr_mode, show_connect, store_connect);
+DEVICE_ATTR(gamma, attr_mode, show_gamma, store_gamma);
+DEVICE_ATTR(polling, attr_mode, show_polling, store_polling);
+DEVICE_ATTR(red_coords, attr_mode, show_red, store_red);
+DEVICE_ATTR(green_coords, attr_mode, show_green, store_green);
+DEVICE_ATTR(blue_coords, attr_mode, show_blue, store_blue);
+DEVICE_ATTR(white_coords, attr_mode, show_white, store_white);
+DEVICE_ATTR(dpms, S_IRUGO, show_dpms, NULL);
+
+/* attr group */
+static struct attribute *attr_list[] = {
+	&dev_attr_disp_connect.attr,
+	&dev_attr_gamma.attr,
+	&dev_attr_polling.attr,
+	&dev_attr_red_coords.attr,
+	&dev_attr_green_coords.attr,
+	&dev_attr_blue_coords.attr,
+	&dev_attr_white_coords.attr,
+	&dev_attr_dpms.attr,
+	NULL
+};
+
+static struct attribute_group fake_v_tx_attr_group = {
+	.attrs = attr_list,
+};
+
+/* Data zone for a dummy display */
+const struct drm_mode_modeinfo modelist[] = {
+	{ /* 640x480 */
+		.clock = 25175,
+		.hdisplay = 640,
+		.hsync_start = 656,
+		.hsync_end = 752,
+		.htotal = 800,
+		.hskew = 0,
+		.vdisplay = 480,
+		.vsync_start = 490,
+		.vsync_end = 492,
+		.vtotal = 525,
+		.vscan = 0,
+
+		.vrefresh = 60,
+
+		.type = DRM_MODE_TYPE_PREFERRED,
+		.name = {"640x480-60"},
+	},
+	{ /* 1024x768 */
+		.clock = 65000,
+		.hdisplay = 1024,
+		.hsync_start = 1048,
+		.hsync_end = 1184,
+		.htotal = 1344,
+		.hskew = 0,
+		.vdisplay = 768,
+		.vsync_start = 771,
+		.vsync_end = 777,
+		.vtotal = 806,
+		.vscan = 0,
+
+		.vrefresh = 60,
+
+		.name = {"1024x768-60"},
+	},
+	{ /* 640x480 @30Hz */
+		.clock = 12500,
+		.hdisplay = 640,
+		.hsync_start = 656,
+		.hsync_end = 752,
+		.htotal = 800,
+		.hskew = 0,
+		.vdisplay = 480,
+		.vsync_start = 490,
+		.vsync_end = 492,
+		.vtotal = 525,
+		.vscan = 0,
+
+		.vrefresh = 30,
+
+		.name = {"640x480-30"},
+	},
+	{ /* 1920x1080 @24Hz */
+		.clock = 74250,
+		.hdisplay = 1920,
+		.hsync_start = 2558,
+		.hsync_end = 2602,
+		.htotal = 2750,
+		.hskew = 0,
+		.vdisplay = 1080,
+		.vsync_start = 1084,
+		.vsync_end = 1089,
+		.vtotal = 1125,
+		.vscan = 0,
+
+		.vrefresh = 24,
+
+		.name = {"1920x1080-24"},
+	},
+};
+
+
+/* API for transmitter driver */
+static int test_get_modes(struct video_tx_device *dev,
+			  struct drm_mode_modeinfo *mode_info, int n)
+{
+	struct video_tx_client_data *video_tx_client =
+				video_tx_get_drvdata(dev);
+	int min = n < ARRAY_SIZE(modelist) ? n : ARRAY_SIZE(modelist);
+
+	if (video_tx_client->conn_status != connector_status_connected)
+		return -EINVAL;
+	if (mode_info == NULL)
+		return ARRAY_SIZE(modelist);
+
+	memcpy(mode_info, modelist, sizeof(modelist[0]) * min);
+	dev_dbg(video_tx_client->dev, "driver->test_get_modes_list\n");
+	return ARRAY_SIZE(modelist);
+}
+
+static int test_set_mode(struct video_tx_device *dev,
+				struct drm_mode_modeinfo *mode_info)
+{
+	int i = -1;
+	struct video_tx_client_data *video_tx_client =
+				video_tx_get_drvdata(dev);
+
+	if (video_tx_client->conn_status != connector_status_connected)
+		return -EINVAL;
+	if (mode_info == NULL)
+		return -EINVAL;
+
+	mutex_lock(&video_tx_client->tx_client_lock);
+	for (i = 0; i < ARRAY_SIZE(modelist); i++) {
+		if (memcmp(mode_info, modelist+i, sizeof(*mode_info)) == 0) {
+			video_tx_client->current_mode_index = i;
+			break;
+		}
+	}
+	mutex_unlock(&video_tx_client->tx_client_lock);
+
+	dev_dbg(video_tx_client->dev, "driver->test_set_mode\n");
+
+	return (i < ARRAY_SIZE(modelist)) ? 0 : -EINVAL;
+}
+
+static int test_dpms(struct video_tx_device *dev, int status)
+{
+	char *str_dpms;
+	struct video_tx_client_data *video_tx_client =
+				video_tx_get_drvdata(dev);
+
+	switch (status) {
+	case DRM_MODE_DPMS_ON:
+		str_dpms = "DRM_MODE_DPMS_ON";
+		break;
+	case DRM_MODE_DPMS_STANDBY:
+		str_dpms = "DRM_MODE_DPMS_STANDBY";
+		break;
+	case DRM_MODE_DPMS_SUSPEND:
+		str_dpms = "DRM_MODE_DPMS_SUSPEND";
+		break;
+	case DRM_MODE_DPMS_OFF:
+		str_dpms = "DRM_MODE_DPMS_OFF";
+		break;
+	default:
+		dev_err(video_tx_client->dev, "DPMS: unknown status!\n");
+		return -EINVAL;
+	}
+
+	mutex_lock(&video_tx_client->tx_client_lock);
+	video_tx_client->dpms_status = status;
+	dev_dbg(video_tx_client->dev, "driver->dpms( %s )\n",
+			str_dpms);
+	mutex_unlock(&video_tx_client->tx_client_lock);
+
+	return 0;
+}
+
+static int test_get_tx_info(struct video_tx_device *dev,
+				struct video_tx_info *tx_info)
+{
+	struct video_tx_client_data *video_tx_client =
+				video_tx_get_drvdata(dev);
+
+	if (tx_info == NULL)
+		return -ENOMEM;
+
+	memcpy(tx_info, &video_tx_client->dummy_tx_info,
+			sizeof(struct video_tx_info));
+	dev_dbg(video_tx_client->dev, "driver->get_tx_info\n");
+	return 0;
+}
+
+static int test_get_display_info(struct video_tx_device *dev,
+		struct video_tx_display_info *disp_info)
+{
+	struct video_tx_client_data *video_tx_client =
+				video_tx_get_drvdata(dev);
+
+	if (disp_info == NULL)
+		return -ENOMEM;
+	if (video_tx_client->conn_status != connector_status_connected)
+		return -EINVAL;
+
+	memcpy(disp_info, &video_tx_client->dummy_display_info,
+			sizeof(struct video_tx_display_info));
+	dev_dbg(video_tx_client->dev, "driver->get_display_info\n");
+	return 0;
+}
+
+static enum drm_connector_status test_detect(
+				struct video_tx_device *dev)
+{
+	struct video_tx_client_data *video_tx_client =
+			video_tx_get_drvdata(dev);
+
+	dev_dbg(video_tx_client->dev, "driver->detect\n");
+	return video_tx_client->conn_status;
+}
+
+static struct video_tx_driver test_driver_tx = {
+	.get_modes = test_get_modes,
+	.set_mode = test_set_mode,
+	.dpms = test_dpms,
+	.get_tx_info = test_get_tx_info,
+	.detect = test_detect,
+	.get_display_info = test_get_display_info
+};
+
+/* methods for video_tx_client */
+static int client_init(struct device *dev)
+{
+	int ret = 0;
+	struct video_tx_client_data	*video_tx_client;
+	struct video_tx_device *v_tx_dev;
+
+	video_tx_client = devm_kzalloc(dev, sizeof(*video_tx_client),
+						GFP_KERNEL);
+	if (video_tx_client == NULL)
+		return -ENOMEM;
+
+	mutex_init(&video_tx_client->tx_client_lock);
+
+	snprintf(video_tx_client->dummy_tx_info.name,
+			DRM_CONNECTOR_NAME_LEN,
+			"Generic Video");
+	video_tx_client->dummy_tx_info.connector_type =
+				DRM_MODE_CONNECTOR_VGA;
+	video_tx_client->dummy_tx_info.idx = 0;
+	video_tx_client->dummy_tx_info.red_bits = 8;
+	video_tx_client->dummy_tx_info.green_bits = 8;
+	video_tx_client->dummy_tx_info.blue_bits = 8;
+
+	video_tx_client->dummy_display_info.gamma = 0; /* real gamma 1.0 */
+
+	/* Default color space coordinates (10bits)
+	 * The data comes from DELL 1930MWc
+	 */
+	video_tx_client->dummy_display_info.red_x = 655;
+	video_tx_client->dummy_display_info.red_y = 338;
+	video_tx_client->dummy_display_info.blue_x = 154;
+	video_tx_client->dummy_display_info.blue_y = 61;
+	video_tx_client->dummy_display_info.green_x = 307;
+	video_tx_client->dummy_display_info.green_y = 614;
+	video_tx_client->dummy_display_info.white_x = 321;
+	video_tx_client->dummy_display_info.white_y = 337;
+
+	/*
+	 * Because the resolution used by FPGA is 640x480, for generating
+	 * a proper dpi for android home screen, we set the example display
+	 * size to 3.7 inch.
+	 */
+	video_tx_client->dummy_display_info.width_mm = 76;
+	video_tx_client->dummy_display_info.height_mm = 57;
+
+	video_tx_client->conn_status = connector_status_connected;
+	video_tx_client->dev = dev;
+
+	ret = sysfs_create_group(&dev->kobj,
+					&fake_v_tx_attr_group);
+	if (ret) {
+		dev_err(dev, "sysfs for video tx client error\n");
+		return ret;
+	}
+
+	v_tx_dev = video_tx_register_device(dev, &test_driver_tx);
+	if (v_tx_dev == NULL) {
+		dev_err(dev, "register video tx device error.\n");
+		return -EINVAL;
+	}
+
+	ret = dev_set_drvdata(dev, v_tx_dev);
+	if (ret) {
+		video_tx_unregister_device(v_tx_dev);
+		return ret;
+	}
+
+	video_tx_client->polling_enabled = true;
+	video_tx_set_drvdata(v_tx_dev, video_tx_client);
+	video_tx_request_polling(v_tx_dev);
+
+	return ret;
+}
+
+static void client_destroy(struct device *dev)
+{
+	struct video_tx_device *v_tx_dev;
+	struct video_tx_client_data *video_tx_client;
+
+	sysfs_remove_group(&dev->kobj, &fake_v_tx_attr_group);
+
+	v_tx_dev = dev_get_drvdata(dev);
+	if (v_tx_dev != NULL) {
+		video_tx_client = video_tx_get_drvdata(v_tx_dev);
+		if (video_tx_client->polling_enabled == true)
+			video_tx_cancel_polling(v_tx_dev);
+		video_tx_unregister_device(v_tx_dev);
+	}
+}
+
+/* module entry and exit functions */
+static int video_tx_probe(struct platform_device *pdev)
+{
+	int ret = client_init(&pdev->dev);
+
+	if (ret != 0)
+		return ret;
+
+	dev_dbg(&pdev->dev, "fake video tx client driver is loaded.\n");
+	return 0;
+}
+
+static int video_tx_remove(struct platform_device *pdev)
+{
+	client_destroy(&pdev->dev);
+	dev_dbg(&pdev->dev, "fake video tx client driver is removed.\n");
+	return 0;
+}
+
+static const struct of_device_id video_transmitter_ids[] = {
+	{ .compatible = "generic,video_transmitter" },
+	{ /*empty*/ }
+};
+
+static struct platform_driver f_video_tx_client = {
+	.probe = video_tx_probe,
+	.remove = video_tx_remove,
+	.driver = {
+		.name = TEST_VD_TX_DEV,
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(video_transmitter_ids),
+	},
+};
+
+module_platform_driver(f_video_tx_client);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Fake_Video_TX_driver");
diff --git a/drivers/video/video-tx/video_tx.c b/drivers/video/video-tx/video_tx.c
new file mode 100644
index 0000000..b232d53
--- /dev/null
+++ b/drivers/video/video-tx/video_tx.c
@@ -0,0 +1,489 @@
+/*
+ *
+ * (C) COPYRIGHT 2014 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+/*
+ * Global list containing all the video_tx_device registered with the
+ * framework and a mutext to protect all accesses.
+ */
+
+#include <linux/i2c.h>
+#include <linux/module.h>
+#include <linux/of_i2c.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/workqueue.h>
+
+#include <video/video_tx.h>
+
+#define DEFAULT_POLLING_PERIOD_MS 500
+#define WQ_MAX_NAME 50
+
+static DEFINE_MUTEX(client_mutex);
+static LIST_HEAD(video_tx_list);
+static struct workqueue_struct *video_tx_wq;
+static u16 polling_period_ms = DEFAULT_POLLING_PERIOD_MS;
+
+struct video_tx_device {
+	struct list_head list;
+	struct device *dev;
+	const struct video_tx_driver *driver;
+	/* Protects the notifier block for adding/removing listeners */
+	struct mutex mutex;
+	struct blocking_notifier_head notifier;
+	struct delayed_work polling_dwork;
+	enum drm_connector_status cached_status;
+	bool polling_enabled;
+	void *private;
+};
+
+/*
+ * Search the "video_tx_list" to get a "struct video_tx_device"
+ * whose "dev" field is equal to the argument of the function.
+ */
+static struct video_tx_device *find_video_tx_by_dev(struct device *dev)
+{
+	struct video_tx_device *tx_device;
+
+	mutex_lock(&client_mutex);
+	list_for_each_entry(tx_device, &video_tx_list, list) {
+		if (tx_device->dev == dev) {
+			mutex_unlock(&client_mutex);
+			return tx_device;
+		}
+	}
+	mutex_unlock(&client_mutex);
+
+	return NULL;
+}
+
+/** Called from the host driver **/
+
+/**
+ * of_find_video_tx_by_node - find a video_tx from a device tree node
+ *
+ * @node: device tree node of the video transmitter
+ *
+ * This function will be called by the host in order to get a reference
+ * to the video transmitter structure.
+ *
+ */
+struct video_tx_device *of_find_video_tx_by_node(struct device_node *node)
+{
+	struct i2c_client *i2c;
+	struct platform_device *pdev;
+	struct device *dev;
+
+	/* The device can be either in the i2c bus or in the platform bus */
+	i2c = of_find_i2c_device_by_node(node);
+	pdev = of_find_device_by_node(node);
+	if (i2c)
+		dev = &i2c->dev;
+	else if (pdev)
+		dev = &pdev->dev;
+	else {
+		pr_err("%s: could not find a device matching the dt node\n",
+			__func__);
+		return NULL;
+	}
+
+	return find_video_tx_by_dev(dev);
+}
+EXPORT_SYMBOL_GPL(of_find_video_tx_by_node);
+
+/**
+ * video_tx_hotplug_notifier_register - register hotplug notifier
+ *
+ * @video_tx: pointer to the video tx device_node
+ * @nb: pointer to the notifier block provided by the host
+ *
+ * This function will be called by the host in order to show that it is
+ * interested on receiving hotplug notifications from the client.
+ *
+ * It cannot be called from an atomic context.
+ *
+ */
+void video_tx_hotplug_notifier_register(struct video_tx_device *video_tx,
+					struct notifier_block *nb)
+{
+	mutex_lock(&video_tx->mutex);
+	blocking_notifier_chain_register(&video_tx->notifier, nb);
+	mutex_unlock(&video_tx->mutex);
+}
+EXPORT_SYMBOL_GPL(video_tx_hotplug_notifier_register);
+
+/**
+ * video_tx_hotplug_notifier_unregister - unregister hotplug notifier
+ *
+ * @video_tx: pointer to the video tx device_node
+ * @nb: pointer to the notifier block provided by the host
+ *
+ * This function will be called by the host in order to show that it's
+ * no longer interested on receiving hotplug notifications from the client.
+ *
+ * It cannot be called from an atomic context.
+ *
+ */
+void video_tx_hotplug_notifier_unregister(struct video_tx_device *video_tx,
+					struct notifier_block *nb)
+{
+	mutex_lock(&video_tx->mutex);
+	blocking_notifier_chain_unregister(&video_tx->notifier, nb);
+	mutex_unlock(&video_tx->mutex);
+}
+EXPORT_SYMBOL_GPL(video_tx_hotplug_notifier_unregister);
+
+/**
+ * video_tx_get_modes - get a list of the modes supported by a video tx
+ *
+ * @video_tx: pointer to the video tx device_node
+ * @modelist: list of modes to be fill in by the client
+ * @n: if modelist is not NULL, the number of modes there is space for
+ *
+ * This function will be called by the host in order to get the list of
+ * modes supported by the video transmitter.
+ *
+ * If modelist is not NULL the client will write at most @a n modes into
+ * the memory area pointed by this variable. If the returned value does not
+ * match @a n, then the available mode list has changed, and the host should
+ * repeat the process to get the correct modelist.
+ *
+ * The function will return the number of supported modes or negative on error.
+ */
+int video_tx_get_modes(struct video_tx_device *video_tx,
+		       struct drm_mode_modeinfo *modelist, int n)
+{
+	if (!video_tx->driver->get_modes)
+		return -EINVAL;
+
+	return video_tx->driver->get_modes(video_tx, modelist, n);
+}
+EXPORT_SYMBOL_GPL(video_tx_get_modes);
+
+/**
+ * video_tx_set_mode - set the mode of a video tx
+ *
+ * @video_tx: pointer to the video tx device
+ * @mode: the mode we want to set in the video tx
+ *
+ * This function will be called by a host in order to set the mode of a
+ * client video tx.
+ *
+ * It will return 0 on success and negative if the mode cannot be set.
+ *
+ */
+int video_tx_set_mode(struct video_tx_device *video_tx,
+				struct drm_mode_modeinfo *mode)
+{
+	if (!video_tx->driver->set_mode)
+		return -EINVAL;
+
+	return video_tx->driver->set_mode(video_tx, mode);
+}
+EXPORT_SYMBOL_GPL(video_tx_set_mode);
+
+/**
+ * video_tx_dpms - set the power status of a video tx
+ *
+ * @video_tx: pointer to the video tx device
+ * @mode: the power status we want to put the device into
+ *	(follows the  DRM_MODE_DPMS definitions)
+ *
+ * This function will be called by a host in order to change the power
+ * mode of a video tx client.
+ *
+ * It will return 0 on success and negative on error.
+ *
+ */
+int video_tx_dpms(struct video_tx_device *video_tx, int mode)
+{
+	if (!video_tx->driver->dpms)
+		return -EINVAL;
+
+	return video_tx->driver->dpms(video_tx, mode);
+}
+EXPORT_SYMBOL_GPL(video_tx_dpms);
+
+/**
+ * video_tx_get_info - get the platform specific information from the video TX
+ *
+ * @video_tx: pointer to the video tx device
+ * @info: pointer to the video_tx_info structure that will be filled in by the
+ *	client video tx.
+ *
+ * It will return 0 on success and negative on error.
+ *
+ */
+int video_tx_get_info(struct video_tx_device *video_tx,
+		      struct video_tx_info *info)
+{
+	if (!video_tx->driver->get_tx_info)
+		return -EINVAL;
+
+	return video_tx->driver->get_tx_info(video_tx, info);
+}
+EXPORT_SYMBOL_GPL(video_tx_get_info);
+
+/**
+ * video_tx_get_display_info - get the display specific information from the TX
+ *
+ * @video_tx: pointer to the video tx device
+ * @info: pointer to the video_tx_display_info structure that will be filled in
+ *	by the client video tx.
+ *
+ * It will return 0 on success and negative on error.
+ *
+ */
+int video_tx_get_display_info(struct video_tx_device *video_tx,
+		      struct video_tx_display_info *info)
+{
+	if (!video_tx->driver->get_display_info)
+		return -EINVAL;
+
+	return video_tx->driver->get_display_info(video_tx, info);
+}
+EXPORT_SYMBOL_GPL(video_tx_get_display_info);
+
+/**
+ * video_tx_detect - get the current status of the video transmitter
+ *
+ * @video_tx: pointer to the video tx device
+ *
+ * This function will be called by a host that is interested on knowing
+ * the hotplug status of a video transmitter.
+ *
+ */
+enum drm_connector_status video_tx_detect(struct video_tx_device *video_tx)
+{
+	if (!video_tx->driver->detect)
+		return -EINVAL;
+
+	return video_tx->driver->detect(video_tx);
+}
+EXPORT_SYMBOL_GPL(video_tx_detect);
+
+/** Called from the video transmitter client **/
+
+/**
+ * video_tx_report_hotplug_event - report a hotplug event to the framework
+ *
+ * @tx_device: pointer to the video tx device
+ *
+ * This function will be called by the video transmitter client when a new
+ * hotplug event occurs. The framework will then signal the notifier so that
+ * any hosts listening can get their notifier callbacks executed.
+ *
+ * Cannot be called from an atomic context.
+ */
+void video_tx_report_hotplug_event(struct video_tx_device *tx_device)
+{
+	enum drm_connector_status s;
+
+	if (!tx_device->driver->detect) {
+		dev_warn(tx_device->dev, "detect() not implemented\n");
+		return;
+	}
+
+	s = tx_device->driver->detect(tx_device);
+
+	blocking_notifier_call_chain(&tx_device->notifier, s, tx_device);
+}
+EXPORT_SYMBOL_GPL(video_tx_report_hotplug_event);
+
+static void video_tx_polling_work(struct work_struct *work)
+{
+	struct video_tx_device *tx_device =
+		container_of(work, struct video_tx_device, polling_dwork.work);
+	enum drm_connector_status s = tx_device->driver->detect(tx_device);
+
+	mutex_lock(&tx_device->mutex);
+	if (s != tx_device->cached_status) {
+		tx_device->cached_status = s;
+		blocking_notifier_call_chain(&tx_device->notifier, s,
+					     tx_device);
+	}
+
+	/* Queue work for the next period unless polling is disabled */
+	if (tx_device->polling_enabled)
+		queue_delayed_work(video_tx_wq, &tx_device->polling_dwork,
+				   msecs_to_jiffies(polling_period_ms));
+	mutex_unlock(&tx_device->mutex);
+}
+
+/**
+ * video_tx_request_polling - use polling for hotplugs instead of interrupts
+ *
+ * @tx_device: pointer to the video tx device
+ *
+ * This function can be called by the video_tx client if this does not support
+ * hotplug interrupts. The video tx framework will launch a kernel thread that
+ * will perform polling instead by periodically calling detect() in the client.
+ *
+ * Cannot be called from an atomic context.
+ */
+void video_tx_request_polling(struct video_tx_device *tx_device)
+{
+	if (!tx_device->driver->detect) {
+		dev_warn(tx_device->dev, "detect() not implemented\n");
+		return;
+	}
+
+	mutex_lock(&tx_device->mutex);
+	if (!tx_device->polling_enabled) {
+		tx_device->cached_status =
+			tx_device->driver->detect(tx_device);
+
+		queue_delayed_work(video_tx_wq, &tx_device->polling_dwork,
+				msecs_to_jiffies(polling_period_ms));
+		tx_device->polling_enabled = true;
+	}
+	mutex_unlock(&tx_device->mutex);
+}
+EXPORT_SYMBOL_GPL(video_tx_request_polling);
+
+/**
+ * video_tx_cancel_polling - cancel the polling thread
+ *
+ * @tx_device: pointer to the video tx device
+ *
+ * This function will be called by the video tx client when it is no longer
+ * interested in reporting hotplug events through polling. After this function
+ * returns it is guaranteed that the polling thread will not call detect()
+ * anymore in the client.
+ *
+ * Cannot be called from an atomic context.
+ */
+void video_tx_cancel_polling(struct video_tx_device *tx_device)
+{
+	mutex_lock(&tx_device->mutex);
+	tx_device->polling_enabled = false;
+	cancel_delayed_work_sync(&tx_device->polling_dwork);
+	mutex_unlock(&tx_device->mutex);
+}
+EXPORT_SYMBOL(video_tx_cancel_polling);
+
+/**
+ * video_tx_register_device - register a video tx with the framework
+ *
+ * @dev: pointer to the video transmitter device structure
+ * @driver: pointer to the driver structure that contains all the ops
+ *
+ * This function will register a video transmitter client with the video_tx
+ * framework.
+ * It will return a pointer to the newly allocated video_tx_device structure or
+ * NULL in case of an error.
+ *
+ * The video tx driver needs to call this function before using any of the
+ * other facilities of the framework.
+ *
+ */
+struct video_tx_device *video_tx_register_device(struct device *dev,
+					struct video_tx_driver *driver)
+{
+	struct video_tx_device *tx_device;
+
+	tx_device = kzalloc(sizeof(struct video_tx_device), GFP_KERNEL);
+	if (!tx_device)
+		return NULL;
+
+	INIT_LIST_HEAD(&tx_device->list);
+	tx_device->dev = dev;
+	tx_device->driver = driver;
+	mutex_init(&tx_device->mutex);
+	BLOCKING_INIT_NOTIFIER_HEAD(&tx_device->notifier);
+	INIT_DELAYED_WORK(&tx_device->polling_dwork, video_tx_polling_work);
+	tx_device->polling_enabled = false;
+
+	/* Add it to the global list of registered drivers */
+	mutex_lock(&client_mutex);
+	list_add_tail(&tx_device->list, &video_tx_list);
+	mutex_unlock(&client_mutex);
+
+	return tx_device;
+}
+EXPORT_SYMBOL_GPL(video_tx_register_device);
+
+/**
+ * video_tx_unregister_device - unregister a video tx with the framework
+ *
+ * @tx_device: pointer to the video tx device
+ *
+ */
+void video_tx_unregister_device(struct video_tx_device *tx_device)
+{
+
+	mutex_lock(&client_mutex);
+	list_del(&tx_device->list);
+	mutex_unlock(&client_mutex);
+
+	mutex_lock(&tx_device->mutex);
+	if (tx_device->polling_enabled) {
+		tx_device->polling_enabled = false;
+		cancel_delayed_work_sync(&tx_device->polling_dwork);
+	}
+	mutex_unlock(&tx_device->mutex);
+
+	tx_device->driver = NULL;
+	tx_device->dev = NULL;
+	tx_device->private = NULL;
+
+	kfree(tx_device);
+}
+EXPORT_SYMBOL_GPL(video_tx_unregister_device);
+
+void video_tx_set_drvdata(struct video_tx_device *tx_device, void *data)
+{
+	tx_device->private = data;
+}
+EXPORT_SYMBOL_GPL(video_tx_set_drvdata);
+
+void *video_tx_get_drvdata(struct video_tx_device *tx_device)
+{
+	return tx_device->private;
+}
+EXPORT_SYMBOL_GPL(video_tx_get_drvdata);
+
+/* Module boilerplate */
+static int __init video_tx_init(void)
+{
+	video_tx_wq = create_singlethread_workqueue("video-tx-polling");
+	if (!video_tx_wq) {
+		pr_err("video-tx: could not initialize work queue\n");
+		return -ENOMEM;
+	}
+
+	pr_info("video-tx: initialized (polling_period_ms = %hu)\n",
+		polling_period_ms);
+
+	return 0;
+}
+module_init(video_tx_init);
+
+static void __exit video_tx_exit(void)
+{
+	if (video_tx_wq)
+		destroy_workqueue(video_tx_wq);
+
+	WARN_ON(!list_empty(&video_tx_list));
+}
+module_exit(video_tx_exit);
+
+module_param(polling_period_ms, ushort, 0444);
+MODULE_PARM_DESC(polling_period_ms, "Period in ms of the hotplug polling thread");
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Video-TX Framework");
diff --git a/include/uapi/video/malidp_adf.h b/include/uapi/video/malidp_adf.h
new file mode 100644
index 0000000..18a2489
--- /dev/null
+++ b/include/uapi/video/malidp_adf.h
@@ -0,0 +1,290 @@
+/*
+ *
+ * (C) COPYRIGHT 2013-2015 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _UAPI_MALIDP_ADF_H_
+#define _UAPI_MALIDP_ADF_H_
+
+#include <linux/ioctl.h>
+#include <linux/types.h>
+#include <drm/drm_fourcc.h>
+#include <video/adf.h>
+
+/* Product identification */
+#define MALIDP_CORE_ID(__product, __major, __minor, __status) \
+	((((__product) & 0xFFFF) << 16) | (((__major) & 0xF) << 12) | \
+	(((__minor) & 0xF) << 8) | ((__status) & 0xFF))
+#define MALIDP_CORE_ID_PRODUCT_ID(__core_id) ((u32)(__core_id) >> 16)
+#define MALIDP_CORE_ID_MAJOR(__core_id)      (((u32)(__core_id) >> 12) & 0xF)
+#define MALIDP_CORE_ID_MINOR(__core_id)      (((u32)(__core_id) >> 8) & 0xF)
+#define MALIDP_CORE_ID_STATUS(__core_id)     (((u32)(__core_id)) & 0xFF)
+
+#define MALIDP_DP500_PRODUCT_ID 0x0500
+#define MALIDP_DP550_PRODUCT_ID 0x0550
+
+/* Custom pixel formats */
+#define MALIDP_FORMAT_XYUV	fourcc_code('M', 'X', 'Y', 'V') /* [31:0] X:Y:Cb:Cr 8:8:8:8 little endian */
+#define MALIDP_FORMAT_VYU30	fourcc_code('M', 'V', '3', '0') /* [31:0] X:Cr:Y:Cb 2:10:10:10 little endian */
+#define MALIDP_FORMAT_NV12AFBC	fourcc_code('M', '1', '2', 'A') /* AFBC compressed YUV 4:2:0, 8 bits per component */
+#define MALIDP_FORMAT_NV16AFBC	fourcc_code('M', '1', '6', 'A') /* AFBC compressed YUV 4:2:2, 8 bits per component */
+#define MALIDP_FORMAT_YUV10_420AFBC	fourcc_code('M', '3', '0', 'A') /* AFBC compressed YUV 4:2:0, 10 bits per component */
+#define MALIDP_FORMAT_Y0L2	fourcc_code('Y', '0', 'L', '2') /* YUV 4:2:0, ARM linear 10-bit packed format */
+/* YUV 4:2:0, 10-bit per component, 2 plane.
+ * Each sample packed into the top 10 bits of a 16-bit word.
+ * Plane 0: [63:0] Y3:x:Y2:x:Y1:x:Y0, 10:6:10:6:10:6:10:6
+ * Plane 1: [63:0] V02:x:U02:x:V00:x:U00, 10:6:10:6:10:6:10:6
+ */
+#define MALIDP_FORMAT_P010	fourcc_code('P', '0', '1', '0')
+
+/* Custom interface types */
+#define MALIDP_INTF_LVDS    (ADF_INTF_TYPE_DEVICE_CUSTOM + 1)
+#define MALIDP_INTF_VIRTUAL (ADF_INTF_TYPE_DEVICE_CUSTOM + 2)
+#define MALIDP_INTF_MEMORY  (ADF_INTF_TYPE_DEVICE_CUSTOM + 3)
+#define MALIDP_INTF_UNKNOWN (ADF_INTF_TYPE_DEVICE_CUSTOM + 4)
+
+/* Flags to describe blending mode */
+#define MALIDP_ALPHA_MODE_NONE    (1 << 0)
+#define MALIDP_ALPHA_MODE_LAYER   (0 << 1)
+#define MALIDP_ALPHA_MODE_PIXEL   (1 << 1)
+#define MALIDP_ALPHA_MODE_NO_BG   (0 << 2)
+#define MALIDP_ALPHA_MODE_W_BG    (1 << 2)
+#define MALIDP_ALPHA_MODE_PREMULT (1 << 3)
+
+/* Flags to describe transformation
+ * Rotations are in a counter-clockwise direction */
+#define MALIDP_TRANSFORM_SET_R(X) (((X) & 0x3) << 0)
+#define MALIDP_TRANSFORM_GET_R(X) (((X) >> 0) & 0x3)
+#define MALIDP_TRANSFORM_R0       0
+#define MALIDP_TRANSFORM_R90      1
+#define MALIDP_TRANSFORM_R180     2
+#define MALIDP_TRANSFORM_R270     3
+#define MALIDP_TRANSFORM_HFLIP    (1 << 2)
+#define MALIDP_TRANSFORM_VFLIP    (1 << 3)
+
+/* Flags for other things */
+#define MALIDP_FLAG_BUFFER_INPUT    (0 << 0)
+#define MALIDP_FLAG_BUFFER_OUTPUT   (1 << 0)
+#define MALIDP_FLAG_YUV_MASK        (3 << 1)
+#define MALIDP_FLAG_YUV_BT601       (0 << 1)
+#define MALIDP_FLAG_YUV_BT709       (1 << 1)
+#define MALIDP_FLAG_YUV_NARROW      (0 << 2)
+#define MALIDP_FLAG_YUV_WIDE        (1 << 2)
+#define MALIDP_FLAG_AFBC            (1 << 3)
+#define MALIDP_FLAG_AFBC_YTR        (1 << 4)
+/*
+ * This forces inverse-gamma-correction to be disabled, which is enabled by
+ * default for YUV buffers and always disabled for RGB buffers
+ */
+#define MALIDP_FLAG_FORCE_NO_IGAMMA (1 << 5)
+#define MALIDP_FLAG_SRGB	    (1 << 6)
+#define MALIDP_FLAG_AFBC_SPLITBLK   (1 << 7)
+#define MALIDP_FLAG_SMART_BBOX      (1 << 8)
+
+/* Layer feature descriptors */
+#define MALIDP_LAYER_FEATURE_SCALING   (1 << 0)
+#define MALIDP_LAYER_FEATURE_TRANSFORM (1 << 1)
+#define MALIDP_LAYER_FEATURE_AFBC      (1 << 2)
+#define MALIDP_LAYER_FEATURE_SRGB      (1 << 3)
+
+/* Flags to describe the strategy used for partitioning
+ * rotation memory
+ */
+
+/*
+ * MALIDP_ROTMEM_PARTITION_FIXED
+ * The hardware paritions memory in a fixed pattern based on the number of
+ * layers using the rotation memory. Rotation memory is used by buffers
+ * that meet one or more of the following criteria:
+ *  * Are rotated by 90 or 270 degrees
+ *  * Are compressed with AFBC (with or without rotation)
+ *
+ * The fixed partitions use the following pattern:
+ * | Number of buffers in rotation memory | Buffer 1 | Buffer 2 | Buffer 3 |
+ * |                  1                   |   100%   |   N/A    |    N/A   |
+ * |                  2                   |    50%   |   50%    |    N/A   |
+ * |                  3                   |    50%   |   25%    |    25%   |
+ */
+#define MALIDP_ROTMEM_PARTITION_FIXED (1 << 0)
+
+#define MALIDP_MAX_N_FORMATS 64
+
+#define MALIDP_N_GAMMA_COEFFS 64
+
+struct malidp_buffer_config {
+	/* The index of the adf_buffer_config which this malidp config relates
+	 * to */
+	__u32 adf_buffer_index;
+
+	/* The ID of the interface which this config relates to */
+	__u32 adf_intf_id;
+
+	/* The on-screen size/position of the buffer (per interface) */
+	__u16 display_top;
+	__u16 reserved1;
+	__u16 display_left;
+	__u16 reserved2;
+
+	/* The display dimensions are given after any scaling has been
+	 * applied (but before any rotate operation) */
+	__u16 display_width;
+	__u16 reserved3;
+	__u16 display_height;
+	__u16 reserved4;
+
+	/* The transformation to be applied. The application must ensure that
+	 * this field is consistent for all malidp_buffer_configs which target
+	 * a particular adf_buffer_config */
+	__u32 transform;
+
+	/* Special purpose flags. Bitwise-or of MALIDP_FLAG_XX */
+	__u32 flags;
+
+	/* Alpha blending parameters in case of composition */
+	__u32 alpha_mode; /* Bitwise OR of MALIDP_ALPHA_MODE_XX */
+	__u8 layer_alpha; /* 0xFF is opaque */
+	__u8 pad[3];
+
+	/* AFBC-specific fields */
+	__u16 afbc_crop_l;
+	__u16 afbc_crop_r;
+	__u16 afbc_crop_t;
+	__u16 afbc_crop_b;
+
+};
+
+struct malidp_post_data_hdr {
+	__u32 type;
+	__u32 size;
+};
+
+struct malidp_custom_data {
+	struct malidp_post_data_hdr reserved;
+
+	/* This is the total number of custom buffer descriptions included.
+	 * It can be up to n_bufs * n_interfaces (one config per interface per
+	 * buffer)
+	 */
+	__u32 n_malidp_buffer_configs;
+
+	/* The size of each buffer config, allows for future expansion, and for
+	 * user/kernel space to have mismatched struct descriptions */
+	__u32 sizeof_malidp_buffer_config;
+
+	/* Everything past this point is an array of malidp_buffer_configs */
+	struct malidp_buffer_config buffers[];
+};
+
+struct malidp_adf_overlay_custom_data {
+	/* Non-zero if this overlay engine can be scaled. Should not be used
+	 * by new software, use the features field instead.
+	 */
+	__u32 supports_scaling;
+	/* Bitwise-OR of MALIDP_LAYER_FEATURE_xxx supported by this overlay */
+	__u32 features;
+	/* The number of layers supported by this overlay engine */
+	__u32 n_supported_layers;
+	__u32 pad;
+};
+
+struct malidp_adf_intf_custom_data {
+	__u8 gamma; /* gamma value as returned by the EDID standard */
+	/* (u16, u16) binary fixed point.
+	 * (h_input*v_input)/v_output should be less than threshold.
+	 */
+	__u32 downscaling_threshold;
+};
+
+struct malidp_adf_device_custom_data {
+	/* Information about the available rotation memory*/
+	__u32 rotation_memory_size; /* Size of available memory in bytes */
+	__u32 rotation_memory_strategy; /* Bitwise-or of MALIDP_ROTMEM_* */
+
+	__u32 n_scalers; /* The number of scaling blocks available */
+
+	/* Minimum and maximum supported dimensions for a layer (in pixels) */
+	__u32 min_width;
+	__u32 min_height;
+	__u32 max_width;
+	__u32 max_height;
+
+	/* The number of AFBC pixel formats supported by this device */
+	__u32 n_supported_afbc_formats;
+	/* List of AFBC pixel formats supported by this device */
+	__u32 supported_afbc_formats[MALIDP_MAX_N_FORMATS];
+
+	/* The number of write-back pixel formats supported by this device */
+	__u32 n_supported_mw_formats;
+	/* List of write-back pixel formats supported by this device */
+	__u32 supported_mw_formats[MALIDP_MAX_N_FORMATS];
+	/* The number of unsupported transform formats */
+	__u32 n_xform_invalid_formats;
+	/* The bitfield AFBC formats which support split block */
+	__u64 supported_afbc_splitblk;
+	/* List of unsupported transform formats */
+	__u32 xform_invalid_formats[MALIDP_MAX_N_FORMATS];
+};
+
+#define MALIDP_ADF_EVENT_FLIP (ADF_EVENT_DEVICE_CUSTOM + 1)
+
+/**
+ * struct adf_flip_event - a new scene was posted on the screen
+ *
+ * A flip event always occurrs at the same time than an standard vsync event.
+ * So they will have exactly the same timestamp.
+ *
+ * @base: event header
+ * @timestamp: time of flip event, in nanoseconds
+ */
+struct malidp_adf_flip_event {
+	struct adf_event base;
+	__aligned_u64 timestamp;
+};
+
+/**
+ * struct malidp_adf_get_output_fence - retrieve an output fence from kernel
+ * space. This can only be used on interfaces of type ADF_INTF_MEMORY.
+ *
+ * @output_fence: sync_fence fd which will clear when the output buffer has
+ * been written out.
+ *
+ */
+struct malidp_adf_get_output_fence {
+	__s32 output_fence;
+};
+
+/**
+ * struct malidp_adf_set_gamma - enable/disable the gamma correction and
+ * program the HW gamma coef. table.
+ * This can only be used on the primary interface.
+ *
+ * @enable: enable/disable the gamma correction.
+ * @coefficient: the gamma coeff. table for HW.
+ *
+ */
+struct malidp_adf_set_gamma {
+	__u32 enable;
+	__u32 pad;	/* align to 64bit */
+
+	__u32 coefficient[MALIDP_N_GAMMA_COEFFS];
+};
+
+#define MALIDP_ADF_IOCTL_GET_OUTPUT_FENCE _IOR('D', 128, \
+					struct malidp_adf_get_output_fence)
+
+#define MALIDP_ADF_IOCTL_SET_GAMMA		  _IOW('D', 129, \
+					struct malidp_adf_set_gamma)
+
+#endif /* _UAPI_MALIDP_ADF_H_ */
diff --git a/include/video/video_tx.h b/include/video/video_tx.h
new file mode 100644
index 0000000..158ec2c
--- /dev/null
+++ b/include/video/video_tx.h
@@ -0,0 +1,112 @@
+/*
+ *
+ * (C) COPYRIGHT 2014 ARM Limited. All rights reserved.
+ *
+ * This program is free software and is provided to you under the terms of the
+ * GNU General Public License version 2 as published by the Free Software
+ * Foundation, and any use by you of this program is subject to the terms
+ * of such GNU licence.
+ *
+ * A copy of the licence is included with the program, and can also be obtained
+ * from Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA  02110-1301, USA.
+ *
+ */
+
+
+
+#ifndef _VIDEO_TX_H_
+#define _VIDEO_TX_H_
+
+#include <drm/drm_crtc.h>
+#include <uapi/drm/drm_mode.h>
+
+struct video_tx_device;
+
+/* Platform-specific information */
+struct video_tx_info {
+	/* A descriptive name of the output */
+	char name[DRM_CONNECTOR_NAME_LEN];
+	/* The type of connector, one of DRM_MODE_CONNECTOR_XXX */
+	u32 connector_type;
+	/* The ID number of this connector (i.e. HDMI0 vs HDMI1) */
+	u32 idx;
+	/* Bits used for each component by the transmitter */
+	u8 red_bits;
+	u8 green_bits;
+	u8 blue_bits;
+};
+
+/* Display-specific information */
+struct video_tx_display_info {
+	/*
+	 * gamma value as reported by the EDID standard, where the real gamma
+	 * value can be obtained using the formula:
+	 *	real_gamma = (edid_gamma + 100) / 100
+	 * This means only gamma values from 1 to 3.54 can be represented.
+	 */
+	u8 gamma;
+	/*
+	 * xy CIE coordinates of the display. These coordinates should be in
+	 * 10bits representing values from 0 to 1023/1024 as reported by the
+	 * EDID standard.
+	 */
+	u16 red_x, red_y;
+	u16 green_x, green_y;
+	u16 blue_x, blue_y;
+	u16 white_x, white_y;
+	/*
+	 * Physical display dimensions. EDID uses a maximum of 12 bits which
+	 * allows values from 0 to 4095 but we use up to 16 bits in our API
+	 * which allows values up to 65535. In any case, these parameters are
+	 * interpreted as regular unsigned integers.
+	 */
+	u16 width_mm, height_mm;
+};
+
+struct video_tx_driver {
+	/* client driver ops */
+	/* Retrieve a list of modes supported by the display */
+	int (*get_modes)(struct video_tx_device *,
+			 struct drm_mode_modeinfo *, int n);
+	/* Set a mode in the display */
+	int (*set_mode)(struct video_tx_device *, struct drm_mode_modeinfo *);
+	/* Set the DPMS status of the display */
+	int (*dpms)(struct video_tx_device *, int);
+	/* Get the platform specific information */
+	int (*get_tx_info)(struct video_tx_device *, struct video_tx_info *);
+	/* Get the display specific information */
+	int (*get_display_info)(struct video_tx_device *,
+				  struct video_tx_display_info *);
+	/* Detect whether a display is connected or not */
+	enum drm_connector_status (*detect)(struct video_tx_device *);
+};
+
+/* Host functions */
+struct video_tx_device *of_find_video_tx_by_node(struct device_node *node);
+void video_tx_hotplug_notifier_register(struct video_tx_device *video_tx,
+					struct notifier_block *nb);
+void video_tx_hotplug_notifier_unregister(struct video_tx_device *video_tx,
+					struct notifier_block *nb);
+int video_tx_get_modes(struct video_tx_device *video_tx,
+		       struct drm_mode_modeinfo *modelist, int n);
+int video_tx_set_mode(struct video_tx_device *video_tx,
+				struct drm_mode_modeinfo *mode);
+int video_tx_dpms(struct video_tx_device *video_tx, int mode);
+int video_tx_get_info(struct video_tx_device *video_tx,
+		      struct video_tx_info *info);
+int video_tx_get_display_info(struct video_tx_device *video_tx,
+		      struct video_tx_display_info *info);
+enum drm_connector_status video_tx_detect(struct video_tx_device *video_tx);
+
+/* Client functions */
+void video_tx_report_hotplug_event(struct video_tx_device *tx_device);
+struct video_tx_device *video_tx_register_device(struct device *dev,
+					struct video_tx_driver *driver);
+void video_tx_unregister_device(struct video_tx_device *tx_device);
+void video_tx_set_drvdata(struct video_tx_device *tx_device, void *data);
+void *video_tx_get_drvdata(struct video_tx_device *tx_device);
+void video_tx_request_polling(struct video_tx_device *tx_device);
+void video_tx_cancel_polling(struct video_tx_device *tx_device);
+
+#endif /* _VIDEO_TX_H_ */
-- 
1.7.9.5

