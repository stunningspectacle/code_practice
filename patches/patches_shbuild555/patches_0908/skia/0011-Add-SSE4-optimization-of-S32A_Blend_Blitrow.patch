From 379c10d4ecb432c8af7548724b6332bdc6496e5d Mon Sep 17 00:00:00 2001
From: Henrik Smiding <henrik.smiding@intel.com>
Date: Thu, 30 Oct 2014 17:05:17 +0100
Subject: [PATCH 11/12] Add SSE4 optimization of S32A_Blend_Blitrow

Adds optimization of Skia S32A_Blend_Blitrow blitter using SSE4 SIMD
instruction set. Special case for when alpha is zero.

Change-Id: Iafe81e102821038b4ad1562effc755ccca776cf3
Old-Change-ID: I1ad99a95732c0da8b57911b05c437573d3a76217
Ori-Change-ID: Ic555865c53be8f25a3587ef291cdbbcac19723c1
Orig-Change-Id: I2821972a7da87a3d4e3ff865c1f5c130a0d161ce
Category: aosp improvement
Domain: AOSP-Others
Origin: internal
Upstream-Candidate: yes
Tracked-On: https://jira01.devtools.intel.com/browse/CTEAN-1950
Orig-Tracked-On: https://jira01.devtools.intel.com/browse/IMINAN-2473
Signed-off-by: Joakim Landberg <joakim.landberg@intel.com>
Old-Reviewed-on: https://android.intel.com:443/374231
Signed-off-by: Xinyun Liu <xinyun.liu@intel.com>
---
 src/opts/SkBlitRow_opts_SSE4.h         |    3 +
 src/opts/SkBlitRow_opts_SSE4_asm.S     |  623 ++++++++++++++++++++++++++++++++
 src/opts/SkBlitRow_opts_SSE4_x64_asm.S |  572 +++++++++++++++++++++++++++++
 src/opts/opts_check_x86.cpp            |    2 +-
 4 files changed, 1199 insertions(+), 1 deletion(-)

diff --git a/src/opts/SkBlitRow_opts_SSE4.h b/src/opts/SkBlitRow_opts_SSE4.h
index 0fc7062..261ab1f 100644
--- a/src/opts/SkBlitRow_opts_SSE4.h
+++ b/src/opts/SkBlitRow_opts_SSE4.h
@@ -18,6 +18,9 @@ extern "C" void S32A_Opaque_BlitRow32_SSE4_asm(SkPMColor* SK_RESTRICT dst,
                                                const SkPMColor* SK_RESTRICT src,
                                                int count, U8CPU alpha);
 
+extern "C" void S32A_Blend_BlitRow32_SSE4_asm(SkPMColor* SK_RESTRICT dst,
+                                              const SkPMColor* SK_RESTRICT src,
+                                              int count, U8CPU alpha);
 #define SK_ATT_ASM_SUPPORTED
 #endif
 
diff --git a/src/opts/SkBlitRow_opts_SSE4_asm.S b/src/opts/SkBlitRow_opts_SSE4_asm.S
index 417e517..fac77bb 100644
--- a/src/opts/SkBlitRow_opts_SSE4_asm.S
+++ b/src/opts/SkBlitRow_opts_SSE4_asm.S
@@ -468,4 +468,627 @@ S32A_Opaque_BlitRow32_SSE4_asm:
 #ifndef __clang__
     .size S32A_Opaque_BlitRow32_SSE4_asm, .-S32A_Opaque_BlitRow32_SSE4_asm
 #endif
+
+
+/*
+ * void S32A_Blend_BlitRow32_SSE4(SkPMColor* SK_RESTRICT dst,
+ *                                const SkPMColor* SK_RESTRICT src,
+ *                                int count, U8CPU alpha)
+ *
+ * The primary optimization comes from checking the source pixels' alpha value.
+ * If the alpha is zero, the pixel can be skipped entirely.
+ * According to collected statistics, this case is quite common.
+ * The main loop(s) uses pre-loading and unrolling in an attempt to reduce the
+ * memory latency worse-case.
+ */
+
+    .section .text.sse4.2,"ax",@progbits
+    .type S32A_Blend_BlitRow32_SSE4_asm, @function
+    .globl S32A_Blend_BlitRow32_SSE4_asm
+    .hidden S32A_Blend_BlitRow32_SSE4_asm
+    .p2align 4
+S32A_Blend_BlitRow32_SSE4_asm:
+    .cfi_startproc
+    PUSH(%ebx)
+    movl        12(%esp), %eax          // Source pointer
+    movl        16(%esp), %ecx          // Pixel count
+    movl        8(%esp), %edx           // Destination pointer
+    movl        20(%esp), %ebx          // Fetch global alpha parameter
+    prefetcht0  (%eax)
+
+    // Setup SSE constants
+    pcmpeqd     %xmm7, %xmm7            // 0xFF000000 mask to check alpha
+    pcmpeqw     %xmm6, %xmm6            // 16-bit 256 to calculate inv. alpha
+    pslld       $24, %xmm7
+    pcmpeqw     %xmm0, %xmm0            // 0x00FF00FF mask (Must be in xmm0 because of pblendvb)
+    addl        $1, %ebx                // Modify global alpha range to 1..256
+    psrlw       $15, %xmm6
+    imul        $0x10001, %ebx          // Duplicate alpha to two 16-bit values
+    psrlw       $8, %xmm0
+    subl        $4, %ecx                // Check if we have only 0-3 pixels
+    psllw       $8, %xmm6
+    js          .LBlendReallySmall
+    PUSH(%edi)
+    cmpl        $11, %ecx               // Do we have enough pixels to run the main loop?
+    ja          .LBlendBigBlit
+
+    // Handle small blits (4-15 pixels)
+    // ********************************
+    xorl        %edi, %edi              // Reset offset to zero
+
+.LBlendSmallLoop:
+    lddqu       (%eax, %edi), %xmm1     // Load four source pixels
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendSmallAlphaZero
+
+    // Handle global and pixel alphas (calculate and scale)
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    lddqu       (%edx, %edi), %xmm5     // Load last four destination pixels (overlapping)
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    addl        $16, %edi
+    subl        $4, %ecx                // Check if we can store all four pixels
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqu      %xmm1, -16(%edx, %edi)  // Store four destination pixels
+    jns         .LBlendSmallLoop
+    jmp         .LBlendSmallRemaining
+
+    .p2align 4
+.LBlendSmallAlphaZero:
+    addl        $16, %edi
+    subl        $4, %ecx                // Check if there are four additional pixels, at least
+    jns         .LBlendSmallLoop
+
+    // Handle the last 0-3 pixels (also used by the big unaligned loop)
+.LBlendSmallRemaining:
+    cmpl        $-4, %ecx               // Check if we are done
+    je          .LBlendSmallExit
+    sall        $2, %ecx                // Calculate offset for last pixels
+    addl        %ecx, %edi
+
+    lddqu       (%eax, %edi), %xmm1     // Load last four source pixels (overlapping)
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendSmallExit
+
+    // Handle mixed alphas (calculate and scale)
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    lddqu       (%edx, %edi), %xmm5     // Load last four destination pixels (overlapping)
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm3               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm3            // Scale red and blue
+    movdqa      %xmm5, %xmm2            // Clone destination pixels
+    psrlw       $8, %xmm2               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm2            // Scale alpha and green
+
+    pblendvb    %xmm0, %xmm3, %xmm2     // Combine scaled destination results
+    cmp         $-8, %ecx               // Check how many pixels should be written
+    paddb       %xmm2, %xmm1            // Add source and destination pixels together
+    jb          .LBlendSmallPixelsLeft1
+    ja          .LBlendSmallPixelsLeft3
+    pblendw     $0xF0, %xmm1, %xmm5
+    movdqu      %xmm5, (%edx, %edi)     // Store last two destination pixels
+.LBlendSmallExit:
+    POP(%edi)
+    POP(%ebx)
+    ret
+
+.LBlendSmallPixelsLeft1:
+    pblendw     $0xC0, %xmm1, %xmm5
+    movdqu      %xmm5, (%edx, %edi)     // Store last destination pixel
+    POP(%edi)
+    POP(%ebx)
+    ret
+
+.LBlendSmallPixelsLeft3:
+    pblendw     $0xFC, %xmm1, %xmm5
+    movdqu      %xmm5, (%edx, %edi)     // Store last three destination pixels
+    POP(%edi)
+    POP(%ebx)
+    ret
+
+
+    // Handle really small blits (0-3 pixels)
+    // **************************************
+.LBlendReallySmall:
+    addl        $4, %ecx
+    jle         .LBlendReallySmallExit
+    pxor        %xmm1, %xmm1
+    cmp         $2, %ecx                // Check how many pixels should be read
+    pinsrd      $0x0, (%eax), %xmm1     // Load one source pixel
+    pinsrd      $0x0, (%edx), %xmm5     // Load one destination pixel
+    jb          .LBlendReallySmallCalc
+    pinsrd      $0x1, 4(%eax), %xmm1    // Load second source pixel
+    pinsrd      $0x1, 4(%edx), %xmm5    // Load second destination pixel
+    je          .LBlendReallySmallCalc
+    pinsrd      $0x2, 8(%eax), %xmm1    // Load third source pixel
+    pinsrd      $0x2, 8(%edx), %xmm5    // Load third destination pixel
+
+.LBlendReallySmallCalc:
+    ptest       %xmm7, %xmm1            // Check if all alphas are opaque
+    jz          .LBlendReallySmallExit  // If all alphas are zero, just store
+
+    // Handle mixed alphas (calculate and scale)
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    cmp         $2, %ecx                // Check how many pixels should be written
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    pextrd      $0x0, %xmm1, (%edx)     // Store one destination pixel
+    jb          .LBlendReallySmallExit
+    pextrd      $0x1, %xmm1, 4(%edx)    // Store second destination pixel
+    je          .LBlendReallySmallExit
+    pextrd      $0x2, %xmm1, 8(%edx)    // Store third destination pixel
+.LBlendReallySmallExit:
+    POP(%ebx)
+    ret
+
+    // Handle bigger blit operations (16+ pixels)
+    // ******************************************
+    .p2align 4
+.LBlendBigBlit:
+    // Align destination?
+    testl       $0xF, %edx
+    lddqu       (%eax), %xmm1           // Pre-load four source pixels
+    jz          .LBlendAligned
+
+    movl        %edx, %edi              // Calculate alignment of destination pointer
+    negl        %edi
+    andl        $0xF, %edi
+
+    // Handle 1-3 pixels to align destination
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlignDone        // If all alphas are opaque, just skip
+
+    // Handle global and pixel alphas (calculate and scale)
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    lddqu       (%edx), %xmm5           // Load four destination pixels
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm3               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm3            // Scale red and blue
+    movdqa      %xmm5, %xmm2            // Clone destination pixels
+    psrlw       $8, %xmm2               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm2            // Scale alpha and green
+
+    cmp         $8, %edi                // Check how many pixels should be written
+    pblendvb    %xmm0, %xmm3, %xmm2     // Combine scaled destination results
+    paddb       %xmm2, %xmm1            // Add source and destination pixels together
+    jb          .LBlendAlignPixelsLeft1
+    ja          .LBlendAlignPixelsLeft3
+    pblendw     $0x0F, %xmm1, %xmm5     // Blend two pixels
+    jmp .LBlendAlignStorePixels
+
+.LBlendAlignPixelsLeft1:
+    pblendw     $0x03, %xmm1, %xmm5     // Blend one pixel
+    jmp .LBlendAlignStorePixels
+
+.LBlendAlignPixelsLeft3:
+    pblendw     $0x3F, %xmm1, %xmm5     // Blend three pixels
+
+.LBlendAlignStorePixels:
+    movdqu      %xmm5, (%edx)           // Store destination pixels
+
+.LBlendAlignDone:
+    addl        %edi, %eax              // Adjust pointers and pixel count
+    addl        %edi, %edx
+    shrl        $2, %edi
+    lddqu       (%eax), %xmm1           // Pre-load new source pixels (after alignment)
+    subl        %edi, %ecx
+
+.LBlendAligned:                         // Destination is guaranteed to be 16 byte aligned
+    xorl        %edi, %edi              // Reset offset to zero
+    subl        $8, %ecx                // Decrease counter (Reserve four pixels for the cleanup)
+    testl       $0xF, %eax              // Check alignment of source pointer
+    jz          .LBlendAlignedLoop
+
+    // Source not aligned to destination
+    // *********************************
+    .p2align 4
+.LBlendUnalignedLoop:                   // Main loop for unaligned, handles eight pixels per iteration
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlphaZero00
+
+    // Handle global and pixel alphas (calculate and scale)
+.LBlendAlphaNotZero00:
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%edx, %edi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    lddqu       16(%eax, %edi), %xmm2   // Pre-load four source pixels
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqa      %xmm1, (%edx, %edi)     // Store four destination pixels
+
+    // Handle next four pixels
+    ptest       %xmm7, %xmm2            // Check if all alphas are zero or opaque
+    jz         .LBlendAlphaZero01
+
+    // Handle global and pixel alphas (calculate and scale)
+.LBlendAlphaNotZero01:
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm2, %xmm3            // Filter out alpha and green components from source
+    movdqa      16(%edx, %edi), %xmm5   // Load four destination pixels
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm2               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm2            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm1     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm1, %xmm1     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm2
+    psubw       %xmm1, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    lddqu       32(%eax, %edi), %xmm1   // Pre-load four source pixels
+    addl        $32, %edi
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm2            // Add source and destination pixels together
+    subl        $8, %ecx
+    movdqa      %xmm2, -16(%edx, %edi)  // Store four destination pixels
+    jae         .LBlendUnalignedLoop
+    addl        $8, %ecx                // Adjust pixel count
+    jmp         .LBlendLoopCleanup0
+
+    .p2align 4
+.LBlendUnalignedLoopZero:               // Alternate 'alpha zero' main loop for unaligned
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jnz         .LBlendAlphaNotZero00
+.LBlendAlphaZero00:
+    lddqu       16(%eax, %edi), %xmm2   // Pre-load four source pixels
+    ptest       %xmm7, %xmm2            // Check if all alphas are zero or opaque
+    jnz         .LBlendAlphaNotZero01
+.LBlendAlphaZero01:
+    lddqu       32(%eax, %edi), %xmm1   // Pre-load four source pixels
+    addl        $32, %edi               // Adjust offset and pixel count
+    subl        $8, %ecx
+    jae         .LBlendUnalignedLoopZero
+    addl        $8, %ecx                // Adjust pixel count
+
+    // Cleanup - handle pending pixels from loop
+.LBlendLoopCleanup0:
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlphaZero03
+
+    // Handle global and pixel alphas (calculate and scale)
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%edx, %edi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqa      %xmm1, (%edx, %edi)     // Store four destination pixels
+
+.LBlendAlphaZero03:
+    addl        $16, %edi
+    subl        $4, %ecx
+    js          .LBlendSmallRemaining   // Reuse code from small loop
+    lddqu       (%eax, %edi), %xmm1     // Pre-load four source pixels
+    jmp         .LBlendLoopCleanup0
+
+    // Source aligned to destination
+    // *****************************
+    .p2align 4
+.LBlendAlignedLoop:                     // Main loop for aligned, handles eight pixels per iteration
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlphaZero10
+
+    // Handle global and pixel alphas (calculate and scale)
+.LBlendAlphaNotZero10:
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%edx, %edi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    movdqa      16(%eax, %edi), %xmm2   // Pre-load four source pixels
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqa      %xmm1, (%edx, %edi)     // Store four destination pixels
+
+    // Handle next four pixels
+    ptest       %xmm7, %xmm2            // Check if all alphas are zero or opaque
+    jz         .LBlendAlphaZero11
+
+    // Handle global and pixel alphas (calculate and scale)
+.LBlendAlphaNotZero11:
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm2, %xmm3            // Filter out alpha and green components from source
+    movdqa      16(%edx, %edi), %xmm5   // Load four destination pixels
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm2               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm2            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm1     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm1, %xmm1     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm2
+    psubw       %xmm1, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    movdqa      32(%eax, %edi), %xmm1   // Pre-load four source pixels
+    addl        $32, %edi
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm2            // Add source and destination pixels together
+    subl        $8, %ecx
+    movdqa      %xmm2, -16(%edx, %edi)  // Store four destination pixels
+    jae         .LBlendAlignedLoop
+    jmp         .LBlendLoopCleanup1
+
+    .p2align 4
+.LBlendAlignedLoopZero:                 // Alternate 'alpha zero' main loop for unaligned
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jnz         .LBlendAlphaNotZero10
+.LBlendAlphaZero10:
+    movdqa      16(%eax, %edi), %xmm2   // Pre-load four source pixels
+    ptest       %xmm7, %xmm2            // Check if all alphas are zero or opaque
+    jnz         .LBlendAlphaNotZero11
+.LBlendAlphaZero11:
+    movdqa      32(%eax, %edi), %xmm1   // Pre-load four source pixels
+    addl        $32, %edi               // Adjust offset and pixel count
+    subl        $8, %ecx
+    jae         .LBlendAlignedLoopZero
+
+    // Cleanup - handle four pending pixels from loop
+.LBlendLoopCleanup1:
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlphaZero13
+
+    // Handle global and pixel alphas (calculate and scale)
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%edx, %edi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqa      %xmm1, (%edx, %edi)     // Store four destination pixels
+
+.LBlendAlphaZero13:
+    addl        $8, %ecx                // Adjust offset and pixel count
+    jz          .LBlendExit
+    addl        $16, %edi
+
+    // Handle last 1-7 pixels
+.LBlendRemainLoop1:
+    movdqa      (%eax, %edi), %xmm1     // Load four source pixels
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendRemainAlphaZero1
+
+    // Handle global and pixel alphas (calculate and scale)
+    movd        %ebx, %xmm4             // Create global alpha constant
+    movdqa      %xmm0, %xmm3
+    pshufd      $0, %xmm4, %xmm4
+
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%edx, %edi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm4, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm4, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    subl        $4, %ecx
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    jle         .LBlendRemainStore
+    movdqa      %xmm1, (%edx, %edi)     // Store four destination pixels
+    addl        $16, %edi
+    jmp         .LBlendRemainLoop1
+
+    // All alphas were zero (skip)
+    .p2align 4
+.LBlendRemainAlphaZero1:
+    subl        $4, %ecx                // Check if we have more than four pixels left
+    jle         .LBlendExit
+    addl        $16, %edi
+    jmp         .LBlendRemainLoop1
+
+    // Store the last 1-4 pixels
+    .p2align 4
+.LBlendRemainStore:
+    jz          .LBlendRemainFull
+    movdqa      (%edx, %edi), %xmm5     // Load four destination pixels
+    cmp         $-2, %ecx               // Check how many pixels should be written
+    jb          .LBlendRemainPixelsLeft11
+    ja          .LBlendRemainPixelsLeft13
+    pblendw     $0x0F, %xmm1, %xmm5
+    movdqa      %xmm5, (%edx, %edi)     // Store last 2 destination pixels
+.LBlendExit:
+    POP(%edi)                           // Exit
+    POP(%ebx)
+    ret
+
+.LBlendRemainPixelsLeft11:
+    pblendw     $0x03, %xmm1, %xmm5
+    movdqa      %xmm5, (%edx, %edi)     // Store last destination pixel
+    POP(%edi)                           // Exit
+    POP(%ebx)
+    ret
+
+.LBlendRemainPixelsLeft13:
+    pblendw     $0x3F, %xmm1, %xmm5
+    movdqa      %xmm5, (%edx, %edi)     // Store last 3 destination pixels
+    POP(%edi)                           // Exit
+    POP(%ebx)
+    ret
+
+.LBlendRemainFull:
+    movdqa      %xmm1, (%edx, %edi)     // Store last 4 destination pixels
+    POP(%edi)                           // Exit
+    POP(%ebx)
+    ret
+
+    .cfi_endproc
+    .size S32A_Blend_BlitRow32_SSE4_asm, .-S32A_Blend_BlitRow32_SSE4_asm
 #endif
diff --git a/src/opts/SkBlitRow_opts_SSE4_x64_asm.S b/src/opts/SkBlitRow_opts_SSE4_x64_asm.S
index 41a147e..305e384 100644
--- a/src/opts/SkBlitRow_opts_SSE4_x64_asm.S
+++ b/src/opts/SkBlitRow_opts_SSE4_x64_asm.S
@@ -465,4 +465,576 @@ S32A_Opaque_BlitRow32_SSE4_asm:
     .word   256, 256, 256, 256, 256, 256, 256, 256
 .LResultMergeMask:
     .long   0x00FF00FF, 0x00FF00FF, 0x00FF00FF, 0x00FF00FF
+
+/*
+ * void S32A_Blend_BlitRow32_SSE4(SkPMColor* SK_RESTRICT dst,
+ *                                const SkPMColor* SK_RESTRICT src,
+ *                                int count, U8CPU alpha)
+ *
+ * The primary optimization comes from checking the source pixels' alpha value.
+ * If the alpha is zero, the pixel can be skipped entirely.
+ * According to collected statistics, this case is quite common.
+ * The main loop(s) uses pre-loading and unrolling in an attempt to reduce the
+ * memory latency worse-case.
+ */
+
+    .section .text.sse4.2,"ax",@progbits
+    .type S32A_Blend_BlitRow32_SSE4_asm, @function
+    .globl S32A_Blend_BlitRow32_SSE4_asm
+    .hidden S32A_Blend_BlitRow32_SSE4_asm
+    .p2align 4
+S32A_Blend_BlitRow32_SSE4_asm:
+    .cfi_startproc
+    prefetcht0  (%rsi)
+    movq        %rsi, %rax              // Source pointer
+    movl        %ecx, %esi              // Global alpha
+    movl        %edx, %ecx              // Pixel count
+    movq        %rdi, %rdx              // Destination pointer
+
+    // Setup SSE constants
+    addl        $1, %esi                // Modify global alpha range to 1..256
+    imul        $0x10001, %esi          // Duplicate alpha to two 16-bit values
+    movdqa      .LAlphaCheckMask(%rip), %xmm7  // 0xFF000000 mask to check alpha
+    movdqa      .LInverseAlphaCalc(%rip), %xmm6// 16-bit 256 to calculate inv. alpha
+    movdqa      .LResultMergeMask(%rip), %xmm0 // 0x00FF00FF mask (Must be in xmm0 because of pblendvb)
+    movd        %esi, %xmm8             // Create global alpha constant
+    pshufd      $0, %xmm8, %xmm8
+
+    subl        $4, %ecx                // Check if we have only 0-3 pixels
+    js          .LBlendReallySmall
+    cmpl        $11, %ecx               // Do we have enough pixels to run the main loop?
+    ja          .LBlendBigBlit
+
+    // Handle small blits (4-15 pixels)
+    // ********************************
+    xorq        %rdi, %rdi              // Reset offset to zero
+
+.LBlendSmallLoop:
+    lddqu       (%rax, %rdi), %xmm1     // Load four source pixels
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendSmallAlphaZero
+
+    // Handle global and pixel alphas (calculate and scale)
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    lddqu       (%rdx, %rdi), %xmm5     // Load last four destination pixels (overlapping)
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    addq        $16, %rdi
+    subl        $4, %ecx                // Check if we can store all four pixels
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqu      %xmm1, -16(%rdx, %rdi)  // Store four destination pixels
+    jns         .LBlendSmallLoop
+    jmp         .LBlendSmallRemaining
+
+    .p2align 4
+.LBlendSmallAlphaZero:
+    addq        $16, %rdi
+    subl        $4, %ecx                // Check if there are four additional pixels, at least
+    jns         .LBlendSmallLoop
+
+    // Handle the last 0-3 pixels (also used by the big unaligned loop)
+.LBlendSmallRemaining:
+    cmpl        $-4, %ecx               // Check if we are done
+    je          .LBlendSmallExit
+    sall        $2, %ecx                // Calculate offset for last pixels
+    movslq      %ecx, %rcx
+    addq        %rcx, %rdi
+
+    lddqu       (%rax, %rdi), %xmm1     // Load last four source pixels (overlapping)
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendSmallExit
+
+    // Handle mixed alphas (calculate and scale)
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    lddqu       (%rdx, %rdi), %xmm5     // Load last four destination pixels (overlapping)
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm3               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm3            // Scale red and blue
+    movdqa      %xmm5, %xmm2            // Clone destination pixels
+    psrlw       $8, %xmm2               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm2            // Scale alpha and green
+
+    pblendvb    %xmm0, %xmm3, %xmm2     // Combine scaled destination results
+    cmpl        $-8, %ecx               // Check how many pixels should be written
+    paddb       %xmm2, %xmm1            // Add source and destination pixels together
+    jb          .LBlendSmallPixelsLeft1
+    ja          .LBlendSmallPixelsLeft3
+    pblendw     $0xF0, %xmm1, %xmm5
+    movdqu      %xmm5, (%rdx, %rdi)     // Store last two destination pixels
+.LBlendSmallExit:
+    ret
+
+.LBlendSmallPixelsLeft1:
+    pblendw     $0xC0, %xmm1, %xmm5
+    movdqu      %xmm5, (%rdx, %rdi)     // Store last destination pixel
+    ret
+
+.LBlendSmallPixelsLeft3:
+    pblendw     $0xFC, %xmm1, %xmm5
+    movdqu      %xmm5, (%rdx, %rdi)     // Store last three destination pixels
+    ret
+
+
+    // Handle really small blits (0-3 pixels)
+    // **************************************
+.LBlendReallySmall:
+    addl        $4, %ecx
+    jle         .LBlendReallySmallExit
+    pxor        %xmm1, %xmm1
+    cmpl        $2, %ecx                // Check how many pixels should be read
+    pinsrd      $0x0, (%rax), %xmm1     // Load one source pixel
+    pinsrd      $0x0, (%rdx), %xmm5     // Load one destination pixel
+    jb          .LBlendReallySmallCalc
+    pinsrd      $0x1, 4(%rax), %xmm1    // Load second source pixel
+    pinsrd      $0x1, 4(%rdx), %xmm5    // Load second destination pixel
+    je          .LBlendReallySmallCalc
+    pinsrd      $0x2, 8(%rax), %xmm1    // Load third source pixel
+    pinsrd      $0x2, 8(%rdx), %xmm5    // Load third destination pixel
+
+.LBlendReallySmallCalc:
+    ptest       %xmm7, %xmm1            // Check if all alphas are opaque
+    jz          .LBlendReallySmallExit  // If all alphas are zero, just store
+
+    // Handle mixed alphas (calculate and scale)
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    cmpl        $2, %ecx                // Check how many pixels should be written
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    pextrd      $0x0, %xmm1, (%rdx)     // Store one destination pixel
+    jb          .LBlendReallySmallExit
+    pextrd      $0x1, %xmm1, 4(%rdx)    // Store second destination pixel
+    je          .LBlendReallySmallExit
+    pextrd      $0x2, %xmm1, 8(%rdx)    // Store third destination pixel
+.LBlendReallySmallExit:
+    ret
+
+    // Handle bigger blit operations (16+ pixels)
+    // ******************************************
+    .p2align 4
+.LBlendBigBlit:
+    // Align destination?
+    testl       $0xF, %edx
+    lddqu       (%rax), %xmm1           // Pre-load four source pixels
+    jz          .LBlendAligned
+
+    movq        %rdx, %rdi              // Calculate alignment of destination pointer
+    negq        %rdi
+    andl        $0xF, %edi
+
+    // Handle 1-3 pixels to align destination
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlignDone        // If all alphas are opaque, just skip
+
+    // Handle global and pixel alphas (calculate and scale)
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    lddqu       (%rdx), %xmm5           // Load four destination pixels
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm3               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm3            // Scale red and blue
+    movdqa      %xmm5, %xmm2            // Clone destination pixels
+    psrlw       $8, %xmm2               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm2            // Scale alpha and green
+
+    cmpl        $8, %edi                // Check how many pixels should be written
+    pblendvb    %xmm0, %xmm3, %xmm2     // Combine scaled destination results
+    paddb       %xmm2, %xmm1            // Add source and destination pixels together
+    jb          .LBlendAlignPixelsLeft1
+    ja          .LBlendAlignPixelsLeft3
+    pblendw     $0x0F, %xmm1, %xmm5     // Blend two pixels
+    jmp .LBlendAlignStorePixels
+
+.LBlendAlignPixelsLeft1:
+    pblendw     $0x03, %xmm1, %xmm5     // Blend one pixel
+    jmp .LBlendAlignStorePixels
+
+.LBlendAlignPixelsLeft3:
+    pblendw     $0x3F, %xmm1, %xmm5     // Blend three pixels
+
+.LBlendAlignStorePixels:
+    movdqu      %xmm5, (%rdx)           // Store destination pixels
+
+.LBlendAlignDone:
+    addq        %rdi, %rax              // Adjust pointers and pixel count
+    addq        %rdi, %rdx
+    shrq        $2, %rdi
+    lddqu       (%rax), %xmm1           // Pre-load new source pixels (after alignment)
+    subl        %edi, %ecx
+
+.LBlendAligned:                         // Destination is guaranteed to be 16 byte aligned
+    xorq        %rdi, %rdi              // Reset offset to zero
+    subl        $8, %ecx                // Decrease counter (Reserve four pixels for the cleanup)
+    testl       $0xF, %eax              // Check alignment of source pointer
+    jz          .LBlendAlignedLoop
+
+    // Source not aligned to destination
+    // *********************************
+    .p2align 4
+.LBlendUnalignedLoop:                   // Main loop for unaligned, handles eight pixels per iteration
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlphaZero00
+
+    // Handle global and pixel alphas (calculate and scale)
+.LBlendAlphaNotZero00:
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%rdx, %rdi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    lddqu       16(%rax, %rdi), %xmm2   // Pre-load four source pixels
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqa      %xmm1, (%rdx, %rdi)     // Store four destination pixels
+
+    // Handle next four pixels
+    ptest       %xmm7, %xmm2            // Check if all alphas are zero or opaque
+    jz         .LBlendAlphaZero01
+
+    // Handle global and pixel alphas (calculate and scale)
+.LBlendAlphaNotZero01:
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm2, %xmm3            // Filter out alpha and green components from source
+    movdqa      16(%rdx, %rdi), %xmm5   // Load four destination pixels
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm2               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm2            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm1     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm1, %xmm1     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm2
+    psubw       %xmm1, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    lddqu       32(%rax, %rdi), %xmm1   // Pre-load four source pixels
+    addq        $32, %rdi
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm2            // Add source and destination pixels together
+    subl        $8, %ecx
+    movdqa      %xmm2, -16(%rdx, %rdi)  // Store four destination pixels
+    jae         .LBlendUnalignedLoop
+    addl        $8, %ecx                // Adjust pixel count
+    jmp         .LBlendLoopCleanup0
+
+    .p2align 4
+.LBlendUnalignedLoopZero:               // Alternate 'alpha zero' main loop for unaligned
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jnz         .LBlendAlphaNotZero00
+.LBlendAlphaZero00:
+    lddqu       16(%rax, %rdi), %xmm2   // Pre-load four source pixels
+    ptest       %xmm7, %xmm2            // Check if all alphas are zero or opaque
+    jnz         .LBlendAlphaNotZero01
+.LBlendAlphaZero01:
+    lddqu       32(%rax, %rdi), %xmm1   // Pre-load four source pixels
+    addq        $32, %rdi               // Adjust offset and pixel count
+    subl        $8, %ecx
+    jae         .LBlendUnalignedLoopZero
+    addl        $8, %ecx                // Adjust pixel count
+
+    // Cleanup - handle pending pixels from loop
+.LBlendLoopCleanup0:
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlphaZero03
+
+    // Handle global and pixel alphas (calculate and scale)
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%rdx, %rdi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqa      %xmm1, (%rdx, %rdi)     // Store four destination pixels
+
+.LBlendAlphaZero03:
+    addq        $16, %rdi
+    subl        $4, %ecx
+    js          .LBlendSmallRemaining   // Reuse code from small loop
+    lddqu       (%rax, %rdi), %xmm1     // Pre-load four source pixels
+    jmp         .LBlendLoopCleanup0
+
+    // Source aligned to destination
+    // *****************************
+    .p2align 4
+.LBlendAlignedLoop:                     // Main loop for aligned, handles eight pixels per iteration
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlphaZero10
+
+    // Handle global and pixel alphas (calculate and scale)
+.LBlendAlphaNotZero10:
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%rdx, %rdi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    movdqa      16(%rax, %rdi), %xmm2   // Pre-load four source pixels
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqa      %xmm1, (%rdx, %rdi)     // Store four destination pixels
+
+    // Handle next four pixels
+    ptest       %xmm7, %xmm2            // Check if all alphas are zero or opaque
+    jz         .LBlendAlphaZero11
+
+    // Handle global and pixel alphas (calculate and scale)
+.LBlendAlphaNotZero11:
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm2, %xmm3            // Filter out alpha and green components from source
+    movdqa      16(%rdx, %rdi), %xmm5   // Load four destination pixels
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm2               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm2            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm1     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm1, %xmm1     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm2
+    psubw       %xmm1, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    movdqa      32(%rax, %rdi), %xmm1   // Pre-load four source pixels
+    addq        $32, %rdi
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm2            // Add source and destination pixels together
+    subl        $8, %ecx
+    movdqa      %xmm2, -16(%rdx, %rdi)  // Store four destination pixels
+    jae         .LBlendAlignedLoop
+    jmp         .LBlendLoopCleanup1
+
+    .p2align 4
+.LBlendAlignedLoopZero:                 // Alternate 'alpha zero' main loop for unaligned
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jnz         .LBlendAlphaNotZero10
+.LBlendAlphaZero10:
+    movdqa      16(%rax, %rdi), %xmm2   // Pre-load four source pixels
+    ptest       %xmm7, %xmm2            // Check if all alphas are zero or opaque
+    jnz         .LBlendAlphaNotZero11
+.LBlendAlphaZero11:
+    movdqa      32(%rax, %rdi), %xmm1   // Pre-load four source pixels
+    addq        $32, %rdi               // Adjust offset and pixel count
+    subl        $8, %ecx
+    jae         .LBlendAlignedLoopZero
+
+    // Cleanup - handle four pending pixels from loop
+.LBlendLoopCleanup1:
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendAlphaZero13
+
+    // Handle global and pixel alphas (calculate and scale)
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%rdx, %rdi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    movdqa      %xmm1, (%rdx, %rdi)     // Store four destination pixels
+
+.LBlendAlphaZero13:
+    addl        $8, %ecx                // Adjust offset and pixel count
+    jz          .LBlendExit
+    addq        $16, %rdi
+
+    // Handle last 1-7 pixels
+.LBlendRemainLoop1:
+    movdqa      (%rax, %rdi), %xmm1     // Load four source pixels
+    ptest       %xmm7, %xmm1            // Check if all alphas are zero or opaque
+    jz          .LBlendRemainAlphaZero1
+
+    // Handle global and pixel alphas (calculate and scale)
+    movdqa      %xmm0, %xmm3
+    pandn       %xmm1, %xmm3            // Filter out alpha and green components from source
+    movdqa      (%rdx, %rdi), %xmm5     // Load four destination pixels
+    pmulhuw     %xmm8, %xmm3            // Scale alpha and green
+    psllw       $8, %xmm1               // Filter out red and blue components from source
+    pmulhuw     %xmm8, %xmm1            // Scale red and blue
+
+    pshufhw     $0xF5, %xmm3, %xmm2     // Repeat source alpha for scaling of destination (high)
+    psllw       $8, %xmm3               // Combine scaled source results
+    pshuflw     $0xF5, %xmm2, %xmm2     // Repeat source alpha (low)
+    movdqa      %xmm6, %xmm4            // Clone 256 constant
+    por         %xmm3, %xmm1
+    psubw       %xmm2, %xmm4            // Finalize alpha calculations
+    movdqa      %xmm5, %xmm3            // Clone destination pixels
+
+    psllw       $8, %xmm5               // Filter out red and blue components
+    pmulhuw     %xmm4, %xmm5            // Scale red and blue
+    psrlw       $8, %xmm3               // Filter out alpha and green components
+    pmullw      %xmm4, %xmm3            // Scale alpha and green
+
+    subl        $4, %ecx
+    pblendvb    %xmm0, %xmm5, %xmm3     // Combine scaled destination results
+    paddb       %xmm3, %xmm1            // Add source and destination pixels together
+    jle         .LBlendRemainStore
+    movdqa      %xmm1, (%rdx, %rdi)     // Store four destination pixels
+    addq        $16, %rdi
+    jmp         .LBlendRemainLoop1
+
+    // All alphas were zero (skip)
+    .p2align 4
+.LBlendRemainAlphaZero1:
+    subl        $4, %ecx                // Check if we have more than four pixels left
+    jle         .LBlendExit
+    addq        $16, %rdi
+    jmp         .LBlendRemainLoop1
+
+    // Store the last 1-4 pixels
+    .p2align 4
+.LBlendRemainStore:
+    jz          .LBlendRemainFull
+    movdqa      (%rdx, %rdi), %xmm5     // Load four destination pixels
+    cmpl        $-2, %ecx               // Check how many pixels should be written
+    jb          .LBlendRemainPixelsLeft11
+    ja          .LBlendRemainPixelsLeft13
+    pblendw     $0x0F, %xmm1, %xmm5
+    movdqa      %xmm5, (%rdx, %rdi)     // Store last 2 destination pixels
+.LBlendExit:
+    ret
+
+.LBlendRemainPixelsLeft11:
+    pblendw     $0x03, %xmm1, %xmm5
+    movdqa      %xmm5, (%rdx, %rdi)     // Store last destination pixel
+    ret
+
+.LBlendRemainPixelsLeft13:
+    pblendw     $0x3F, %xmm1, %xmm5
+    movdqa      %xmm5, (%rdx, %rdi)     // Store last 3 destination pixels
+    ret
+
+.LBlendRemainFull:
+    movdqa      %xmm1, (%rdx, %rdi)     // Store last 4 destination pixels
+    ret
+
+    .cfi_endproc
+    .size S32A_Blend_BlitRow32_SSE4_asm, .-S32A_Blend_BlitRow32_SSE4_asm
 #endif
diff --git a/src/opts/opts_check_x86.cpp b/src/opts/opts_check_x86.cpp
index 1a30532..266ffc8 100644
--- a/src/opts/opts_check_x86.cpp
+++ b/src/opts/opts_check_x86.cpp
@@ -212,7 +212,7 @@ static SkBlitRow::Proc32 platform_32_procs_SSE4[] = {
     NULL,                               // S32_Opaque,
     S32_Blend_BlitRow32_SSE2,           // S32_Blend,
     S32A_Opaque_BlitRow32_SSE4_asm,     // S32A_Opaque
-    S32A_Blend_BlitRow32_SSE2,          // S32A_Blend,
+    S32A_Blend_BlitRow32_SSE4_asm       // S32A_Blend,
 };
 #endif
 
-- 
1.7.9.5

